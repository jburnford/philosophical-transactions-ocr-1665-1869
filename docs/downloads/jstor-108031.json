{
  "id": "ee3adae48c9df14b8590a5257c0be3c8b2442b6d",
  "text": "§ 1. Brief Historical Sketch of the Subject.\n\nThe first inventors of the integral calculus observed that only a certain number of formulæ were susceptible of exact integration, or could be reduced to a finite number of terms involving algebraic, circular, or logarithmic quantities. When this result could not be attained, they were accustomed to develop the integral in an infinite series. But this method, although useful when numerical values are to be computed, is entirely inadequate, in an analytical point of view, to supply the place of the exact integral; for the progress of analysis has shown many instances of exact relation between different integrals which cannot by any means be inferred from the infinite series in which they are developed.\n\nThe first great improvement beyond this was made by Fagnani about the year 1714. This most acute and ingenious mathematician proposed the following question to the scientific world in an Italian journal*: \"Given a biquadratic parabola whose equation is $x^4 = y$, and an arc of it, to find another arc, so that their difference may be rectifiable.\"\n\nNo answer appearing, he published a solution of the problem in the year 1715†, and extended it in a nearly similar manner to other curves whose equation is $x^n = y$, viz. to those cases where $n$ equals one of the numbers $3, \\frac{5}{2}, \\frac{7}{3}, \\frac{9}{4}, \\frac{11}{5}, \\frac{13}{6}$.\n\nIn the year 1718 and afterwards he published a variety of important theorems respecting the division into equal parts of the arcs of the lemniscate, and respecting the ellipse and hyperbola, in both of which he showed how two arcs may be determined of which the difference is a known straight line. These discoveries justify us in regarding Fagnani as the founder of a new and very curious branch of analysis.\n\nEuler, who enriched almost every department of science with new discoveries, exhibited the complete algebraic integral of the equation\n\n$$\\frac{dx}{\\sqrt{\\alpha + \\beta x + \\gamma x^2 + \\delta x^3 + \\varepsilon x^4}} + \\frac{dy}{\\sqrt{\\alpha + \\beta y + \\gamma y^2 + \\delta y^3 + \\varepsilon y^4}} = 0;$$\n\na remarkable theorem, which long continued to be the ne plus ultra of this branch of science, little success having attended the endeavours of mathematicians to arrive at results of greater generality.\n\n* Giornale de' Letterati d'Italia, tom. xix. p. 438. † tom. xxii. p. 229.\nThe excellent work of Legendre* was destined to arrange, classify, and distinguish the properties of elliptic integrals which are implicitly contained in Euler's theorem above mentioned. In this treatise he has thoroughly examined the nature of these transcendentals, and presented the results of his inquiries in a luminous and well-arranged theory.\n\nThe extensive tables which accompany his work will enable future mathematicians to make as frequent and convenient use of elliptic integrals as they have hitherto done of circular and logarithmic ones.\n\nIn the year 1828 Mr. Abel, of Christiania in Norway, published a very remarkable theorem, which gives the sum of a series of integrals of the form \\( \\int \\frac{P dx}{\\sqrt{R}} \\), where \\( P \\) and \\( R \\) are entire functions of \\( x \\), of the form \\( x^n + ax^{n-1} + bx^{n-2} + \\ldots \\); \\( n \\) being any whole positive number, and \\( a, b, \\&c. \\) constant coefficients.\n\nThis theorem extends much further than Euler's, in as much as the latter is limited to those forms of \\( R \\) which contain no higher powers of \\( x \\) than the fourth. It departs still more widely from Euler's theorem, in exhibiting the sum, not of two only, but of many integrals of the same form. And it must be observed that this plurality of terms is in general necessary; for if we give to the expression \\( \\int \\frac{dx}{\\sqrt{R}} \\) its utmost generality, it does not appear possible to find the sum of only two such integrals in finite algebraic, or logarithmic terms; but it is requisite to combine a greater number of them, below which number the problem cannot be reduced.\n\nAbel's theorem in general furnishes a multitude of solutions for each particular case of the problem: notwithstanding which it is possible to find other solutions which appear not to be comprised in his theorem, nor deducible from it†.\n\nOn the publication of this theorem the illustrious Legendre, who at an advanced age still cultivated his favourite science with all the ardour of youth, was one of the first to feel its extent and importance. And accordingly, with a degree of zeal almost unequalled in the annals of science, he devoted a large portion of time to the verification and elucidation of the theorem by numerical examples. The result of these calculations was amply confirmatory of its truth, and it therefore undoubtedly stands upon the basis of rigorous demonstration.\n\nThere can be little doubt that the ingenious mathematician to whom we are indebted for this theorem would have arrived at fresh discoveries, of not inferior value,\n\n---\n\n* Exercices de Calcul Intégral. Paris, 1811. Traité des Fonctions Elliptiques. Paris, 1825.\n\n† For instance, if \\( \\frac{dx}{\\sqrt{1+x^4}} + \\frac{dy}{\\sqrt{1+y^4}} = 0 \\), his theorem gives the integral \\( xy = 1 \\); but, apparently, it does not give this other integral \\( y^2 = \\frac{\\sqrt{1+x^4}+x\\sqrt{2}}{\\sqrt{1+x^4}-x\\sqrt{2}} \\), which was discovered by Fagnani (Produzioni Matematiche, vol. ii. p. 369.).\nif a premature death had not terminated his career, to the irreparable loss of science, at the early age of twenty-seven.\n\nBefore concluding this slight historical sketch of the subject, I ought not to omit mention of a valuable recent memoir by M. Poisson*, in which he has considered various forms of integrals which are not comprehended in Abel's formula.\n\nIt has already been stated that the integrals to which Abel's theorem relates are those comprised in the general expression $\\int \\frac{P}{\\sqrt{R}} \\, dx$, where $P$ and $R$ are entirely polynomials in $x$. Next in order of succession to these there naturally presents itself the class of integrals whose general expression is $\\int \\frac{P}{\\sqrt[3]{R}} \\, dx$, where the polynomial $R$ is affected with a cubic instead of a quadratic radical.\n\nBut Abel's theorem has no reference to these, and consequently affords us no assistance in their solution. The same may be said with regard to the succeeding classes of integrals, $\\int \\frac{P}{\\sqrt[4]{R}} \\, dx$, $\\int \\frac{P}{\\sqrt[5]{R}} \\, dx$, and generally $\\int \\frac{P}{\\sqrt[n]{R}} \\, dx$. Still less does it enable us to find the sum of such integrals as $\\int \\phi(R) \\, dx$, $R$ being as before an entire polynomial†; and $\\phi$ any function whatever. This is the problem to the solution of which the following pages will be dedicated.\n\nI may be here permitted to mention, that Abel's theorem was unknown to me until some years after its publication, and that these Researches were nearly completed before I was acquainted with it. I have, however, made no alteration in them, but have chosen to present the subject in the manner in which it originally occurred to me.\n\nI am not aware that Mr. Abel has left any memorial of the successive steps of reasoning by which he arrived at his theorem. Probably they were very different from those which I have employed, and therefore I have detailed at some length my method of investigation, beginning with the first rudiments of the theory at which I afterwards arrived.\n\n§ 2.\n\nIt was remarked by the earliest inventors of the integral calculus, that there was a mutual dependence between the two integrals $\\int y \\, dx$ and $\\int x \\, dy$, so that if the one were given the other became known, by virtue of the equation\n\n$$\\int x \\, dy + \\int y \\, dx = xy + C.$$  \n\nIf therefore one of these forms happened to be more easy of integration than the other, they directed it to be substituted for it.\n\n* Crellé's Journal, vol. xii. p. 89. Berlin, 1834.\n\n† By \"polynomial\" I here understand an expression containing at least two different powers of $x$.\nThere is, however, one case in which no alteration is produced by this substitution, and that is when the variable \\( x \\) is the same function of \\( y \\) that \\( y \\) is of \\( x \\); or when \\( x = \\phi y, \\ y = \\phi x \\). For then the integral \\( \\int y \\ dx \\) or \\( \\int \\phi x \\ dx \\) has the same form with \\( \\int x \\ dy \\) or \\( \\int \\phi y \\ dy \\).\n\nIn this case therefore\n\n\\[\n\\int \\phi x \\ dx + \\int \\phi y \\ dy = xy + C.\n\\]\n\nThis equation holds good whether \\( \\int \\phi x \\ dx \\) can be integrated in finite terms, or whether it cannot.\n\nThe equations \\( x = \\phi y \\) and \\( y = \\phi x \\), manifestly imply that a symmetrical equation exists between \\( x \\) and \\( y \\), and its symmetry is the only requisite condition. In other respects it may be any whatever.\n\nNotwithstanding the simplicity of this reasoning, it does not appear that any mathematician before Fagnani clearly perceived the important consequences which might be deduced from it. But he has obtained from it the following important theorem respecting the arcs of the hyperbola.\n\nIf \\( x \\) be the abscissa of a hyperbola whose principal semi-axis \\( = 1 \\), its arc\n\n\\[\n= \\int d x \\sqrt{\\frac{e^2 x^2 - 1}{x^2 - 1}},\n\\]\n\nwhere \\( e \\) is the eccentricity, or the distance between the centre and focus.\n\nLet \\( y \\) be another abscissa, so related to the former that\n\n\\[\ne y = \\sqrt{\\frac{e^2 x^2 - 1}{x^2 - 1}},\n\\]\n\nwhence\n\n\\[\ne^2 x^2 y^2 = e^2 (x^2 + y^2) - 1.\n\\]\n\nThis equation being symmetrical with respect to \\( x \\) and \\( y \\), it follows that those letters may be permuted,\n\n\\[\n\\therefore e x = \\sqrt{\\frac{e^2 y^2 - 1}{y^2 - 1}}.\n\\]\n\nMultiplying these equations respectively by \\( d x \\) and \\( d y \\), and then adding them,\n\n\\[\ne y \\ dx + e x \\ dy = dx \\sqrt{\\frac{e^2 x^2 - 1}{x^2 - 1}} + dy \\sqrt{\\frac{e^2 y^2 - 1}{y^2 - 1}}.\n\\]\n\n\\[\n\\therefore e x y + C = \\int d x \\sqrt{\\frac{e^2 x^2 - 1}{x^2 - 1}} + \\int d y \\sqrt{\\frac{e^2 y^2 - 1}{y^2 - 1}},\n\\]\n\nwhich is the theorem in question.\n\nSince the arc of an ellipse may also be expressed by the formula \\( \\int d x \\sqrt{\\frac{e^2 x^2 - 1}{x^2 - 1}} \\),\n\nit may be asked whether the theorem applies to the ellipse, or to the hyperbola, or to both curves?\nLet us therefore return to the equation\n\n\\[ e^2 x^2 y^2 = e^2 (x^2 + y^2) - 1, \\]\n\nwhence\n\n\\[ -(x^2 + y^2) + x^2 y^2 = -\\frac{1}{e^2} \\]\n\n\\[ (1 - x^2)(1 - y^2) = 1 - \\frac{1}{e^2}. \\]\n\nIn the ellipse the abscissæ \\( x, y \\) are necessarily both less than 1, and in the hyperbola they are both greater than 1. Therefore in either case the product \\((1 - x^2)(1 - y^2)\\) is a positive quantity, \\(\\therefore 1 - \\frac{1}{e^2}\\) must be a positive quantity, which gives \\(1 > \\frac{1}{e^2}\\), or \\(e > 1\\). This condition obtains in the hyperbola but not in the ellipse, therefore the theorem is not applicable to the latter. An analogous theorem, however, exists for the ellipse, which I shall not now stop to examine.\n\nIn imitation of the above proceeding, let us make the more general supposition\n\n\\[ ey = \\left( \\frac{e^n x^n - 1}{x^n - 1} \\right)^{\\frac{1}{n}}, \\]\n\nwhence\n\n\\[ e^n x^n y^n = e^n (x^n + y^n) - 1, \\]\n\na symmetrical equation;\n\n\\[ \\therefore ex = \\left( \\frac{e^n y^n - 1}{y^n - 1} \\right)^{\\frac{1}{n}}. \\]\n\nProceeding as before, we find\n\n\\[ ey + C = \\int \\left( \\frac{e^n x^n - 1}{x^n - 1} \\right)^{\\frac{1}{n}} dx + \\int \\left( \\frac{e^n y^n - 1}{y^n - 1} \\right)^{\\frac{1}{n}} dy \\]\n\n\\[ = S \\int \\left( \\frac{e^n x^n - 1}{x^n - 1} \\right)^{\\frac{1}{n}} dx, \\]\n\nwhere the notation \\( S \\int \\) is employed to express with brevity the sum of two (or any number) of similar integrals.\n\nThe sums of many other integrals might be found in the same manner; but I proceed to more general inquiries.\n\n§ 3.\n\nThe first idea of a more extended method occurred to me about fifteen years ago, when pursuing mathematical studies at Cambridge; and it was suggested by an attentive consideration of the process by which Fagnani had rectified the hyperbola, as mentioned in the preceding section. The question occurred to me, whether it might not be possible to combine three integrals in a similar manner, by supposing two symmetrical equations to exist between three variables?\nSince we have\n\n\\[ x y z + C = \\int y z \\, dx + \\int x z \\, dy + \\int x y \\, dz, \\]\n\nif we suppose any two equations to exist between the variables, then \\( y \\) and \\( z \\) are functions of \\( x \\) which assume definite values when \\( x \\) is given. Therefore also the product \\( y z \\) is a function of \\( x \\), which may be called \\( \\phi x \\).\n\nIf now the two equations are symmetrical, it follows that the letters \\( x, y, z \\) may be permuted; which gives \\( x z = \\phi y \\), and \\( x y = \\phi z \\);\n\n\\[\n\\begin{align*}\nx y z + C &= \\int \\phi x \\, dx + \\int \\phi y \\, dy + \\int \\phi z \\, dz \\\\\n&= S \\int \\phi x \\, dx.\n\\end{align*}\n\\]\n\nIt is evident that this reasoning may be extended to any number \\( n \\) of variables between which there exist \\( n - 1 \\) symmetrical equations, which circumstance renders them all similar functions of each other.\n\nLet \\( r \\) designate their product \\( x y z \\ldots \\), and therefore \\( \\frac{r}{x} = y z \\ldots \\), or the product of all except \\( x \\).\n\n\\[\n\\begin{align*}\nr + C &= \\int \\frac{r}{x} \\, dx + \\int \\frac{r}{y} \\, dy + \\ldots, &c.\n\\end{align*}\n\\]\n\nBut if \\( \\frac{r}{x} = \\phi x \\), we have by merely permuting the letters,\n\n\\[\n\\begin{align*}\n\\frac{r}{y} &= \\phi y, \\frac{r}{z} = \\phi z, &c.\n\\end{align*}\n\\]\n\nTherefore\n\n\\[\n\\begin{align*}\nr + C &= \\int \\phi x \\cdot dx + \\int \\phi y \\cdot dy + \\ldots, &c. \\\\\n&= S \\int \\phi x \\cdot dx. \\quad (A.)\n\\end{align*}\n\\]\n\nThis equation I first obtained in the year 1821, but not having leisure at that time to pursue the subject much further, I contented myself with making a note of it as being a subject that deserved to be further examined into. I afterwards found it to be the key, as it were, of the whole method.\n\nIn the year 1825 I resumed this investigation, and endeavoured, by the trial of various forms of symmetrical equations between the variables, to see whether this method would lead to new results, or whether, on the contrary, it would turn out to be a mere variation of the methods in common use.\n\nI here give the results of some of these early trials, just as I find them in the original papers.\n\n**Ex. 1.** Let the 2 symmetrical equations be\n\n(1.) \\( x + y + z = a \\)\n\n(2.) \\( x^2 + y^2 + z^2 = b^2 \\),\n\n\\( a \\) and \\( b^2 \\) being constants.\nThese give\n\n\\[ \\varphi x \\text{ or } y z = \\frac{a^2 - b^2}{2} - ax + x^2. \\]\n\nAnd theorem A. gives\n\n(3.) \\( xy z + C = \\int \\varphi x \\, dx + \\int \\varphi y \\, dy + \\int \\varphi z \\, dz. \\)\n\nNow here it is easy to verify the theorem, because \\( \\int \\varphi x \\, dx \\) is known, viz.\n\n\\[ \\int \\varphi x \\, dx = \\frac{a^2 - b^2}{2} x - \\frac{a}{2} x^2 + \\frac{x^3}{3}, \\]\n\nand similarly with respect to \\( \\int \\varphi y \\, dy \\) and \\( \\int \\varphi z \\, dz \\); \\( \\therefore \\) by addition,\n\n\\[ 8 \\int \\varphi x \\, dx = \\frac{a^2 - b^2}{2} (x + y + z) - \\frac{a}{2} (x^2 + y^2 + z^2) + \\frac{x^3 + y^3 + z^3}{3}, \\]\n\nor, by help of equations (1.) and (2.), \n\n\\[ 8 \\int \\varphi x \\cdot dx = \\text{const.} + \\frac{x^3 + y^3 + z^3}{3}. \\]\n\nAlthough this result differs at first sight from that given by equation (3.), \n\n\\[ 8 \\int \\varphi x \\, dx = \\text{const.} + xy z, \\]\n\nyet it is easy to see that they are identical. For since\n\n\\[ x + y + z = \\text{const.}, \\text{ by equation (1.)}, \\]\n\nand\n\n\\[ x^2 + y^2 + z^2 = \\text{const.}, \\text{ by equation (2.)}, \\]\n\nit follows as a necessary consequence that\n\n\\[ \\frac{x^3 + y^3 + z^3}{3} = xy z + \\text{const.}, \\]\n\nwhich verifies the theorem in this case.\n\nIn the examples which follow next I shall suppose one of the given equations to be\n\n\\[ x + y + z = 0. \\]\n\nEx. 2. Let the other equation be \\((x^2 - 1)(y^2 - 1)(z^2 - 1) = -1\\), we find\n\n\\[ \\varphi x, \\text{ or } y z = -1 + \\sqrt{\\frac{1 + x^2 - x^4}{1 - x^2}}. \\]\n\nEx. 3. Let \\(x^4 + y^4 + z^4 = 2xy z\\), we find\n\n\\[ 2yz = 2x^2 + x + \\sqrt{4x^3 + x^2} = 2\\varphi x. \\]\n\nEx. 4. Let \\(x^5 + y^5 + z^5 = -5\\), we find\n\n\\[ yz = \\frac{x^2}{2} + \\sqrt{\\frac{1}{x} + \\frac{x^4}{4}} = \\varphi x. \\]\n\nIn each of these cases therefore we find the sum of three integrals of the form \\( \\int \\varphi x \\cdot dx \\) to be equal to \\( xy z + C \\).\nBefore going further it may be well to adopt, for the sake of brevity, the following notation.\n\nLet there be any number of variables, three for example; then the sum of their \\( n \\)th powers or \\( x^n + y^n + z^n \\) may be briefly written \\( Sx^n \\), and similarly if \\( f(x) \\) be any function of \\( x \\), \\( Sf(x) \\) stands for the sum of \\( f(x) + f(y) + f(z) \\). Also \\( Sxy \\) means \\( xy + xz + yz \\). And in general\n\n\\[\nSf(x,y) = f(x,y) + f(y,x) + f(x,z) + f(z,x) + f(y,z) + f(z,y),\n\\]\n\nbeing the sum of all the permutations of the letters. A few examples will render this notation familiar.\n\nLet there be 3 variables, then\n\n\\[\nSx = x + y + z \\\\\nSxy = xy + xz + yz \\\\\nSx^2y = x^2y + y^2x + x^2z + z^2x + y^2z + z^2y \\\\\nSx^2y^2 = x^2y^2 + x^2z^2 + y^2z^2.\n\\]\n\nLet \\( r = xyz \\).\n\n\\[\nSr = yz + xz + xy = Sxy \\\\\n\\frac{1}{r} = \\frac{1}{r} Sxy \\\\\n\\frac{1}{r^3} = \\frac{1}{r^3} Sx^2y^2 \\\\\n\\frac{1}{r^n} = \\frac{1}{r^n} Sax^nyn, \\text{&c. &c.}\n\\]\n\nLet there be 5 variables, \\( u, v, x, y, z \\), then\n\n\\[\nSuvxy = uvxy + uvxz + uvyz + uxyz + vxyz, \\text{&c. &c. &c.}\n\\]\n\nThe greater the number of the variables, the greater is the advantage of this abbreviated notation.\n\nTo resume our examples:\n\n**Ex. 5.**—Let \\( Sx^2y^2 + axyz + bSxy = c \\). Then supposing, as before, that \\( x + y + z = 0 \\), we find\n\n\\[\n2yz = 2x^2 - ax - b + \\sqrt{(4c + b^2) + 2abx + a^2x^2 - 4ax^3}.\n\\]\n\nBy properly determining the constants \\( a, b, c \\), this radical may be made to agree with any proposed cubic \\( \\sqrt{x^3 + ax^2 + bx + c} \\).\n\n**Ex. 6.**—Let \\( x^6 + y^6 + z^6 = 0 \\), or \\( Sx^6 = 0 \\). Here \\( yz \\) or \\( \\varphi x \\) is an implicit function of \\( x \\), only determinable by the solution of the cubic equation\n\n\\[\n(m - x^2)^3 = \\frac{3}{2} x^2 m^2,\n\\]\n\nwhere \\( m = yz \\).\nNotwithstanding the complicated nature of the function $\\phi x$, we still have\n\n$$S \\int \\phi x \\cdot dx = xyz + C.$$  \n\nBut the most interesting result was obtained by combining the equations\n\n$$x + y + z = 0$$\n\n$$xy + xz + yz = -\\frac{x^2 y^2 z^2}{4};$$\n\nor, in the compendious notation, putting $xyz = r$,\n\n$$Sx = 0 \\quad Sxy = \\frac{-r^2}{4};$$\n\nwhence\n\n$$yz = \\frac{2\\sqrt{1 + x^4}}{x^2} - \\frac{2}{x^2} = \\phi x,$$\n\nand by the general theorem A\n\n$$xyz + C = S \\int \\phi x \\cdot dx. \\quad \\ldots \\ldots \\ldots \\ldots (1.)$$\n\nBut $\\int \\phi x \\cdot dx$ consists of two parts, of which the latter is $\\int \\frac{-2dx}{x^3} = \\frac{2}{x}$. Therefore the sum of three such portions $= \\frac{2}{x} + \\frac{2}{y} + \\frac{2}{z} = 2S \\frac{1}{x} = \\frac{2Sxy}{r} = \\frac{-r}{2}$; since by hypothesis $Sxy = \\frac{-r^2}{4}$.\n\nHence if we put\n\n$$\\int \\frac{\\sqrt{1 + x^4}}{x^2} \\cdot dx = \\int \\psi x \\cdot dx,$$\n\nequation (1.) becomes\n\n$$r + C = 2S \\int \\psi x \\cdot dx - \\frac{r}{2};$$\n\nwhence\n\n$$S \\int \\psi x \\cdot dx = \\frac{3}{4} r + \\text{const.}$$\n\nNow this result is highly deserving of attention; for the integral which we have here called $\\int \\psi x \\cdot dx = \\int \\frac{\\sqrt{1 + x^4}}{x^2} \\cdot dx$, is no other than the arc of an equilateral hyperbola whose abscissa is $x$, the equation of the curve being referred to its asymptotes. When I arrived at this result, I immediately perceived that (provided there were no error in the reasoning, of which I at first entertained some doubts,) it was an entirely new and undiscovered property of the hyperbola. I therefore proceeded to verify it by calculating numerical examples.\n\nThe theorem may be stated thus: If three abscissae of an equilateral hyperbola verify the equations $Sx = 0$, $Sxy = \\frac{-r^2}{4}$, the sum of the arcs subtended by those abscissae $= \\frac{3}{4} r + \\text{const.}$ In order to eliminate the constant, the value of which was unknown, I supposed one of the abscissae $x$ to assume some other value $x'$, and there-\nfore a corresponding change to take place with respect to \\( y \\) and \\( z \\) (since they are functions of \\( x \\)). These new values may be called \\( y' \\) and \\( z' \\).\n\nAt the same time the product \\( xyz = r \\) is changed to \\( x'y'z' = r' \\); and the first set of arcs, which may be denoted by \\( A \\), are changed for a second set, which may be denoted by \\( B \\).\n\nNow the original equation gives, sum of arcs \\( A = \\frac{3}{4}r + C \\), and the changed equation gives, sum of arcs \\( B = \\frac{3}{4}r' + C \\); \\( \\therefore \\) by subtraction, sum of arcs \\( A - \\) sum of arcs \\( B = \\frac{3}{4}(r - r') \\), in which result the constant is eliminated.\n\nThe accompanying figure 1. represents two opposite equilateral hyperbolas, with their asymptotes. \\( C \\) is the centre, and origin of the abscissæ \\( CX = x, CY = y, CZ = z \\), of which the latter must be negative (supposing the two former positive), by reason of the equation \\( x + y + z = 0 \\). Therefore it belongs to the opposite hyperbola. If \\( XP \\) is the ordinate corresponding to the abscissa \\( CX \\), the equation of the curve is \\( CX \\cdot XP = 1 \\), and the arc subtended by \\( CX \\) is the infinite arc \\( OP \\).\n\nFig. 2. represents the abscissa \\( CX = x \\), both in its original and in its altered state when it has become \\( CX' = x' \\). In the former case it subtends the infinite arc \\( OP \\), and in the latter case the infinite arc \\( OP' \\). But in taking the difference there remains the portion of abscissa \\( XX' \\) subtended by the arc \\( PP' \\), which is a finite quantity, and thus the embarrassing consideration of the infinite arcs is avoided.\n\nNow the sum of arcs \\( A - \\) sum of arcs \\( B = \\) sum of three limited arcs, of which \\( P P' \\) is one, and the others subtend the portions of abscissæ \\( YY' \\) and \\( ZZ' \\). Denoting these arcs by \\( K \\), we have this equation in finite terms:\n\n\\[\n\\text{Sum of arcs } K = \\frac{3}{4}(r - r').\n\\]\n\nNow in order to put this equation to the test of numerical computation, it is requisite to find three quantities that verify the equations\n\n\\[\nSx = 0 \\quad Sxy = \\frac{-r^2}{4}\n\\]\n\nSuppose, therefore,\n\n\\[\nx = 1 \\\\\ny = 1.7535 \\\\\nz = -2.7535,\n\\]\n\nwhence\n\n\\[\nxyz = -4.8281 = r.\n\\]\n\nThe equations are satisfied by these values, and also by the following:\n\n\\[\nx' = 1.1 \\\\\ny' = 1.5826 \\\\\nz' = -2.6826,\n\\]\nwhence\n\n\\[ x' y' z' = -4.670 = r'. \\]\n\n\\[\\begin{align*}\n[4.] & \\quad \\therefore x' - x = 0.1 \\\\\n& \\quad y' - y = -0.1709 \\\\\n& \\quad z' - z = 0.0709 \\\\\n& \\quad r' - r = 0.1581.\n\\end{align*}\\]\n\nNow we can, without difficulty, calculate the approximate value of the arc (P P' in fig. 2.) subtended by the portion of abscissa \\(x' - x\\) (X X' in the figure). Calling this the arc \\((x)\\), we have\n\n\\[ \\text{Arc}(x) = 0.1351 \\]\n\\[ \\text{Arc}(y) = 0.1817 \\]\n\\[ \\text{Arc}(z) = 0.0715. \\]\n\nAnd according to the theorem we ought to have\n\n\\[ \\text{Sum of arcs} = \\frac{3}{4} (r' - r) = 0.118. \\]\n\nBut in this example, arc \\((x)\\) is to be accounted negative. Therefore we have\n\n\\[ \\text{Arc}(y) + \\text{Arc}(z) = 0.253 \\]\n\\[ - \\text{Arc}(x) = 0.135 \\]\n\\[ \\text{Sum} = 0.118 \\]\n\nwhich is in accordance with the theorem.\n\nSecond example.—Suppose, as before,\n\n\\[ x = 1 \\]\n\\[ y = 1.7535 \\]\n\\[ z = -2.7535, \\]\n\nwhence\n\n\\[ x y z = -4.8281. \\]\n\nAnd also\n\n\\[ x' = 2 \\]\n\\[ y' = 0.8875 \\]\n\\[ z' = -2.8875, \\]\n\nwhence\n\n\\[ x' y' z' = -5.1253; \\]\n\nboth of which systems of values satisfy the given equations of condition.\n\n\\[\\begin{align*}\n[5.] & \\quad \\therefore x' - x = 1 \\\\\n& \\quad y' - y = -0.866 \\\\\n& \\quad z' - z = -0.134 \\\\\n& \\quad r' - r = -0.297.\n\\end{align*}\\]\n\nBy calculation we find\n\n\\[ \\text{Arc}(x) = 1.1319 \\]\n\\[ \\text{Arc}(y) = 1.0443 \\]\n\\[ \\text{Arc}(z) = 0.1350. \\]\n\nBut in this example both arc \\((x)\\) and arc \\((z)\\) are negative. Therefore we have\n\\[- \\text{Arc}(x) - \\text{Arc}(z) = -1.267\\]\n\\[+ \\text{Arc}(y) = +1.044\\]\n\\[\\text{Sum} = -0.223\\]\n\nAlso\n\n\\[r' - r = -0.297\\]\n\\[\\therefore \\frac{3}{4} (r' - r) = -0.223\\]\n\nin accordance with the theorem.\n\nI had at first some difficulty to perceive the reason why some of the arcs were to be considered negative rather than the others. This question was one of a novel nature, which had not hitherto occurred to analysts, and therefore no solution of it was to be met with in books. On the other hand, to leave so essential a point without any demonstration was unsatisfactory. But the following considerations appeared to afford an explanation of this fact.\n\nIn the first example, since \\(x + y + z = 0\\), and both \\(x\\) and \\(y\\) are positive quantities, \\(z\\) must be negative. Therefore \\(xy\\) is positive, but \\(xz\\) and \\(yz\\) are negative.\n\nNow we have\n\n\\[\\frac{yz}{2} = \\frac{\\sqrt{1 + x^4} - 1}{x^2},\\]\n\nwhich therefore must be negative: \\(\\therefore\\) also \\(\\sqrt{1 + x^4} - 1\\) must be negative. But this quantity would necessarily be positive if the radical had a positive sign. Therefore the radical must have a negative sign.\n\nReasoning in the same manner, because \\(\\frac{xz}{2} = \\frac{\\sqrt{1 + y^4} - 1}{y^2}\\), this radical has necessarily a negative sign; and because \\(\\frac{xy}{2} = \\frac{\\sqrt{1 + z^4} - 1}{z^2}\\), this radical has a positive sign.\n\nAttributing, therefore, these signs to the radicals, the three hyperbolic arcs are respectively,\n\n\\[-\\int \\frac{dx}{x^2} \\sqrt{1 + x^4}, \\quad -\\int \\frac{dy}{y^2} \\sqrt{1 + y^4}, \\quad +\\int \\frac{dz}{z^2} \\sqrt{1 + z^4}.\\]\n\nOn the other hand, during the change of \\(x, y, z\\) to \\(x', y', z'\\) respectively, we have seen that \\(x\\) and \\(z\\) increase while \\(y\\) diminishes (see equations [4.]); \\(\\therefore dx\\) and \\(dz\\) are to be accounted positive, and \\(dy\\) negative. This consideration renders it necessary to write\n\n\\[[6.] \\quad -\\int \\frac{dx}{x^2} \\sqrt{1 + x^4}, \\quad +\\int \\frac{dy}{y^2} \\sqrt{1 + y^4}, \\quad +\\int \\frac{dz}{z^2} \\sqrt{1 + z^4}.\\]\n\nAnd thus the assertion that arc \\((x)\\) is to be considered negative in this example is justified.\n\nSecond example.—Here the reasoning remains the same as far as regards the signs of the different radicals; but it appears from the equations [5.], that while \\(x\\) increases, both \\(y\\) and \\(z\\) diminish, \\(\\therefore dx\\) is positive, and \\(dy\\) and \\(dz\\) are negative. Therefore the only difference between this example and the former respects the sign of \\(dz\\). Therefore equation [6.] must be written\nwhich justifies the assertion, that in this example arcs \\( (x) \\) and \\( (z) \\) are to be accounted negative, and arc \\( (y) \\) positive.\n\nPerhaps this reasoning may not be altogether free from objection: I wish it, therefore, to be remembered that I am not giving it here as being the most convenient method of determining the signs of the arcs, but merely as being the reasoning I employed at the time* when I first met with this theorem.\n\nThis theorem shows that three hyperbolic arcs may be determined in an infinity of ways, so that their sum may be an algebraic quantity. At the same time it shows that one of these arcs cannot be supposed always to be 0, so that Fagnani's theorem respecting the sum of two arcs is not an instance or particular case of this. I have dwelt at some length on this theorem, because the theory of the conic sections has always been regarded as so important by mathematicians that any considerable addition to it is thought deserving of attention.\n\nI now proceed to other results which presented themselves in the course of this inquiry.\n\nStill continuing to suppose the variables to be three in number, it is allowable to suppose between them any two symmetrical equations whatever; and thence if we can deduce the value of \\( yz \\) or \\( \\varphi x \\) in terms of \\( x \\) alone, we may apply the general theorem A.\n\n**Ex. 1.** Let \\( Sx = a \\), and \\( Sxy = \\left( \\frac{xyz}{2} \\right)^2 \\), we find\n\n\\[\n\\frac{yz}{2} = \\frac{1}{x^2} + \\frac{\\sqrt{1 - x^4 + ax^3}}{x^3}.\n\\]\n\n**Ex. 2.** Let \\( Sx = a \\), and \\( Sxy = \\sqrt{2b} \\cdot xyz \\), we find\n\n\\[\nyz = x^2 - a - b \\cdot x + \\sqrt{2b} \\cdot x^3 + (b^2 - 2ab)x^2.\n\\]\n\n**Ex. 3.** Let \\( \\sqrt{x} + \\sqrt{y} + \\sqrt{z} = \\sqrt{a} \\) (or \\( S\\sqrt{x} = \\sqrt{a} \\)), and let \\( Sx = b \\), we find\n\n\\[\n\\sqrt{yz} = \\frac{a - b}{2} - \\sqrt{ax} + x = f x,\n\\]\n\nwhence\n\n\\[\nyz = \\varphi x = [fx]^2.\n\\]\n\nA great variety of different suppositions of this sort may be made; but if the resulting function \\( \\varphi x \\) should become too complicated, little practical advantage would be derived from the knowledge of its properties. I therefore thought of another method of obtaining this function, by means of what may be termed \"changing the conditions.\" Thus let the original equations of condition be\n\n\\[\nx + y + z = 0, \\quad \\text{and} \\quad xy + xz + yz = -1,\n\\]\n\n* 1825.\nwhence this equation results,\n\n\\[ yz = x^2 - 1. \\]\n\nNow for \\( x, y, z \\) write their cubes (both in the original and in the resulting equation), and they become\n\n\\[\n[7.] \\quad x^3 + y^3 + z^3 = 0 \\\\\nx^3 y^3 + x^3 z^3 + y^3 z^3 = -1\n\\]\n\nand\n\n\\[ y^3 z^3 = x^6 - 1. \\]\n\nTaking the cube root of this, we have\n\n\\[ yz = \\sqrt[3]{x^6 - 1}. \\]\n\nWhence it follows that the sum of three integrals\n\n\\[ \\int dx \\sqrt[3]{x^6 - 1} + \\int dy \\sqrt[3]{y^6 - 1} + \\int dz \\sqrt[3]{z^6 - 1} = xyz + C, \\]\n\nwhenever \\( x, y, z \\) satisfy the two given equations of condition [7.], which may be briefly written\n\n\\[ Sx^3 = 0 \\quad Sy^3 = -1. \\]\n\nHere we changed the conditions, by writing \\( x^3 \\) for \\( x \\). We might have written \\( x^n \\) for \\( x \\), and thereby obtained a more general result*. Even values of \\( n \\) must, however, be excluded, because the equation \\( x^n + y^n + z^n = 0 \\) would otherwise be impossible.\n\n**Ex. 4.** Let \\( Sx = a \\), and \\( S \\frac{1}{x} = \\frac{1}{b} \\), whence\n\n\\[ yz = \\frac{abx - bx^2}{x - b}. \\]\n\nNow if we write for \\( x, y, z, a, b \\), their square roots, these three equations become\n\n\\[ \\sqrt{x} + \\sqrt{y} + \\sqrt{z} = \\sqrt{a}, \\]\n\\[ \\sqrt{\\frac{1}{x}} + \\sqrt{\\frac{1}{y}} + \\sqrt{\\frac{1}{z}} = \\sqrt{\\frac{1}{b}}, \\]\n\nand\n\n\\[ \\sqrt{yz} = \\frac{\\sqrt{abx} - \\sqrt{b} \\cdot x}{\\sqrt{x} - \\sqrt{b}} = f(x), \\]\n\nwhence\n\n\\[ yz = \\varphi(x) = [fx]^2. \\]\n\nMany interesting theorems may be obtained by this method of \"changing the original conditions,\" but these examples of it will suffice for the present.\n\nI now perceived that the hypothesis upon which my method was grounded, viz. that \\( n - 1 \\) symmetrical equations existed between \\( n \\) variables, was the same thing as to suppose that these variables were the roots of an equation of \\( n \\) dimensions, one of whose coefficients at least was variable, the others being either constants, or functions of the variable one. This consideration introduced a great degree of clearness and\n\n* Viz. the sum of three integrals, like \\( \\int dx \\sqrt[3]{x^{2n} - 1} \\).\nsimplicity into the subject, besides facilitating in no ordinary degree the progress of research. For instance, suppose there are 3 variables, and let \\( x + y + z = p \\), \\( xy + xz + yz = q \\) and \\( xyz = r \\), then \\( x, y, z \\) are the roots of the equation\n\n\\[\nu^3 - pu^2 + qu - r = 0,\n\\]\n\nwhere the variable \\( u \\) denotes indifferently either of the variables \\( x, y, \\) or \\( z \\). This new letter \\( u \\) is only introduced for the sake of clearness, since we may equally well say that \\( x, y, z \\) are the roots of the equation\n\n\\[\nx^3 - px^2 + qx - r = 0,\n\\]\n\nor of\n\n\\[\ny^3 - py^2 + qy - r = 0, \\text{ &c.}\n\\]\n\nThis latter mode of expression is often more convenient. Now the function \\( \\phi x \\), which we wish to determine,\n\n\\[\nyz = \\frac{xyz}{x} = \\frac{r}{x};\n\\]\n\nand since \\( p, q \\) are here supposed to be given functions of \\( r \\), we may find the value of \\( \\frac{r}{x} \\) in terms of \\( x \\), provided we can solve the algebraic equation\n\n\\[\nx^3 - px^2 + qx - r = 0,\n\\]\n\nwith respect to \\( r \\).\n\n**Example.** Let us resume the question concerning the sum of 3 arcs in the equilateral hyperbola. The equations of condition were\n\n\\[\nx + y + z = 0,\n\\]\n\n\\[\nxy + xz + yz = \\frac{-x^2 y^2 z^2}{4},\n\\]\n\nor\n\n\\[\np = 0, q = \\frac{-r^2}{4},\n\\]\n\n\\(\\therefore x, y, z\\) are the roots of\n\n\\[\nx^3 - \\frac{r^2}{4} x - r = 0.\n\\]\n\nThis equation (arranged according to the powers of \\( r \\)) is\n\n\\[\n\\frac{-x}{4} x^2 - r + x^3 = 0,\n\\]\n\nor\n\n\\[\nr^2 + \\frac{4}{x} r - 4 x^2 = 0,\n\\]\n\nwhence\n\n\\[\nr = \\frac{-2}{x} + 2 \\sqrt{x^2 + \\frac{1}{x^2}},\n\\]\n\nand\n\n\\[\n\\frac{r}{x} = \\frac{-2}{x^2} + \\frac{2 \\sqrt{1 + x^4}}{x^2} = \\phi x,\n\\]\n\nwhich agrees with the former result. But now we are able to point out with clearness the limits of the possibility of the theorem. For the cubic equation\n\n\\[\nx^3 - \\frac{r^2}{4} x - r = 0\n\\]\nbeing compared with the form\n\n\\[ x^3 - ax + b = 0, \\]\n\nmust have impossible roots when \\( \\frac{b^2}{4} > \\frac{a^3}{27} \\), or when \\( \\frac{r^2}{4} > \\frac{r^6}{64 \\times 27} \\), or \\( 1 > \\frac{r^4}{16 \\times 27} \\), or \\( 16 \\times 27 > r^4 \\). Hence it appears that there are impossible roots whenever \\( r \\) is less than\n\n\\[ \\sqrt[4]{16 \\times 27} = 2 \\sqrt[4]{27} = \\pm 4.559. \\]\n\nAccordingly in our numerical examples it will be seen that the values* of \\( r \\) are not contained within these limits.\n\nAnother example. We have found (page 183. Ex. 3.) that the suppositions \\( Sx = 0 \\), \\( Sx^4 = 2r \\), give\n\n\\[ 2\\varphi x = 2x^2 + x + \\sqrt{4x^3 + x^2}. \\]\n\nHere \\( x, y, z \\) are roots of \\( x^3 + qx - r = 0 \\), and we easily find from the doctrine of equations that\n\n\\[ Sx^4 = 2q^2, \\quad \\therefore 2q^2 = 2r, \\quad \\therefore q^2 = r. \\]\n\nTherefore \\( x + qx - q^2 = 0 \\). Solving this quadratic equation with respect to \\( q \\) we have\n\n\\[ q = \\frac{x}{2} + \\frac{1}{2} \\sqrt{x^2 + 4x^3}. \\]\n\nBut since\n\n\\[ x^3 + qx - r = 0, \\quad \\frac{r}{x} = x^2 + q. \\]\n\n\\[ \\therefore \\frac{2r}{x} = 2x^2 + x + \\sqrt{x^2 + 4x^3} = 2\\varphi x, \\]\n\nwhich agrees with the former result.\n\nAnother example. Let \\( x^3 + qx - r = 0 \\), which gives for the first condition\n\n\\[ Sx = 0. \\]\n\nAnd let the second condition be\n\n\\[ r^2 + cr = q^2 + aq + b, \\]\n\n\\( a, b, c \\) being constants. We find\n\n\\[ \\frac{r}{x} = \\frac{x^2 + \\frac{c}{2}x - \\frac{a}{2} + \\sqrt{X}}{1 - x^2}, \\]\n\nwhere \\( X \\) is a polynomial of 6 dimensions.\n\nNow let the \\( n \\) variables \\( x, y, z \\ldots \\) be roots of \\( x^n - px^{n-1} + \\ldots \\pm r = 0 \\),\n\nwhere I continue to denote the product of all the roots by \\( r \\); we have still \\( \\varphi x = \\frac{r}{x} \\).\n\nLet the coefficients \\( p, \\&c. \\&c. \\) be replaced by their values in terms of \\( r \\) (which are supposed given, by means of \\( n - 1 \\) equations of condition). Then let the equation be arranged according to the powers of \\( r \\), and the solution of it will give the value of \\( r \\) in terms of \\( x \\), and therefore the value of \\( \\frac{r}{x} = \\varphi x \\).\n\n* These were \\( r = -4.83, r = -4.67, r = -5.13. \\)\nNow if it be considered that this method extends to any number whatever of variables, and that the coefficients of the equation may be any functions of each other that we please to make them, it will appear at once how wide a field of inquiry here opens before us. It was the wish to reduce these extensive but rather complicated results to something like a clear and connected system which obliged me to defer the publication of them longer than I should otherwise have wished, by which means I lost the priority which at one time was in my power of announcing the existence of this new branch of analysis; for the results hitherto mentioned, together with many others, which for the sake of brevity I omit, were obtained in the years 1825 and 1826, and consequently two or three years previously to the publication of Abel's theorem. And it will be observed that they comprise large classes of integrals which are not contained in his formula\n\n$$\\int \\frac{P \\, dx}{\\sqrt{R}}.$$  \n\nOf this I have given an instance in the integral,\n\n$$\\int dx \\sqrt[3]{x^6 - 1},$$  \n\nand the more general one,\n\n$$\\int dx \\sqrt{x^{2n} - 1}.$$  \n\nBut an unlimited number of such forms may be found by the method I have pointed out of \"changing the conditions\" at first established between the variables. We may conclude therefore that if $x, y, z \\ldots$ are the roots of an equation of $n$ dimensions, having at least one variable coefficient, and if we can find the function $\\phi x = \\frac{r}{x}$ in terms of $x$, we may thence deduce the algebraic sum of the $n$ integrals,\n\n$$\\int \\phi x \\cdot dx + \\int \\phi y \\cdot dy + \\ldots.$$  \n\nBut the inverse problem still remains. Given the function $\\phi x$, or the integral $\\int \\phi x \\cdot dx$, to find the equation\n\n$$x^n - p x^{n-1} + \\ldots \\pm r = 0,$$\n\nof which $x, y, z \\ldots$ must be roots, in order that $\\int \\phi x \\cdot dx$ may have an algebraic sum?\n\nThis is evidently the most important part of the subject, for in applying the method to practice the form of the function $\\phi x$ is given beforehand. That this research requires methods of its own will appear at once from a simple example.\n\nLet $\\int \\sqrt{1 + x^n} \\cdot dx$ be the proposed integral, where $n$ is any whole number. Let us first suppose\n\n$$\\sqrt{1 + x^n} = \\phi x = \\frac{r}{x}.$$\nThis gives\n\n\\[ r = x \\sqrt{1 + x^n}, \\]\n\nor\n\n\\[ x^n + 2x^2 - r^2 = 0, \\]\n\nan equation, the product of whose roots must be \\( \\pm r^2 \\). But by the hypothesis this product is always represented by \\( r \\). Whence it follows that no solution of the required problem is effected by the supposition \\( \\sqrt{1 + x^n} = \\frac{r}{x} \\). And at the same time we see that in order for any supposition to be successful, it is necessary that the resulting equation, arranged according to the powers of \\( x \\), should have \\( r \\) for its last term.\n\nNow let us remark, that if \\( S \\int \\psi x \\cdot dx \\) has an algebraic sum, then \\( S \\int (\\psi x + x^a) \\cdot dx \\) has likewise an algebraic sum. For it equals the former sum, with the addition of \\( S \\int x^a \\cdot dx \\), or \\( \\frac{1}{a+1} (x^{a+1} + y^{a+1} + z^{a+1} + \\ldots) \\), which is an algebraic quantity.\n\nIn the same way we see that \\( S \\int (\\psi x + m x^a + n x^b + \\ldots) \\cdot dx \\) has an algebraic sum if \\( m, n, a, b, \\) &c. are constants, and if there are any number of such simple terms of the form \\( m x^a \\). Hence if the proposed integral be \\( \\int \\psi x \\cdot dx \\), and the supposition \\( \\varphi x \\) or \\( \\frac{r}{x} = \\psi x \\) does not succeed, we are led to try the suppositions\n\n\\[ \\frac{r}{x} = \\psi x + x, \\quad \\frac{r}{x} = \\psi x + x + x^2, \\text{ &c. &c.} \\]\n\n**Example.** Let the integral \\( \\int \\psi x \\cdot dx = \\int \\sqrt{1 + x^n} \\cdot dx \\) as before. Suppose \\( \\sqrt{1 + x^n} = \\frac{x}{2} + \\sqrt{1 + r} \\), whence we deduce\n\n\\[ x^n - \\frac{x^3}{4} - \\sqrt{1 + r} \\cdot x - r = 0, \\]\n\nan equation which has \\( n \\) roots, whose product is \\( r \\). We also find\n\n\\[ 1 + r = 1 + x^n - x \\sqrt{1 + x^n} + \\frac{x^3}{4}, \\]\n\nwhence\n\n\\[ \\frac{r}{x} = x^{n-1} + \\frac{x}{4} - \\sqrt{1 + x^n}, \\]\n\nor\n\n\\[ \\varphi x = x^{n-1} + \\frac{x}{4} - \\psi x. \\]\n\nAnd therefore since \\( S \\int \\varphi x \\cdot dx \\) has an algebraic sum \\( = r + \\text{const.} \\), it follows that \\( S \\int \\psi x \\cdot dx \\) has an algebraic sum also, viz.\n\\[ S \\int x^{n-1} \\, dx + \\frac{1}{4} S \\int x \\, dx - (r + \\text{const.}) \\]\n\nor\n\n\\[ \\frac{1}{n} S x^n + \\frac{1}{8} S x^2 - (r + \\text{const.}) \\]\n\nBut if the form of the proposed integral \\( \\int \\psi x \\cdot dx \\) is complicated, no doubt it would be difficult to find an equation like\n\n\\[ \\frac{r}{x} = \\pm \\psi x + m x^a + n x^b + \\ldots., \\]\n\nsuch that when developed and arranged according to the powers* of \\( x \\) its last term should be \\( r \\). Probably this is not possible in general. And yet the proposed integrals \\( S \\int \\psi x \\, dx \\) may have an algebraic sum. For hitherto we have tacitly supposed that this algebraic quantity, if it existed, was the product of the variables \\( = r + \\text{const.} \\), since we have derived all our reasonings from the theorem\n\n\\[ xyz \\ldots = \\int yz \\ldots \\, dx + \\int xz \\ldots \\, dy + \\&c. \\]\n\nBut it is evident that the algebraic sum may as well have any other form as the one in question. It may be a constant or any symmetrical combination of the variables. The foundation of our reasoning has therefore hitherto been too limited, and requires to be extended. Let us therefore direct our inquiries to the attainment of a more general method.\n\n§ 4. Exposition of a more general method.\n\nIf \\( x, y, z \\ldots \\) are the roots of any equation,\n\n\\[ x^n - p x^{n-1} + p' x^{n-2} \\ldots = 0, \\]\n\nthen not only the coefficients themselves \\( p, p', p'', \\&c. \\), but also all combinations of them, are symmetrical functions of the roots. Let \\( v \\) be a general symbol denoting any one of these coefficients or of these combinations. Then \\( v \\) may be considered either as a function of all the roots, or of only one of them. And in the latter case this root may be changed for any of the others without causing any alteration in the value of \\( v \\).\n\nExample. Let there be two variables \\( x \\) and \\( y \\), roots of \\( x^2 - vx + 1 = 0 \\), which may be also written \\( y^2 - vy + 1 = 0 \\). Then \\( v \\) if considered as a function of both \\( x \\) and \\( y \\), is equal to \\( x + y \\), the sum of the roots. But if considered as a function of \\( x \\) alone, it is \\( \\frac{1 + x^3}{x} \\). And if considered as a function of \\( y \\) alone, it is \\( \\frac{1 + y^3}{y} \\).\n\n\\[ \\therefore \\frac{1 + x^3}{x} = \\frac{1 + y^3}{y}, \\]\n\n* The coefficient of the highest power of \\( x \\) being always supposed \\( = 1 \\).\nor \\( x \\) may be permuted for \\( y \\). Hence also\n\n\\[\n\\varphi \\cdot \\frac{1 + x^2}{x} = \\varphi \\cdot \\frac{1 + y^2}{y},\n\\]\n\n\\( \\varphi \\) being any function.\n\nQuantities which (like \\( \\varphi \\cdot \\frac{1 + x^2}{x} \\) in this example) are not changed in value by permuting the roots, maybe termed \"symmetrical functions\" of the variables \\( x, y, z, \\&c. \\) or simply \"symmetricals\" of the equation whose roots are \\( x, y, z \\ldots \\). Thus the quantity \\( \\varphi \\left( \\frac{1 + x^2}{x} \\right) \\) is a symmetrical of the equation\n\n\\[\nx^2 - vx + 1 = 0.\n\\]\n\nBut the quantity \\( \\varphi \\left( \\frac{1 - x^2}{x} \\right) \\) is not a symmetrical of it, because \\( \\frac{1 - x^2}{x} \\) is not equal to \\( \\frac{1 - y^2}{y} \\).\n\n**Ex. 2.** Let \\( x, y, z \\), be roots of \\( x^3 - vx + 1 = 0 \\), which may also be written \\( y^3 - vy + 1 = 0 \\), or \\( z^3 - vz + 1 = 0 \\), whence\n\n\\[\nv = \\frac{1 + x^3}{x} = \\frac{1 + y^3}{y} = \\frac{1 + z^3}{z},\n\\]\n\nwhence also\n\n\\[\n\\varphi \\cdot \\frac{1 + x^3}{x} = \\varphi \\cdot \\frac{1 + y^3}{y} = \\varphi \\cdot \\frac{1 + z^3}{z}.\n\\]\n\nTherefore the quantity \\( \\varphi \\cdot \\frac{1 + x^3}{x} \\) is a symmetrical of the equation \\( x^3 - vx + 1 = 0 \\); but \\( \\varphi \\cdot \\frac{1 + x^2}{x} \\) is not a symmetrical of it, because \\( \\frac{1 + x^2}{x} \\) is not equal to \\( \\frac{1 + y^2}{y} \\).\n\nThese things being premised, it is evident that the same quantity may be a symmetrical of one equation and not so of another. Therefore the problem arises: Any quantity being given, to find the equation with respect to which it is symmetrical?\n\n**Ex. 1.** Let \\( \\frac{1 + x^2}{x} \\) be the given quantity. Put \\( \\frac{1 + x^3}{x} = v \\), \\( v \\) being a general symbol for any symmetrical quantity:\n\n\\[\n\\therefore x^2 - vx + 1 = 0\n\\]\n\nis the required equation, and the indeterminate \\( v \\) is thereby determined to be the sum of the roots.\n\n**Ex. 2.** Let \\( \\frac{1 + x^3}{x} \\) be the given quantity. Put \\( \\frac{1 + x^3}{x} = v \\):\n\n\\[\n\\therefore x^3 - vx + 1 = 0\n\\]\n\nis the required equation, and \\( -v \\) is thereby determined to be the sum of the products of every two roots*.\n\n---\n\n* **Another example.**—Let \\( \\frac{1 + x + x^2}{1 - x} \\) be the given quantity. Put it \\( = v \\):\n\n\\[\n\\therefore x^2 + (1 + v)x + (1 - v) = 0\n\\]\n\nis the required equation, and \\( (1 + v) \\) is determined to be the sum of the roots \\( x + y \\), and \\( 1 - v \\) their product \\( xy \\). Whence, by eliminating \\( v \\), we find the following relation between \\( x \\) and \\( y \\): \\( xy - (x + y) = 2 \\). This example will be referred to hereafter.\nEx. 3. Let $x + \\sqrt{1 - x^2}$ be the given quantity. Put $x + \\sqrt{1 - x^2} = v$:\n\n$$\\therefore (v - x)^2 = 1 - x^2$$\n\n$$2x^2 - 2vx + (v^2 - 1) = 0$$\n\n$$x^2 - vx + \\frac{v^2 - 1}{2} = 0$$\n\nis the required equation, and $v$ is determined to be the sum of its roots. Also $\\frac{v^2 - 1}{2}$ is equal to their product $xy$. In other words, the equation must be such, that its roots $x, y$, answer the condition $xy = \\frac{(x + y)^2 - 1}{2}$.\n\nEx. 4. Let $x + \\sqrt{\\frac{1}{x}}$ be the given quantity. Put $x + \\sqrt{\\frac{1}{x}} = v$:\n\n$$\\therefore (v - x)^2 = \\frac{1}{x}$$\n\n$$\\therefore x^3 - 2vx^2 + v^2x - 1 = 0$$\n\nis the required equation, which is thereby determined to be a cubic, the product of whose roots = 1, and $v$ is found to be half the sum of the roots.\n\nCase of exception.—It is essential to remark, that when the given quantity contains only one power of $x$, it cannot be a symmetrical. Ex. $\\sqrt{1 + x^n}$ cannot be a symmetrical; for if it could, we should have $\\sqrt{1 + x^n} = \\sqrt{1 + y^n} = \\sqrt{1 + z^n} = &c.$, whence $x = y = z = &c.$; whereas we suppose the roots to be in general all different from one another. With this exception the required equation may be easily found in most cases by putting the given quantity, or $fx = v$. And if the roots of the equation thus found are denoted by $x, y, z, . . . .$, it is an immediate consequence of the hypothesis that $fx = fy = fz = &c.$ Thus in the last example we have\n\n$$x + \\sqrt{\\frac{1}{x}} = y + \\sqrt{\\frac{1}{y}} = z + \\sqrt{\\frac{1}{z}}.$$  \n\nLet us now suppose that $S dx$, the sum of the differentials of the roots, or $dx + dy + dz &c.$, is multiplied by a symmetrical, that is, by one of the above-mentioned quantities $fx$. The product is $fx \\cdot dx + fy \\cdot dy + fz \\cdot dz + &c.$ But in consequence of the equality $fx = fy = fz = &c.$ the result is the same, if the first term is multiplied by $fy$, the second by $fz$, the third by $fx$, and so on. So that the product is $fx \\cdot dx + fy \\cdot dy + fz \\cdot dz + &c.$, which is our abbreviated notation $= Sfx \\cdot dx$.\n\n$$\\therefore fx \\cdot S dx = Sfx \\cdot dx. . . . . . . . . . . . . . . . (1.)$$\n\nThis theorem is of the greatest importance, and will be of constant use in the sequel. It must not be forgotten that it is only true when $fx$ is a symmetrical, and therefore capable of being represented by $v$. Replacing $fx$ by $v$, it becomes $v S dx = Sv dx$. In this form it is self-evident, because $v$ remains the same, however the letters $x, y, z, . . .$ are permuted.\nMore generally, if the quantity $S \\psi x \\cdot dx$, which means $\\psi x \\cdot dx + \\psi y \\cdot dy + \\psi z \\cdot dz + \\&c.$, is multiplied by $f \\cdot x$, the product may be exhibited in the form\n\n$$f \\cdot x \\psi x \\cdot dx + f \\cdot y \\psi y \\cdot dy + f \\cdot z \\psi z \\cdot dz + \\&c.,$$\n\nwhich in our notation is $S f \\cdot x \\psi x \\cdot dx$. Whence the theorem\n\n$$f \\cdot x S \\psi x \\cdot dx = S f \\cdot x \\psi x \\cdot dx,$$\n\nwhich may also be put in the self-evident form\n\n$$v S \\psi x \\cdot dx = S v \\psi x \\cdot dx.$$\n\nEquation (1.) is a corollary from (2.) when $\\psi x = 1$.\n\nThese results may be comprised in a general rule, viz. that whatever be the nature of the differential $\\psi x \\cdot dx$, if we multiply the sum of a series of such quantities, or $S \\psi x \\cdot dx$, by $f \\cdot x$ any function of $x$, the multiplication is effected by introducing $f \\cdot x$ within the sign $S$, provided (and this is the essential condition) that $f \\cdot x$ is a symmetrical of that equation of which all the variables are roots. It is upon this principle that the method which I am about to explain chiefly reposes.\n\nSuppose $\\int X \\cdot dx$ to be the proposed integral, $X$ being any function of $x$. In the first place we have to determine the number of the other variables $y, z, \\&c.$, and also the nature of the equation $x^n - p \\cdot x^{n-1} + \\&c. = 0$, of which they are roots. And this may in general be accomplished by the following process: Assume $X$ to be a symmetrical of this unknown equation, or that $X = v$; then if this equation $X = v$ can be cleared of radicals, &c., (as in examples 1, 2, 3, 4,) it may be ultimately reduced to the form\n\n$$x^n - p \\cdot x^{n-1} + p' \\cdot x^{n-2} \\ldots \\ldots = 0,$$\n\nwhere $p, p', p''$, the coefficients, are either constants or functions of $v$. The index $n$ of this equation determines the number of the variables.\n\nLet $Y$ be a quantity containing the variable $y$, in the same manner that $X$ contains $x$, and let $Z$ contain $z$ in the same manner, and so on for the other roots. Then $v = X = Y = Z = \\&c.$, in consequence of the hypothesis that $X$ is a symmetrical of this equation. Therefore the sum of the following series of differentials,\n\n$$X \\cdot dx + Y \\cdot dy + Z \\cdot dz + \\&c.,$$\n\nis equal to $X \\cdot (dx + dy + dz + \\&c.)$\n\n$$= X \\cdot S dx = v S dx.$$\n\nNow $S dx = dp$, where $p$ is the coefficient of the second term of the equation\n\n$$x^n - p \\cdot x^{n-1} + p' \\cdot x^{n-2} \\ldots \\ldots = 0;$$\n\nand, as we have before remarked, $p$ is either a constant or a function of $v = \\varphi \\cdot v$.\n\nFirst let it be a constant: then\n\n$$dp = S dx = 0,$$\nwhich gives\n\n\\[ X \\, dx + Y \\, dy + Z \\, dz + \\ldots = v \\, S \\, dx \\]\n\n\\[ = 0, \\]\n\nwhence we deduce the very important consequence\n\n\\[ \\int X \\, dx + \\int Y \\, dy + \\int Z \\, dz + \\ldots = \\text{const.}, \\]\n\nwhich is true, whatever be the nature of the function \\( X \\), provided only that the coefficient \\( p \\) is constant.\n\nSecondly, let \\( p = \\phi v \\),\n\n\\[ \\therefore dp = d \\cdot \\phi v, \\]\n\n\\[ \\therefore X \\, dx + Y \\, dy + Z \\, dz + \\&c. = v \\cdot d \\phi v, \\]\n\n\\[ \\therefore \\int X \\, dx + \\int Y \\, dy + \\int Z \\, dz + \\&c. = \\int v \\cdot d \\phi v; \\]\n\nand therefore the sum of the integrals, or \\( S \\int X \\, dx \\), is known, whenever the formula \\( \\int v \\, d \\phi v \\) is capable of integration; or, which is equivalent, when the form \\( \\int \\phi v \\cdot dv \\) is capable of integration. These consequences flow, with respect to the proposed integral \\( \\int X \\, dx \\), from the supposition that \\( X \\) is a symmetrical of the equation whose roots the variables are. But a much more general method is attainable, by putting the proposed integral under the form \\( \\int \\frac{X}{\\psi x} \\cdot \\psi x \\, dx \\), and then assuming the quantity \\( \\frac{X}{\\psi x} \\) to be a symmetrical of the said equation*.\n\nTherefore \\( \\frac{X}{\\psi x} \\) may be represented by the general symbol \\( v \\), and the proposed integral by \\( \\int v \\cdot \\psi x \\, dx \\).\n\nThe series of differentials\n\n\\[ X \\, dx + Y \\, dy + Z \\, dz + \\&c. \\]\n\nmay therefore be written\n\n\\[ v \\psi x \\, dx + v \\psi y \\, dy + v \\psi z \\, dz + \\&c. \\]\n\n\\[ = v (\\psi x \\, dx + \\psi y \\, dy + \\&c.), \\]\n\nwhich we write\n\n\\[ = v \\, S \\psi x \\, dx. \\]\n\nTherefore, whenever it happens that \\( S \\psi x \\, dx = 0 \\), we have \\( v \\, S \\psi x \\, dx = 0 \\),\n\n\\[ \\therefore \\int X \\, dx + \\int Y \\, dy + \\int Z \\, dz + \\&c. = \\text{const.}: \\]\n\n* Under this new supposition the quantity \\( X \\) of course ceases, in general, to be a symmetrical of the equation.\nand since $\\psi x$ is arbitrary, this condition $S \\psi x dx = 0$ may frequently be realized. But it will be observed, that every change in the form of $\\psi x$ changes the equation between the variables. But if $S \\psi x dx$ is not $= 0$, as it generally is not, it must be a quantity symmetrically composed with respect to all the variables, and therefore a function of $v$, since all the coefficients of the equation are functions of $v$, or constants. Therefore it may be represented by $d.\\phi v$,\n\n$$\\therefore X dx + Y dy + Z dz + &c. = v S \\psi x dx$$\n\n$$= v.d.\\phi v$$\n\n$$\\therefore \\int X dx + \\int Y dy + &c. = \\int v d.\\phi v;$$\n\nand therefore the sum of the integrals is known in all those cases in which $\\int v d.\\phi v$ can be integrated.\n\nThe most direct and advantageous method of treating any proposed integral $\\int X dx$, is to make one of the two suppositions above mentioned, viz. $X = v$, or $X = v.\\psi x$. But the supposition $X = v + \\psi x$, also, often leads to simple and satisfactory results. Our choice, however, is not limited to these forms, but may include others that are comprehended under the general formula $X = f(v,x)$, each of which may perhaps find its application in special cases.\n\nThis process, in all its generality, constitutes the method which I now propose. The use and application of it will be best shown by examples.\n\n§ 5.\n\nDirect integration of the formula $\\int X . dx$, when that is possible, confirms and illustrates the above results, of which it will be convenient to adduce a few simple examples.\n\nLet there be two variables $x, y$, roots of $x^2 - vx + 1 = 0$. Therefore the quantity $\\frac{1 + x^2}{x} = \\frac{1 + y^2}{y} = v$ is a symmetrical of this equation. And we find\n\n$$x + y = v \\quad \\therefore dx + dy = dv \\quad \\ldots \\ldots \\ldots \\ldots \\ldots (1.)$$\n\n$$xy = 1 \\quad \\therefore \\frac{dx}{x} + \\frac{dy}{y} = 0 \\quad \\ldots \\ldots \\ldots \\ldots \\ldots (2.)$$\n\n$$x^2 + y^2 = v^2 - 2 \\quad \\therefore x dx + y dy = v dv; \\quad \\ldots \\ldots \\ldots (3.)$$\n\nwhich results may be thus written:\n\n$$S dx = dv \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (1.)$$\n\n$$S \\frac{dx}{x} = 0 \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (2.)$$\n\n$$S x dx = v dv. \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (3.)$$\nMultiply each of these equations by the equation \\( \\frac{1 + x^2}{x} = v \\), and we find\n\n\\[\n\\frac{1 + x^2}{x} S \\, dx = v \\, dv \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (1.)\n\\]\n\n\\[\n\\frac{1 + x^2}{x} S \\frac{dx}{x} = 0 \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (2.)\n\\]\n\n\\[\n\\frac{1 + x^2}{x} S \\, x \\, dx = v^2 \\, dv \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (3.)\n\\]\n\nBut because \\( \\frac{1 + x^2}{x} \\) is a symmetrical, we may, according to the general principle, introduce it within the sign \\( S \\).\n\n\\[\n\\therefore S \\frac{1 + x^2}{x} \\, dx = v \\, dv \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (1.)\n\\]\n\n\\[\nS \\frac{1 + x^2}{x^2} \\, dx = 0 \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (2.)\n\\]\n\n\\[\nS (1 + x^2) \\, dx = v^2 \\, dv \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (3.)\n\\]\n\nThe integrals of these equations are\n\n\\[\n*S \\int \\frac{1 + x^2}{x} \\, dx = \\frac{v^2}{2} + \\text{const.} \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (1.)\n\\]\n\n\\[\nS \\int \\frac{1 + x^2}{x^2} \\, dx = \\text{const.} \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (2.)\n\\]\n\n\\[\nS \\int (1 + x^2) \\, dx = \\frac{v^3}{3} + \\text{const.} \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (3.)\n\\]\n\nAnd we propose to verify these three results by direct integration. First then we have\n\n\\[\n\\int \\frac{1 + x^2}{x} \\, dx + \\int \\frac{1 + y^2}{y} \\, dy = \\frac{x^2 + y^2}{2} + \\log x + \\log y + \\text{const.}\n\\]\n\nBut\n\n\\[\nxy = 1 \\quad \\therefore \\log x + \\log y = 0,\n\\]\n\nand\n\n\\[\nx^2 + y^2 = v^2 - 2.\n\\]\n\n\\[\n\\therefore \\int \\frac{1 + x^2}{x} \\, dx + \\int \\frac{1 + y^2}{y} \\, dy = \\frac{v^2}{2} + \\text{const.} \\quad \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots \\ldots (1.)\n\\]\n\nSecondly we have\n\n* It is indifferent whether we write \\( S \\int \\) or \\( \\int S \\), and we may remark that the signs \\( S \\int d \\) may often be permuted. Thus if there are two variables,\n\n\\[\nS \\int dx = \\int S \\, dx = x + y\n\\]\n\n\\[\ndS \\, x = S \\, dx = dx + dy\n\\]\n\n\\[\n\\frac{1}{2} dS \\, x^2 = S \\, dx^2 = x \\, dx + y \\, dy.\n\\]\n\\[ \\int \\frac{1 + x^2}{x^3} \\, dx + \\int \\frac{1 + y^2}{y^2} \\, dy = (x + y) - \\left( \\frac{1}{x} + \\frac{1}{y} \\right) + \\text{const.} \\]\n\n\\[ = (x + y) - \\left( \\frac{x + y}{1} \\right) + \\text{const.} \\]\n\n\\[ = \\text{const.} \\]  \n\nThirdly we have\n\n\\[ \\int (1 + x^2) \\, dx + \\int (1 + y^2) \\, dy = (x + y) + \\frac{x^3 + y^3}{3} + \\text{const.} \\]\n\n\\[ = v + \\frac{x^3 + y^3}{3} + \\text{const.} \\]\n\nBut the formula makes it\n\n\\[ = \\frac{v^3}{3} + \\text{const.} \\]  \n\nIt is necessary therefore to show that these two results are in accordance, or that\n\n\\[ \\frac{v^3}{3} + \\text{const.} = v + \\frac{x^3 + y^3}{3}, \\]\n\nor that\n\n\\[ x^3 + y^3 = v^3 - 3v + \\text{const.} \\]\n\nThis may be shown by multiplying together the equations\n\n\\[ x^2 + y^2 = v^2 - 2, \\]\n\n\\[ x + y = v, \\]\n\nwhich gives\n\n\\[ x^3 + y^3 + xy(x + y) = v^3 - 2v, \\]\n\nand since\n\n\\[ xy = 1, \\text{ and } x + y = v \\]\n\n\\[ x^3 + y^3 = v^3 - 3v \\]\n\nin accordance with the formula.\n\nI will now apply the method to another example, which conducts to a new and interesting property of the cubic parabola. Since \\( \\phi \\frac{1 + x^2}{x} \\) is a symmetrical of the equation \\( x^2 - vx + 1 = 0 \\), (as has been already remarked) we have, as a particular instance of this,\n\n\\[ \\sqrt{\\frac{1 + x^2}{x}} = \\text{a symmetrical} = \\sqrt{v}. \\]\n\nMultiply this equation by \\( S \\, dx = dv \\),\n\n\\[ \\therefore \\sqrt{\\frac{1 + x^2}{x}} \\, S \\, dx = \\sqrt{v} \\, dv, \\]\n\nor\n\n\\[ S \\sqrt{\\frac{1 + x^2}{x}} \\cdot dx = \\sqrt{v} \\, dv. \\]\n\nThe sign \\( S \\) being thus transposed because \\( \\sqrt{\\frac{1 + x^2}{x}} \\) is a symmetrical.\nThe integral of this last equation is\n\n\\[ \\int \\sqrt{\\frac{1 + x^2}{x}} \\, dx = \\frac{2}{3} v^{\\frac{3}{2}} + C, \\]\n\nwhich means that\n\n\\[ [1.] \\int \\sqrt{\\frac{1 + x^2}{x}} \\, dx + \\int \\sqrt{\\frac{1 + y^2}{y}} \\, dy = \\frac{2}{3} (x + y)^{\\frac{3}{2}} + C, \\]\n\nprovided that \\( xy = 1 \\). For since \\( x, y \\), are roots of \\( x^2 - vx + 1 = 0 \\), \\( x + y = v \\), a variable quantity, and \\( xy = 1 \\) is the only condition which the variables must satisfy.\n\nNow assume \\( x = u^2, y = t^2 \\), and the relation between the new variables will be \\( u^2 t^2 = 1 \\), or \\( ut = 1 \\); and equation (1.) becomes, when divided by 2,\n\n\\[ \\frac{1}{3} (u^2 + t^2)^{\\frac{3}{2}} + C = \\int \\sqrt{1 + u^4} \\, du + \\int \\sqrt{1 + t^4} \\, dt, \\]\n\nwhence the following theorem.\n\n*If \\( u, t \\), two ordinates of the cubic parabola*, are reciprocals, so that \\( ut = 1 \\), then the sum of the two corresponding arcs of the curve \\( = \\frac{1}{3} (u^2 + t^2)^{\\frac{3}{2}} + \\text{const}. \\)\n\nThe reader may wish to see this result also verified by direct integration. Since then \\( ut = 1 \\), let us write \\( \\frac{1}{u} \\) instead of \\( t \\) in the equation\n\n\\[ \\frac{1}{3} (u^2 + t^2)^{\\frac{3}{2}} + C = \\int \\sqrt{1 + u^4} \\, du + \\int \\sqrt{1 + t^4} \\, dt, \\]\n\nand it becomes\n\n\\[ \\frac{1}{3} \\left( u^2 + \\frac{1}{u^2} \\right)^{\\frac{3}{2}} + C = \\int \\sqrt{1 + u^4} \\, du - \\int \\sqrt{1 + u^4} \\cdot \\frac{du}{u}, \\]\n\nor\n\n\\[ \\frac{1}{3} \\left( \\frac{1 + u^4}{u^3} \\right)^{\\frac{3}{2}} + C = \\int \\sqrt{1 + u^4} \\, du \\left( 1 - \\frac{1}{u^4} \\right), \\]\n\nwhich ought to be identically true, whatever be the value of \\( u \\). To see that it is so in reality, we have only to differentiate the first part of the equation, and we find its differential to be\n\n\\[ 2 \\sqrt{1 + u^4} \\, du - \\left( \\frac{1 + u^4}{u^4} \\right)^{\\frac{3}{2}} \\cdot du \\]\n\n\\[ = \\sqrt{1 + u^4} \\, du \\left( 2 - \\frac{1 + u^4}{u^4} \\right) = \\sqrt{1 + u^4} \\, du \\left( 1 - \\frac{1}{u^4} \\right), \\]\n\nwhich is the differential of the second part of the equation.\n\nLet us now show the application of the method to formulæ containing cubic radicals.\n\n* The equation to the cubic parabola, whose coordinates are \\( u, u' \\), being \\( 3u' = u^3 \\), it follows that the arc\n\n\\[ = \\int du \\sqrt{1 + u^4}. \\]\nResuming the former equations\n\n\\[ x^2 - v x + 1 = 0, \\quad v = \\frac{1 + x^2}{x}, \\]\n\nwe have\n\n\\[ \\sqrt[3]{v} = \\sqrt[3]{\\frac{1 + x^2}{x}}. \\]\n\nMultiply this equation by \\( S \\, dx (= dv) \\)\n\n\\[ \\therefore \\sqrt[3]{v} \\cdot dv = \\sqrt[3]{\\frac{1 + x^2}{x}} \\cdot S \\, dx. \\]\n\nBut we may introduce \\( \\sqrt[3]{\\frac{1 + x^2}{x}} \\) (since it is a symmetrical) within the sign \\( S \\),\n\n\\[ \\therefore \\sqrt[3]{v} \\cdot dv = S \\sqrt[3]{\\frac{1 + x^2}{x}} \\cdot dx, \\]\n\nand integrating\n\n\\[ \\frac{3}{4} v^{\\frac{4}{3}} + \\text{const.} = S \\int \\sqrt[3]{\\frac{1 + x^2}{x}} \\cdot dx. \\]\n\nIt is plain that the sum of two integrals of the form \\( \\int \\sqrt[3]{\\frac{1 + x^2}{x}} \\cdot dx \\) may be found by a similar process, provided always that \\( xy = 1 \\).\n\nResuming the last example we have\n\n\\[ \\sqrt[3]{v} = \\sqrt[3]{\\frac{1 + x^2}{x}}. \\]\n\nIf we multiply this equation by \\( S \\frac{dx}{x} \\) instead of \\( S \\, dx \\), we have\n\n\\[ \\sqrt[3]{v} \\cdot S \\frac{dx}{x} = \\sqrt[3]{\\frac{1 + x^2}{x}} S \\frac{dx}{x} = S \\sqrt[3]{\\frac{1 + x^2}{x}} \\cdot \\frac{dx}{x} = S \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx. \\]\n\nBut \\( S \\frac{dx}{x} = 0 \\) in this example*,\n\n\\[ \\therefore 0 = S \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx \\]\n\n\\[ \\therefore \\text{integrating we find the sum of two integrals of the form } \\int \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx \\text{ is a constant, if } xy = 1. \\]\n\nSince nothing tends more to elucidate a subject than a frequent recurrence to first principles, I will remark that this result also follows at once from the supposition \\( xy = 1 \\). For if we write \\( \\frac{1}{x} \\) for \\( y \\),\n\n\\[ \\int \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx + \\int \\sqrt[3]{\\frac{1 + y^2}{y^4}} \\cdot dy \\]\n\nbecomes\n\n\\[ \\int \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx - \\int \\sqrt[3]{x^4 + x^2} \\cdot \\frac{dx}{x^2} \\]\n\n\\[ = \\int \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx - \\int \\sqrt[3]{\\frac{1 + x^2}{x^4}} \\cdot dx = 0 = \\text{const.} \\]\n\n* See page 200; or page 208, note.\nWe are now in possession of principles which enable us to attack the general problem, \"To find an algebraic relation between \\( n \\) variables \\( x, y, z \\ldots \\), such that\n\n\\[\n\\int \\phi (X) \\, dx + \\int \\phi (Y) \\, dy + \\int \\phi (Z) \\, dz + \\&c. = \\text{const.},\n\\]\n\n\\( X \\) being a polynomial of \\( n \\) dimensions with constant coefficients of the form\n\n\\[\nx^n - ax^{n-1} + bx^{n-2} + \\&c. + hx + k,\n\\]\n\nand containing at least two distinct powers of \\( x \\); and \\( \\phi \\) being any function whatever of the said polynomial.\n\nIt does not appear that any mathematician has hitherto proposed this problem. The principles of our method lead to the following solution:\n\nLet \\( X \\), or \\( x^n - ax^{n-1} + \\ldots + hx + k = v \\), \\( v \\) being a variable quantity susceptible of any value*.\n\n\\[\n\\therefore x^n - ax^{n-1} + \\ldots + hx + (k - v) = 0.\n\\]\n\nThis equation has only one variable coefficient, viz. \\((k - v)\\). Therefore the values of its \\( n \\) roots depend upon \\( v \\), so far, at least, that when \\( v \\) changes its value, each root (generally speaking) undergoes a corresponding change. Also the sum of the roots \\( x + y + z + \\ldots = a \\) is constant.\n\n\\[\n\\therefore dx + dy + dz + \\ldots = 0,\n\\]\n\nor\n\n\\[\nS dx = 0.\n\\]\n\nSince \\( v = X \\), \\( \\phi v = \\phi X \\). Multiply this equation by \\( S dx = 0 \\),\n\n\\[\n\\therefore \\phi v S dx = \\phi X \\cdot S dx\n\\]\n\n\\[\n\\therefore 0 = \\phi X \\cdot S dx = S \\phi X \\cdot dx\n\\]\n\n(because \\( \\phi X \\) is a symmetrical of this equation)\n\n\\[\n\\therefore \\text{const.} = S \\int \\phi X \\cdot dx,\n\\]\n\nwhich therefore is the required solution of the problem.\n\n**Example.**—Let \\( \\int \\sqrt[3]{x^3 + x + 1} \\cdot dx \\) be the proposed integral. Assume \\( x^3 + x + 1 = v \\),\n\n\\[\n\\therefore x^3 + x + (1 - v) = 0.\n\\]\n\n* To suppose \\( X = v \\) is the same as to suppose \\( X \\) to be a symmetrical of the equation between the variables (as recommended at pages 198, 200). Whence also \\( \\phi X \\) is a symmetrical of the same equation. The symbol \\( v \\) retains the same meaning as before, viz. that of a quantity independent of \\( x \\), or which continues to have the same value when \\( x \\) is permuted for any other root of the equation. I shall give it this meaning throughout the present memoir.\n\nThe solution given in the text may be expressed in other words, by saying that any two of the variables, as for instance \\( x \\) and \\( y \\), are mutually connected by the equation\n\n\\[\nx^n - ax^{n-1} + \\ldots + hx = y^n - ay^{n-1} + \\ldots + hy,\n\\]\n\nwhence of course it follows that \\( X \\), or \\( x^n - ax^{n-1} + \\ldots + hx + k \\), does not change its value when \\( x \\) is permuted for \\( y \\), and therefore it may properly be denoted by \\( v \\), according to the acceptation which we have hitherto given to that letter.\nAttribute to \\( v \\) any numerical value, and let the three roots of the equation then be \\( m, m', m'' \\). And when \\( v \\) has some other value, let the roots be \\( n, n', n'' \\). So that while \\( v \\) has changed progressively from one value to the other, the root \\( m \\) has progressively changed its value to \\( n \\), the root \\( m' \\) to \\( n' \\), and the root \\( m'' \\) to \\( n'' \\).\n\nThese things being thus understood, the meaning of the theorem is, that the value of the integral \\( \\int d x \\sqrt[3]{x^3 + x + 1} \\) taken between the limits \\( x = m, x = n \\),\n\n\\[\n+ \\text{its value between the limits } m', n',\n+ \\text{its value between the limits } m'', n'',\n= \\text{a constant}.\n\\]\n\nIf the question be viewed geometrically, since the roots of an equation are the intersections of a curve with its axis, a progressive change in the value of \\((k - v)\\), the absolute term, is equivalent to a displacement of the axis parallel to itself, in consequence of which all the intersections change their places simultaneously.\n\nIn the case of two variables, we have simply\n\n\\[\nX = x^2 - ax + b = v,\n\\]\n\nor\n\n\\[\nx^2 - ax + (b - v) = 0.\n\\]\n\nAnd if \\( x, y \\), are the roots of this equation, the theorem becomes\n\n\\[\n\\int \\phi X \\cdot dx + \\int \\phi Y \\cdot dy = \\text{const.},\n\\]\n\n\\( \\phi \\) being any function.\n\nNow in this particular case the theorem admits of a very simple demonstration. For since \\( x + y = a, y = a - x \\); and substituting this value in \\( Y = y^2 - ay + b \\), it becomes \\((a - x)^2 - a(a - x) + b = x^2 - ax + b \\): also \\( dy \\) becomes \\(-dx\\).\n\n\\[\n\\therefore \\phi(y^2 - ay + b) \\cdot dy \\text{ becomes } -\\phi(x^2 - ax + b) \\cdot dx.\n\\]\n\nTherefore\n\n\\[\n\\phi(x^2 - ax + b) \\cdot dx + \\phi(y^2 - ay + b) \\cdot dy = 0,\n\\]\n\nor\n\n\\[\n\\phi X \\cdot dx + \\phi Y \\cdot dy = 0\n\\]\n\n\\[\n\\therefore \\int \\phi X \\cdot dx + \\int \\phi Y \\cdot dy = \\text{const.},\n\\]\n\nwhich was to be demonstrated.\n\nLet \\( X = x^n - ax^{n-1} + \\ldots \\) as before, it may be shown upon the same principles that \\( S \\int \\phi X \\cdot x^m \\cdot dx = \\text{const.} \\), provided \\( S x^m \\cdot dx = 0 \\), or \\( S x^{m+1} \\) is constant, that is to say, does not contain \\( v \\); which depends on the relative values of \\( m \\) and \\( n \\). Also we may obtain in a similar manner the solution of the following problem, viz.\n\n\\[\nS \\int \\phi \\left( \\frac{X}{X'} \\right) \\cdot dx = \\text{const.},\n\\]\n\nwhere \\( X \\) is a polynomial of \\( n \\) dimensions, and \\( X' \\) another polynomial of not more than \\( n - 2 \\) dimensions. For, putting\n\\[ \\frac{X}{X'} = v, \\]\n\n\\( x, y, \\&c. \\&c. \\) are roots of\n\n\\[ X - v X' = 0, \\]\n\nwhich is of the form\n\n\\[ x^n - a x^{n-1} + (b - v) x^{n-2} + \\&c. = 0, \\]\n\nwhere\n\n\\[ S x = a = \\text{const.}, \\]\n\nand therefore\n\n\\[ S d x = 0 \\quad \\therefore S \\varphi \\left( \\frac{X}{X'} \\right) d x = \\varphi \\left( \\frac{X}{X'} \\right) S d x = 0, \\]\n\n\\[ \\therefore S \\int \\varphi \\left( \\frac{X}{X'} \\right) d x = \\text{const}. \\]\n\nI will now add several examples, and I request the reader's attention to the directness with which their solutions are obtained by means of the foregoing principles.\n\nIn the present paper I have avoided the use of transformations, except that of \\( x = u^n \\), because they are unnecessary to the success of the method, and that I am here considering general principles rather than individual results.\n\n§ 6. Examples.\n\nEx. 1. Let the proposed integral be\n\n\\[ \\int \\frac{d x}{\\sqrt{1 - x^3}}. \\]\n\nThis is Mr. Lubbock's first example in his paper on Abel's theorem in the Philosophical Magazine*. The result which he finds is equivalent to this, that if \\( x \\) and \\( y \\) satisfy the equation\n\n\\[ xy - (x + y) = 2, \\]\n\nthen\n\n\\[ \\int \\frac{d x}{\\sqrt{1 - x^3}} + \\int \\frac{d y}{\\sqrt{1 - y^3}} = \\text{const}. \\]\n\nFor the sake of comparison I will take this as the first example of my method, and supposing its solution to be unknown, proceed to investigate it as follows:\n\n\\[ \\int \\frac{d x}{\\sqrt{1 - x^3}} \\] may be put under the form\n\n\\[ \\int \\frac{d x}{(1 - x) \\sqrt{\\frac{1 + x + x^3}{1 - x}}}. \\]\n\nPut\n\n\\[ \\frac{1 + x + x^2}{1 - x} = v \\]\n\n\\[ \\therefore x^2 + (1 + v) x + (1 - v) = 0, \\]\n\n\\( x \\) and \\( y \\) must be the roots of this equation†,\n\n* Vol. vi. p. 118. † See the note in page 196.\n\\[\n\\begin{align*}\n\\therefore x + y &= -(1 + v) \\quad xy = 1 - v \\\\\n\\therefore xy - (x + y) &= 2,\n\\end{align*}\n\\]\nwhich is the equation of condition found by Mr. Lubbock.\n\nAgain, the sum of the integrals\n\n\\[\n\\int \\frac{dx}{\\sqrt{1-x}} \\cdot \\frac{1}{v} + \\int \\frac{dy}{\\sqrt{1-y}} \\cdot \\frac{1}{v}\n\\]\n\n\\[\n= \\int \\frac{1}{v} \\left( \\frac{dx}{1-x} + \\frac{dy}{1-y} \\right) = \\int 0 = \\text{const.}\n\\]\n\nbecause, since\n\n\\[\nxy - (x + y) = 2\n\\]\n\n\\[\n(1-x)(1-y) = 1 + xy - (x+y) = 3\n\\]\n\n\\[\n\\therefore \\log (1-x) + \\log (1-y) = \\log 3\n\\]\n\n\\[\n\\therefore \\frac{dx}{1-x} + \\frac{dy}{1-y} = 0\n\\]\n\n\\[\n\\therefore \\text{sum of the integrals} = \\text{const.} \\quad Q. E. D.\n\\]\n\n**Ex. 2.** To find the sum of three integrals of the same form.\n\n\\[\n\\int \\frac{dx}{\\sqrt{1-x^3}} \\text{ may be written } \\int \\frac{dx}{x} \\sqrt{\\frac{x^3}{1-x^3}}. \\quad \\text{Put } \\frac{x^3}{1-x^3} = \\frac{1}{v},\n\\]\n\n\\[\n\\therefore x^3 + vx^2 - 1 = 0.\n\\]\n\nThe three variables \\(x, y, z\\), must be roots of this equation,\n\n\\[\n\\therefore xy z = 1, \\text{ and } xy + xz + yz = 0.\n\\]\n\nHere we have\n\n\\[\n\\sqrt{\\frac{x^2}{1-x^3}} = \\sqrt{\\frac{1}{v}}.\n\\]\n\nMultiply this by \\(S \\frac{dx}{x} = 0*\\),\n\n\\[\n\\therefore \\sqrt{\\frac{x^2}{1-x^3}} S \\frac{dx}{x} = 0.\n\\]\n\nBut\n\n\\[\n\\sqrt{\\frac{x^2}{1-x^3}} S \\frac{dx}{x} = S \\sqrt{\\frac{x^2}{1-x^3}} \\cdot \\frac{dx}{x} = S \\frac{dx}{\\sqrt{1-x^3}}\n\\]\n\n\\[\n\\therefore S \\frac{dx}{\\sqrt{1-x^3}} = 0 \\quad \\therefore S \\int \\frac{dx}{\\sqrt{1-x^3}} = \\text{const.}\n\\]\n\n* In any equation whose last term is constant, \\(S \\frac{dx}{x} = 0\\). For\n\n\\[\nS \\frac{dx}{x} = \\frac{dx}{x} + \\frac{dy}{y} + \\frac{dz}{z} + \\&c.\n\\]\n\n\\[\n= d \\log x + d \\log y + \\&c.\n\\]\n\n\\[\n= d \\log (xyz \\ldots)\n\\]\n\n\\[\n= d \\cdot \\text{const.} = 0.\n\\]\n∴ the sum of the three integrals is constant, provided that \\(xy + xz + yz = 0\\), and that \\(xyz = 1\\). It will be observed that the solution is simpler in the case of three integrals than of two.\n\n**Ex. 3.** Supposing the relation between \\(x, y, z\\) the same as in the last example, to find the sum of three integrals of the form \\(\\int \\frac{x \\, dx}{\\sqrt{1-x^3}}\\). Since\n\n\\[\n\\sqrt{\\frac{1}{v}} = \\frac{x}{\\sqrt{1-x^3}}\n\\]\n\nor in other words, since \\(\\frac{x}{\\sqrt{1-x^3}}\\) is a symmetrical of the equation\n\n\\[\nx^3 + v x^2 - 1 = 0,\n\\]\n\nif it be multiplied by \\(S \\, dx\\) the result will be\n\n\\[\nS \\frac{x \\, dx}{\\sqrt{1-x^3}}.\n\\]\n\nAlso\n\n\\[\nS x = -v \\quad \\therefore S \\, dx = -dv\n\\]\n\n\\[\n\\therefore S \\frac{x \\, dx}{\\sqrt{1-x^3}} = \\sqrt{\\frac{1}{v}} S \\, dx = \\frac{-dv}{\\sqrt{v}}.\n\\]\n\nTherefore\n\n\\[\nS \\int \\frac{x \\, dx}{\\sqrt{1-x^3}} = \\text{const.} - 2\\sqrt{v}.\n\\]\n\n**Ex. 4.** The same suppositions continuing, required the sum of three integrals of the form \\(\\int \\frac{x^2 \\, dx}{\\sqrt{1-x^3}}\\). As before,\n\n\\[\n\\frac{x}{\\sqrt{1-x^3}} = \\sqrt{\\frac{1}{v}}.\n\\]\n\nMultiply by \\(S \\, x \\, dx\\),\n\n\\[\n\\therefore S \\frac{x^2 \\, dx}{\\sqrt{1-x^3}} = \\sqrt{\\frac{1}{v}} S \\, x \\, dx = dv \\sqrt{v},\n\\]\n\n(because the equation \\(x^3 + v x^2 - 1 = 0\\) gives \\(S x^2 = v^2 \\quad \\therefore S \\, x \\, dx = v \\, dv\\))\n\n\\[\n\\therefore S \\int \\frac{x^2 \\, dx}{\\sqrt{1-x^3}} = \\frac{2}{3} v^{\\frac{3}{2}} + \\text{const.}\n\\]\n\nBut since \\(\\int \\frac{x^2 \\, dx}{\\sqrt{1-x^3}}\\) is a form which is readily integrable *per se*, it will naturally be asked whether the result of direct integration is the same as that given by our formulae. This example therefore affords a convenient opportunity of showing the close accordance between this branch of the integral calculus and the theory of algebraic equations.\n\nBy direct integration,\n\n\\[\nS \\int \\frac{x^2 \\, dx}{\\sqrt{1-x^3}} = -\\frac{2}{3} (\\sqrt{1-x^3} + \\sqrt{1-y^3} + \\sqrt{1-z^3}) + \\text{const.}\n\\]\nAnd by our method,\n\n\\[ S \\int \\frac{x^2 \\, dx}{\\sqrt{1 - x^3}} = \\frac{2}{3} v^{\\frac{3}{2}} + \\text{const}. \\]\n\n∴ it remains to verify that\n\n\\[ \\sqrt{1 - x^3} + \\sqrt{1 - y^3} + \\sqrt{1 - z^3} = -v^{\\frac{3}{2}}. \\]\n\nIn order to demonstrate this, let us resume the original equation \\( x^3 + vx^2 - 1 = 0 \\),\n\nwhich gives \\( vx^2 = 1 - x^3 \\),\n\n\\[ ∴ \\sqrt{v} \\cdot x = \\sqrt{1 - x^3}, \\]\n\nand similarly,\n\n\\[ \\sqrt{v} \\cdot y = \\sqrt{1 - y^3} \\]\n\\[ \\sqrt{v} \\cdot z = \\sqrt{1 - z^3} \\]\n\n\\[ ∴ \\sqrt{1 - x^3} + \\sqrt{1 - y^3} + \\sqrt{1 - z^3} = \\sqrt{v} (x + y + z) \\]\n\\[ = \\sqrt{v} (-v) = -v^{\\frac{3}{2}}. \\quad Q.E.D. \\]\n\n**Ex. 5.** \\( \\int \\frac{dx}{\\sqrt{(x^3 + x^2)} + \\sqrt{x^3 + x^2}}. \\)\n\nThis is a function of the binomial \\( x^3 + x^2 \\), which being put \\( = v \\), we have\n\n\\[ x^3 + x^2 - v = 0. \\]\n\nThe three roots of this equation are the variables that answer the problem.\n\nPutting \\( \\sqrt{v} + \\sqrt[3]{v} = \\phi v \\), the sum of the three integrals becomes\n\n\\[ \\int \\frac{dx}{\\phi v} + \\int \\frac{dy}{\\phi v} + \\int \\frac{dz}{\\phi v} = \\int \\frac{1}{\\phi v} S \\, dx; \\]\n\nbut \\( S \\, dx = 0 \\), because \\( x + y + z = -1 \\),\n\n\\[ ∴ \\text{sum of integrals} = \\int 0 = \\text{const}. \\]\n\n**Ex. 6.** \\( \\int dx \\sqrt{1 + x^n}. \\)\n\nHere we cannot suppose \\( \\sqrt{1 + x^n} = v \\) a symmetrical quantity, because that would amount to the supposition \\( \\sqrt{1 + x^n} = \\sqrt{1 + y^n} = \\sqrt{1 + z^n} = &c., \\) which implies that \\( x = y = z = &c., \\) whereas we suppose the roots to be in general all different from one another. This is the reason why it was remarked before, that it was requisite the polynomial should contain at least two distinct powers of \\( x \\). When that is not the case, a second power of \\( x \\) must be introduced. There are several ways of doing this; the simplest is the following:\n\nPut \\( \\int dx \\sqrt{1 + x^n} \\) under the form \\( \\int x \\, dx \\sqrt{\\frac{1 + x^n}{x^2}} \\). Assume \\( \\frac{1 + x^n}{x^2} = v, \\)\n\n\\[ ∴ x^n - vx^2 + 1 = 0; \\]\n\nan equation of \\( n \\) dimensions, of which \\( v \\) is the only variable coefficient. The \\( n \\) roots of this equation answer the problem.\nThe sum of $n$ integrals becomes\n\n$$\\int x \\, dx \\sqrt{v} + \\int y \\, dy \\sqrt{v} + \\text{&c.} = \\int \\sqrt{v} \\cdot Sx \\, dx.$$  \n\nIf $n$ is a number greater than 4, $Sx^2 = 0$:\n\n$$\\therefore Sx \\, dx = 0 \\quad \\therefore \\text{sum of } n \\text{ integrals} = \\text{const.}$$\n\nIf $n = 4$, $Sx^2 = 2v$, $\\therefore Sx \\, dx = dv$,\n\n$$\\therefore \\text{sum of four integrals} = \\int \\sqrt{v} \\cdot dv = \\frac{2}{3} v^{\\frac{3}{2}} + C.$$\n\nIf $n = 3$, $Sx^2 = v^2$, $\\therefore Sx \\, dx = v \\, dv$,\n\n$$\\therefore \\text{sum of three integrals} = \\int v^{\\frac{3}{2}} \\, dv = \\frac{2}{5} v^{\\frac{5}{2}} + C.$$\n\nBut when $n$ is greater than 4, the equation has impossible roots, therefore the solution is imaginary. Although, as Legendre has demonstrated*, these imaginary cases do not cease to have a real analytical meaning; the sum of two imaginary integrals forming a real integral in a manner analogous to that in which two imaginary roots of an equation form a real sum and product.\n\nBut we may avoid these imaginary solutions by putting $\\int dx \\sqrt{1 + x^n}$ in the form\n\n$$\\int dx (a + bx + cx^2 \\ldots \\ldots) \\sqrt{\\frac{1 + x^n}{(a + bx + cx^2 \\ldots \\ldots)^2}}.$$  \n\nAssuming, then,\n\n$$\\frac{1 + x^n}{(a + bx + cx^2 \\ldots \\ldots)^2} = v,$$\n\nwe may attribute to the polynomial any number of terms suitable to the exponent $n$†, and then it is in most cases possible to find such numerical values for the constant coefficients $a$, $b$, $c$, &c., that the resulting equation shall have all its roots real.\n\nEach integral, then, has the form\n\n$$\\int dx (a + bx + cx^2 \\ldots \\ldots) \\sqrt{v},$$\n\nand the sum of all\n\n$$= \\int \\sqrt{v} \\cdot Sx \\, dx (a + bx + cx^2 \\ldots \\ldots),$$\n\nwhere $Sx \\, dx (a + bx + cx^2 \\ldots \\ldots)$ = the aggregate of the partial sums\n\n$$aSx \\, dx + bSx \\, dx + cSx^2 \\, dx + \\ldots \\ldots,$$\n\nwhich is the differential of\n\n$$aSx + \\frac{b}{2} Sx^2 + \\frac{c}{3} Sx^3 + \\ldots \\ldots,$$\n\nand may therefore be expressed in terms of $v$, since the quantities $Sx$, $Sx^2$, $Sx^3$, &c. are readily found in terms of $v$ by the usual doctrine of algebraic equations.\n\n* Fonctions Elliptiques, vol. iii. p. 326.\n\n† In general the number of its terms may be $\\frac{n}{2}$ or $\\frac{n+1}{2}$.\nEx. 7. \\( \\int dx \\sqrt[3]{1 + x^n} \\).\n\nThis may be put in the form\n\n\\[\n\\int dx (a + bx + \\ldots) \\sqrt[3]{\\frac{1 + x^n}{(a + bx + \\ldots)^3}};\n\\]\n\nand putting\n\n\\[\n\\frac{1 + x^n}{(a + bx + \\ldots)^3} = v,\n\\]\n\nthe reasoning is the same nearly as in the preceding case. The same principles are applicable to the more general integral \\( \\int dx \\sqrt[m]{1 + x^n} \\), \\( m \\) being a whole number.\n\nThese solutions give the algebraic sum of \\( n \\) integrals of the proposed form. But this number \\( n \\) may be reduced by various methods to a lower number, which is the minimum that the problem admits of: ex. gr. the lowest number of integrals of the form \\( \\int dx \\sqrt{1 + x^i} \\) which have an algebraic sum is two; of the form \\( \\int dx \\sqrt{1 + x^5} \\) is three; of the form \\( \\int dx \\sqrt{1 + x^{10}} \\) is likewise three, &c. &c., which subject I shall treat of in a subsequent section.\n\nEx. 8. \\( \\int \\frac{dx}{\\sqrt[3]{x^3 - 1}} \\).\n\nFirst solution. Put \\( x^3 = t \\), and the integral becomes\n\n\\[\n\\frac{1}{3} \\frac{t^{-\\frac{2}{3}} dt}{\\sqrt[3]{t^2 - 1}} = \\frac{1}{3} \\cdot \\frac{dt}{\\sqrt[3]{t^3 - t^2}}.\n\\]\n\nPut \\( t^3 - t^2 = v \\), or \\( t^3 - t^2 - v = 0 \\). The three roots of this equation answer the problem.\n\n\\[\n\\therefore \\text{the sum of three integrals } = \\int \\frac{1}{3} S \\frac{dt}{\\sqrt[3]{v}} = \\int 0 = \\text{const.}\n\\]\n\n(because \\( S t = 1 \\), being the coefficient of the second term of the equation \\( t^3 - t^2 - v = 0 \\) taken negatively, whence \\( S dt = 0 \\)).\n\nSecond solution. Put \\( x^3 = t^2 \\), and the integral becomes\n\n\\[\n\\frac{2}{3} \\frac{t^{-\\frac{1}{3}} dt}{\\sqrt[3]{t^2 - 1}} = \\frac{2}{3} \\cdot \\frac{dt}{\\sqrt[3]{t^3 - t}}.\n\\]\n\nPut \\( t^3 - t = v \\),\n\n\\[\n\\therefore t^3 - t - v = 0,\n\\]\n\nand the roots of this equation answer the problem.\n\n\\[\n\\therefore \\text{the sum of three integrals } = \\int \\frac{2}{3} S \\frac{dt}{\\sqrt[3]{v}} = \\int 0 = \\text{const.}\n\\]\n\n(because \\( S t = 0 \\) in the equation \\( t^3 - t - v = 0 \\) \\( \\therefore S dt = 0 \\)), and the sum of the integrals therefore reduces itself in this case also to a constant.\n\nIt will probably be satisfactory to the reader to see some one of these results verified by arithmetical computation. Let us therefore select this last example for that purpose.\n§ 7. Example of an arithmetical calculation of the sum of three Integrals.\n\nThe preceding analysis shows that the sum of the three integrals\n\n\\[ \\int_{\\sqrt[3]{x^3 - 1}} \\frac{dx}{\\sqrt[3]{x^3 - 1}} + \\int_{\\sqrt[3]{y^3 - 1}} \\frac{dy}{\\sqrt[3]{y^3 - 1}} + \\int_{\\sqrt[3]{z^3 - 1}} \\frac{dz}{\\sqrt[3]{z^3 - 1}} = \\text{const}. \\]\n\nif \\( x^{\\frac{2}{3}}, y^{\\frac{2}{3}}, z^{\\frac{2}{3}} \\) are roots of the equation\n\n\\[ t^3 - t - v = 0. \\]\n\nBut the form of this equation shows that the sum of its roots \\(= 0\\), the sum of the products of every two roots \\(= -1\\), while the product of all the roots is a variable quantity \\(= v\\); \\(∴\\) the quantities \\(x, y, z\\) must satisfy the two following equations,\n\n\\[ x^{\\frac{2}{3}} + y^{\\frac{2}{3}} + z^{\\frac{2}{3}} = 0 \\]\n\\[ (xy)^{\\frac{2}{3}} + (xz)^{\\frac{2}{3}} + (yz)^{\\frac{2}{3}} = -1. \\]\n\nAnd if they do so, we shall have\n\n\\[ \\int_x + \\int_y + \\int_z = \\text{const}, \\]\n\ndenoting by \\( \\int_x \\) the integral \\( \\int_{\\sqrt[3]{x^3 - 1}} \\).\n\nBut in order to eliminate the constant, we may take three other variables \\(x', y', z'\\), satisfying the same two equations of condition, and thence deduce\n\n\\[ \\int_{x'} + \\int_{y'} + \\int_{z'} = \\text{const}. \\]\n\nWhence by subtraction we eliminate the constant\n\n\\[ (\\int_x - \\int_{x'}) + (\\int_y - \\int_{y'}) + (\\int_z - \\int_{z'}) = 0. \\quad \\ldots \\quad [1.] \\]\n\nNow by the usual methods we find that the equations of condition are satisfied by the values\n\n\\[ x = .352342 \\]\n\\[ y = .917532 \\]\n\\[ z = 1.057860, \\]\n\nand also by the values\n\n\\[ x' = .392456 \\]\n\\[ y' = .900227 \\]\n\\[ z' = 1.065602*. \\]\n\n* These values give\n\n\\[ x^{\\frac{2}{3}} = -0.209149 \\]\n\\[ y^{\\frac{2}{3}} = -0.878885 \\]\n\\[ z^{\\frac{2}{3}} = 1.088034 \\]\n\\[ x'^{\\frac{2}{3}} = -0.245862 \\]\n\\[ y'^{\\frac{2}{3}} = -0.854138 \\]\n\\[ z'^{\\frac{2}{3}} = 1.100000 \\]\n\nSum \\(= 0\\) \\quad Sum \\(= 0\\)\n\nThis verifies the first equation of condition. The squares of these quantities are\nIt remains therefore to try by actual calculation whether these values satisfy the equation [1.].\n\n\\[ \\int_x = \\int_{\\sqrt[3]{x^3 - 1}} dx = x + \\frac{1}{3} \\cdot \\frac{x^4}{4} + \\frac{1.4}{3.6} \\cdot \\frac{x^7}{7} + \\frac{1.4.7}{3.6.9} \\cdot \\frac{x^{10}}{10} + &c. \\]\n\n\\[ \\int_{x'} = \\int_{\\sqrt[3]{x'^3 - 1}} dx' = x' + \\frac{1}{3} \\cdot \\frac{x'^4}{4} + \\frac{1.4}{3.6} \\cdot \\frac{x'^7}{7} + \\frac{1.4.7}{3.6.9} \\cdot \\frac{x'^{10}}{10} + &c. \\]\n\n∴ putting \\( x' - x = \\Delta x, x'^4 - x^4 = \\Delta (x^4) \\) &c.\n\n\\[ \\int_{x'} - \\int_x = \\Delta x + \\frac{1}{3} \\cdot \\frac{\\Delta (x^4)}{4} + \\frac{1.4}{3.6} \\cdot \\frac{\\Delta (x^7)}{7} + \\frac{1.4.7}{3.6.9} \\cdot \\frac{\\Delta (x^{10})}{10} + &c. \\]\n\nand since \\( \\Delta x = .04011 \\) is a small quantity, we readily find the sum of the series \\( = .04083 \\). Treating the other variables in the same manner, the result obtained is\n\n\\[ X = \\int_{x'} - \\int_x = .040834 \\]\n\n\\[ Y = \\int_{y'} - \\int_y = .027526 \\]\n\n\\[ Z = \\int_{z'} - \\int_z = .013315. \\]\n\nWith regard to the signs, it appears that the integral \\( X \\) has a sign opposed to that of the other two. We find therefore finally,\n\n\\[ Y + Z = .040841 \\]\n\n\\[ X = .040834 \\]\n\n∴ \\( Y + Z - X = .000007. \\)\n\nOn the other hand the formula gives \\( Y + Z - X = 0 \\), rigorously. Therefore the computation is only in error in the sixth place of decimals, which in consequence of the prolixity of these calculations may be considered to be a sufficient trial of its accuracy.\n\n\\[ x^3 = .043743 \\quad x'^3 = .060448 \\]\n\\[ y^3 = .772439 \\quad y'^3 = .729552 \\]\n\\[ z^3 = 1.183818 \\quad z'^3 = 1.210000 \\]\n\nSum = 2 \\quad Sum = 2\n\nSquaring the equation \\( x^3 + y^3 + z^3 = 0 \\), we have\n\n\\[ (x^3 + y^3 + z^3) + 2 (\\overline{x y}^3 + \\overline{x z}^3 + \\overline{y z}^3) = 0, \\]\n\nand substituting the value just found of \\( x^3 + y^3 + z^3 = 2 \\), we have\n\n\\[ \\overline{x y}^3 + \\overline{x z}^3 + \\overline{y z}^3 = -1, \\]\n\nwhich verifies the second equation of condition.\nNote.—The integrals comprised in the formula $\\int \\frac{P dx}{\\sqrt{R}}$ have been called ultra-elliptic by Legendre. I think I have sufficiently shown that no line of distinction can be drawn between them and integrals in general; all of which, that are functions of a given polynomial, possess the property which was supposed to characterize the ultra-elliptic class.",
  "source": "olmocr",
  "added": "2026-01-12",
  "created": "2026-01-12",
  "metadata": {
    "Source-File": "/home/jic823/projects/def-jic823/royalsociety/pdfs/108031.pdf",
    "olmocr-version": "0.3.4",
    "pdf-total-pages": 40,
    "total-input-tokens": 62904,
    "total-output-tokens": 29488,
    "total-fallback-pages": 0
  },
  "attributes": {
    "pdf_page_numbers": [
      [
        0,
        0,
        1
      ],
      [
        0,
        2398,
        2
      ],
      [
        2398,
        5392,
        3
      ],
      [
        5392,
        8009,
        4
      ],
      [
        8009,
        10205,
        5
      ],
      [
        10205,
        12187,
        6
      ],
      [
        12187,
        14446,
        7
      ],
      [
        14446,
        16283,
        8
      ],
      [
        16283,
        18056,
        9
      ],
      [
        18056,
        20061,
        10
      ],
      [
        20061,
        22404,
        11
      ],
      [
        22404,
        23853,
        12
      ],
      [
        23853,
        26401,
        13
      ],
      [
        26401,
        28757,
        14
      ],
      [
        28757,
        30810,
        15
      ],
      [
        30810,
        32636,
        16
      ],
      [
        32636,
        34797,
        17
      ],
      [
        34797,
        37097,
        18
      ],
      [
        37097,
        39124,
        19
      ],
      [
        39124,
        41498,
        20
      ],
      [
        41498,
        44072,
        21
      ],
      [
        44072,
        46614,
        22
      ],
      [
        46614,
        49264,
        23
      ],
      [
        49264,
        51198,
        24
      ],
      [
        51198,
        53543,
        25
      ],
      [
        53543,
        55602,
        26
      ],
      [
        55602,
        57168,
        27
      ],
      [
        57168,
        59435,
        28
      ],
      [
        59435,
        61406,
        29
      ],
      [
        61406,
        64185,
        30
      ],
      [
        64185,
        66712,
        31
      ],
      [
        66712,
        68430,
        32
      ],
      [
        68430,
        70139,
        33
      ],
      [
        70139,
        72081,
        34
      ],
      [
        72081,
        74208,
        35
      ],
      [
        74208,
        76433,
        36
      ],
      [
        76433,
        78706,
        37
      ],
      [
        78706,
        80646,
        38
      ],
      [
        80646,
        82620,
        39
      ],
      [
        82620,
        82990,
        40
      ]
    ],
    "primary_language": [
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en",
      "en"
    ],
    "is_rotation_valid": [
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true,
      true
    ],
    "rotation_correction": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "is_table": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "is_diagram": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ]
  },
  "jstor_metadata": {
    "identifier": "jstor-108031",
    "title": "Researches in the Integral Calculus. Part I",
    "authors": "H. F. Talbot",
    "year": 1836,
    "volume": "126",
    "journal": "Philosophical Transactions of the Royal Society of London",
    "page_count": 40,
    "jstor_url": "https://www.jstor.org/stable/108031"
  }
}