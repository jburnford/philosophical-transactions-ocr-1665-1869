---
layout: default
title: "On a Theory of the Syzygetic Relations of Two Rational Integral Functions, Comprising an Application"
---

<div class="breadcrumb" data-pagefind-ignore>
    <a href="../../">Home</a>
    <span>&raquo;</span>
    <a href="../../volumes/143/">Volume 143</a>
    <span>&raquo;</span>
    Article
</div>

<article data-pagefind-body>
<div class="article-header">
    <h1 data-pagefind-meta="title">On a Theory of the Syzygetic Relations of Two Rational Integral Functions, Comprising an Application to the Theory of Sturm&#x27;s Functions, and That of the Greatest Algebraical Common Measure</h1>

    <div class="article-details">
        <div class="detail-item">
            <span class="detail-label">Author(s)</span>
            <span class="detail-value" data-pagefind-meta="author" data-pagefind-filter="author">J. J. Sylvester</span>
        </div>
        <div class="detail-item">
            <span class="detail-label">Year</span>
            <span class="detail-value" data-pagefind-meta="year" data-pagefind-filter="year">1853</span>
        </div>
        <div class="detail-item">
            <span class="detail-label">Volume</span>
            <span class="detail-value" data-pagefind-meta="volume" data-pagefind-filter="volume">143</span>
        </div>
        <div class="detail-item">
            <span class="detail-label">Pages</span>
            <span class="detail-value">143 pages</span>
        </div>
        <div class="detail-item">
            <span class="detail-label">Language</span>
            <span class="detail-value" data-pagefind-filter="language">en</span>
        </div>
        <div class="detail-item">
            <span class="detail-label">Journal</span>
            <span class="detail-value">Philosophical Transactions of the Royal Society of London</span>
        </div>
    </div>

    <div class="download-links" data-pagefind-ignore>
        <a href="../../downloads/jstor-108572.md" class="download-btn" download>Download MD</a>
        <a href="../../downloads/jstor-108572.json" class="download-btn secondary" download>Download JSON</a>
        <a href="https://www.jstor.org/stable/108572" class="download-btn secondary" target="_blank">View on JSTOR</a>
    </div>
</div>

<h2 data-pagefind-ignore>Full Text (OCR)</h2>
<div class="ocr-text">XVIII. On a Theory of the Syzygetic* relations of two rational integral functions, comprising an application to the Theory of Sturm&#x27;s Functions, and that of the greatest Algebraical Common Measure. By J. J. Sylvester, M.A. Dub., F.R.S., Barrister at Law, and formerly Professor of Natural Philosophy in University College, London.

Received and Read June 16, 1853.

INTRODUCTION.

&quot;How charming is divine philosophy!
Not harsh and crabbed as dull fools suppose,
But musical as is Apollo&#x27;s lute,
And a perpetual feast of nectar&#x27;d sweets,
Where no crude surfeit reigns!&quot;—Comus.

In the first section of the ensuing memoir, which is divided into five sections, I consider the nature and properties of the residues which result from the ordinary process of successive division (such as is employed for the purpose of finding the greatest common measure) applied to $f(x)$ and $\varphi(x)$, two perfectly independent rational integral functions of $x$. Every such residue, as will be evident from considering the mode in which it arises, is a syzygetic function of the two given functions; that is to say, each of the given functions being multiplied by an appropriate other function of a given degree in $x$, the sum of the two products will express a corresponding residue. These multipliers, in fact, are the numerators and denominators to the successive convergents to $\frac{\varphi x}{f x}$ expressed under the form of a continued fraction. If now we proceed à priori by means of the given conditions as to the degree in $(x)$ of the multipliers and of any residue, to determine such residue, we find, as shown in art. (2.), that there are as many homogeneous equations to be solved as there are constants to be determined; accordingly, with the exception of one arbitrary factor which enters into the solution, the problem is definite; and if it be further agreed that the quantities entering into the solution shall be of the lowest possible dimensions in respect of the coefficients of $f$ and $\varphi$, and also of the lowest numerical denomination, then the problem (save as to the algebraical sign of plus or minus) becomes absolutely determinate, and we can assign the numbers of the dimensions for the respective residues and syzygetic multipliers. The residues given by the method of successive division are easily seen not

* Conjugate would imply something very different from Syzygetic, viz. a theory of the Invariantive properties of a system of two algebraical functions.
to be of these lowest dimensions; accordingly there must enter into each of them a certain unnecessary factor, which, however, as it cannot be properly called irrelevant, I distinguish by the name of the Allotrious Factor. The successive residues, when divested of these allotrious factors, I term the Simplified Residues, and in article (3.) and (4.) I express the allotrious factors of each residue in terms of the leading coefficients of the preceding simplified residues of $f$ and $\varphi$. In article (5.) I proceed to determine by a direct method these simplified residues in terms of the coefficients of $f$ and $\varphi$. Beginning with the case where $f$ and $\varphi$ are of the same dimensions ($m$) in $x$, I observe that we may deduce from $f$ and $\varphi$ $m$ linearly independent functions of $x$ each of the degree $(m-1)$ in $x$, all of them syzygetic functions of $f$ and $\varphi$ (vanishing when these two simultaneously vanish), and with coefficients which are made up of terms, each of which is the product of one coefficient of $f$ and one coefficient of $\varphi$. These, in fact, are the very same ($m$) functions as are employed in the method which goes by the name of Bezout&#x27;s abridged method to obtain the resultant to (i.e. the result of the elimination of $x$ performed upon) $f$ and $\varphi$. As these derived functions are of frequent occurrence, I find it necessary to give them a name, and I term them the ($m$) Bezoutics or Bezoutian Primaries; from these ($m$) primaries $m$ Bezoutian secondaries may be deduced by eliminating linearly between them in the order in which they are generated,—first, the highest power of $x$ between two, then the two highest powers of $x$ between three, and finally, all the powers of $x$ between them all: along with the system thus formed it is necessary to include the first Bezoutian primary, and to consider it accordingly as being also the first Bezoutian secondary; the last Bezoutian secondary is a constant identical with the Resultant of $f$ and $\varphi$. When the $m$ times $m$ coefficients of the Bezoutian primaries are conceived as separated from the powers of $x$ and arranged in a square, I term such square the Bezoutic square. This square, as shown in art. (7.), is symmetrical above one of its diagonals, and corresponds therefore (as every symmetrical matrix must do) to a homogeneous quadratic function of ($m$) variables of which it expresses the determinant. This quadratic function, which plays a great part in the last section and in the theory of real roots, I term the Bezoutiant; it may be regarded as a species of generating function. Returning to the Bezoutic system, I prove that the Bezoutian secondaries are identical in form with the successive simplified residues. In art. (6.) I extend these results to the case of $f$ and $\varphi$ being of different dimensions in $x$. In art. (7.) I give a mechanical rule for the construction of the Bezoutic square. In art. (8.) I show how the theory of $f(x)$ and $\varphi(x)$, where the latter is of an inferior degree to $f$, may be brought under the operation of the rule applicable to two functions of the same degree at the expense of the introduction of a known and very simple factor, which in fact will be a constant power of the leading coefficient in $f(x)$. In art. (9.) I give another method of obtaining directly the simplified residues in all cases. In art. (10.) I present the process of successive division under its most general aspect. In arts. (11.) and (12.) I demonstrate the identity of the algebraical sign of the Bezoutian secondaries with
that of the simplified residues, generated by a process corresponding to the development of \( \frac{\varphi x}{f x} \) under the form of an improper continued fraction (where the negative sign takes the place of the positive sign which connects the several terms of an ordinary continual function). As the simplified residue is obtained by driving out an allotrious factor, the signs of the former will of course be governed by the signs accorded by previous convention to the latter; the convention made is, that the allotrious factors shall be taken with a sign which renders them always essentially positive when the coefficients of the given functions are real. I close the section with remarking the relation of the syzygetic factors and the residues to the convergents of the continued fraction which expresses \( \frac{\varphi x}{f x} \) and of the continued fraction which is formed by reversing the order of the quotients in the first named fraction.

In the second section I proceed to express the residues and syzygetic multipliers in terms of the roots and factors of the given functions; the method becoming as it may be said endoscopic instead of being exoscopic*, as in the first section. I begin in arts. (14.) and (15.) with obtaining in this way, under the form of a sum or double sum of terms involving factors and roots of \( f \) and \( \varphi \), and certain arbitrary functions of the roots in each term, a general representative, or to speak more precisely, a group of general representatives for a conjunctive of any given degree in \( x \) to \( f \) and \( \varphi \), i.e. a rational integral function of \( x \), which is the sum of the products of \( f \) and \( \varphi \) multiplied respectively by rational integral functions of \( x \), so as to vanish of necessity when \( f \) and \( \varphi \) simultaneously vanish. This variety of representatives refers not merely to the appearance of arbitrary functions, but to an essential and precedent difference of representation quite irrespective of such arbitrariness.

In articles (16.), (17.), (18.), (19.), (20.), (21.), I show how the arbitrary form of function entering into the several terms of any one (at pleasure) of the formulæ that represent a conjunctive of any given degree may be assigned, so as to make such conjunctive identical in form with a simplified residue of the same degree. The form of arbitrary function so assigned, it may be noticed, is a fractional function of the roots, so that the expression becomes a sum or double sum of fractions. I first prove in arts. (16.), (17.) that such sum is essentially integral, and I determine the weight of its leading coefficient in respect of the roots of \( f \) and \( \varphi \) (this weight being measured

---

* These words admit of an extensive and important application in analysis. Thus the methods for resolving an equation (or to speak more accurately, for making one equation depend upon another of a simpler form) furnished by Tschirnhausen and Mr. Jerrard (although not so presented by the latter) are essentially exoscopic; on the other hand, the methods of Lagrange and Abel for effecting similar objects are endoscopic. So again, the memoir of Jacobi, &quot;De Eliminatione,&quot; hereinafter referred to, takes the exoscopic, and the valuable &quot;Nota ad Eliminationem pertinens&quot; of Professor Richelet in Crelle&#x27;s Journal, the endoscopic view of the subject. In the present memoir (in which the two trains of thought arising out of these distinct views are brought into mutual relation) the subject is treated (chiefly but not exclusively) under its endoscopic aspect in the second, third and fourth sections, and exoscopically in the first and last sections.
by the number of roots of $f$ and $\phi$ conjointly, which appear in any term of such coefficient). Now in the succeeding articles I revert to the Bezoutic system of the first section, and beginning with the supposition of $m$ and $n$ being equal, I demonstrate that the most general form of a conjunctive of any degree in $x$ will be a linear function of the Bezoutics, from which it is easy to deduce that the simplified residues of any given degree in $x$ are the conjunctives whose weight in respect of the roots is a minimum; so that all conjunctives having that weight must be identical (to a numerical factor près), and any integral form of less weight apparently representing a conjunctive must be nugatory, every term vanishing identically. These results are then extended to the case of two functions of unlike degrees. The conclusion is, that the weight of the forms assumed in (16.) and (17.) being equal to the minimum weight, they must (unless they were to vanish, which is easily disproved) represent the simplified residues, or which is the same thing, the Bezoutian secondaries.

We thus obtain for each simplified residue a number of essentially distinct forms of representation, but all of which must be identical to a numerical factor près, a result which leads to remarkable algebraical theorems.

The number of these different formulæ depends upon the degree of the residue; there being only one for the last or constant residue, two for the last but one, three for the last but two, and so on. The formulæ continue to have a meaning when their degree in $x$ exceeds that of $f$ or $\phi$; but then, as although always representing conjunctives, they no longer represent residues, this identity no longer continues to subsist. In articles (22.), (23.), (24.), (25.), I enter into some developments connected with the general formulæ in question: these, it may be observed, are all expressed by means of fractions containing in the numerator and denominator products of differences; the differences in the numerator products being taken between groups of roots of $f$ and groups of roots of $\phi$; and in the denominator between roots of $f$ inter se and roots of $\phi$ inter se. A great enlargement is thus opened out to the ordinary theory of partial fractions.

In art. (26.) I find the numerical ratios between the different formulæ which represent (to a numerical factor près) the same simplified residue, and in arts. (27.) and (28.) I determine the relations of algebraical sign of these formulæ to the simplified residues or Bezoutian secondaries. In art. (29.) I determine the syzygetic multipliers corresponding to any given residue in terms of the factors and roots of the given functions; but the expressions for these, which are closely analogous to those for the residues, cease to be polymorphic. They are obtained separately from the syzygetic equation, and it is worthy of notice, that to obtain the one we use the first of the polymorphic expressions for the residue, and to obtain the other the opposite extremity of the polymorphic scale. In the subsequent articles of this section, by aid of certain general properties of continued fractions, I establish a theorem of reciprocity between the series of residues and either series of syzygetic multipliers.
Section III. is devoted to a determination of the values of the preceding formulæ for the residues and multipliers in the case applicable to M. Sturm&#x27;s theorem, where $\phi(x)$ becomes the differential derivative of $fx$. It becomes of importance to express the formulæ for this case in terms of their roots and factors of $fx$ alone, without the use of the roots and factors of $f&#x27;x$, which will of course be functions of the former.

By selecting a proper form out of the polymorphic scale, the fractional terms of the series for each residue in this case become separately integral, and we obtain my well-known formulæ for the simplified residues (Sturm&#x27;s reduced auxiliary functions) in terms of the factors and the squared differences of partial groups of roots. This is shown in art. (35.). In art. (36.) the multiplier of $f&#x27;x$ in the syzygetic equation is expressed by formulæ of equal simplicity, and in a certain sense complementary to the former. This method, however, does not apply to obtaining expressions for the multiplier of $fx$ in the same equation in terms of the roots and factors of $fx$; for the separate fractions whose sum represents any one of these factors it will be found do not admit of being expressed as integral functions of the roots and factors. To obviate this difficulty I look to the syzygetic equation itself, which contains five quantities, viz. the given function, its first differential derivative, the residue of a given degree, and the two multipliers, all of which, except the multiplier of $fx$, are known, or have been previously determined as rational integral functions of the roots and factors of $fx$. I use this equation itself for determining the fifth quantity, the multiplier in question. To perform the general operations by a direct method required for this would be impossible; the difficulty is got over by finding, by means of the syzygetic equation, the particular form that the result must assume when certain relations of equality spring up between the roots of $fx$; and then, by aid of these particular determinations, the general form is demonstratively inferred.

This investigation extends over arts. (38.), (39.), (40.), (41.), (42.), (43.). It turns out that the expressions for the multipliers of $fx$ are of much greater complexity than for the multipliers of $f&#x27;x$ or for the residues. Any such multiplier consists of a sum of parts, each of which, as in the case of the residues and of the factors of $f&#x27;x$, is affected with a factor consisting of the squared differences of a group of roots; but the other factor, instead of being simply (as for the residues and factors before mentioned) a product of certain factors of $fx$, consists of the sum of a series of products of sums of powers by products of combinations of factors of $fx$, each of which series is affected with the curious anomaly of its last term, becoming augmented in a certain numerical ratio beyond what it should be, in order to be conformable to the regular flow of the preceding terms in the series*.

The fourth section opens with the establishment of two propositions concerning

* The syzygetic multipliers are identical with the numerators and denominators (expressed in their simplest form) of the successive convergents to the continued fraction which expresses $\frac{f&#x27;x}{fx}$.
quadratic functions which are made use of in the sequel. Art. (28.) contains the proof of a law which, although of extreme simplicity, I do not remember to have seen, and with which I have not found that analysts are familiar: I mean the law of the constancy of signs (as regards the number of positive and negative signs) in any sum of positive and negative squares into which a given quadratic function admits of being transformed by substituting for the variables linear functions of the variables with real coefficients. This constant number of positive signs which attaches to a quadratic function under all its transformations, and which is a transcendental function of the coefficients invariable for real substitutions, may be termed conveniently its inertia, until a better word be found. This inertia it is shown in art. (26.), by aid of a theorem identical with one formerly given by M. Cauchy, is measured by the number of combinations of sign in the series of determinants of which the first is the complete determinant of the function; the second, the determinant when one variable is made zero; the next, the determinant when another variable as well as the first is made zero, and so on, until all the variables are exhausted, and the determinant becomes positive unity. In art. (46.) I give some curious and interesting expressions for the residues and syzygetic multipliers, under the form of determinants communicated to me by M. Hermite; and in art. (47.) I show how, by aid of the generating function which M. Hermite employs, and of the law of inertia stated at the opening of the section, an instantaneous demonstration may be given of the applicability of my formulæ for M. Sturm&#x27;s functions for discovering the number of real roots of $fx$, without any reference to the rule of common measure; and moreover, that these formulæ may be indefinitely varied, and give the generating function, out of which they may be evolved in its most general form. Had the law of inertia been familiar to mathematicians, this constructive and instantaneous method of finding formulæ for determining the number of real roots within prescribed limits would, in all probability, have been discovered long ago, as an obvious consequence of such law. I then proceed in arts. (48.) and (49.), to inquire as to the nature of the indications afforded by the successive simplified residues to two general functions $f$ and $\phi$; and I find that the succession of signs of these residues serves to determine the number of roots of $f$ or $\phi$, comprised between given limits after all pairs of roots of either function, contained within the given limits, not separated by roots of the other function, have been removed, and the operation, if necessary, repeated toties quoties until no two roots of either function are left unseparated by roots of the other; or in other words, until every root finally retained in one function is followed by a root of the other, or else by one of the assigned limits. The system of roots comprised between given limits thus reduced I call the effective scale of intercalations; such a scale may begin with a root of the numerator or of the denominator of $\frac{\phi x}{f&#x27;x}$; and upon this and the relative magnitudes of the greatest root of $\phi x$ and $fx$ it will depend whether in the series of residues (among which $fx$ and $\phi x$ are for this purpose to be counted)
changes will be lost or gained as \( x \) passes from positive infinity to negative infinity. In art. (50.) I observe that the theory of real roots of a single function given by M. Sturm&#x27;s theorem is a corollary to this theory of the intercalations of real roots of two functions, depending upon the well-known law, that odd groups of the limiting function \( f&#x27;x \) lie between every two consecutive real roots of \( fx \). In art. (51.) I verify the law of reciprocity, already stated to exist between the residues of \( fx \) and \( \phi x \), by an \(\textit{à posteriori}\) method founded on the theory of intercalations. In arts. (52.), (53.), (54.), I obtain a remarkable rule, founded upon the process of common measure, for finding a superior and inferior limit in an infinite variety of ways to the roots of any given function. This method stands in a singular relation of contrast to those previously known. All previous methods (including those derived through Newton&#x27;s Rule) proceed upon the idea of treating the function whose roots are to be limited as made up of the sum of parts, each of which retains a constant sign for all values of the variable external to the quantities which are to be shown to limit the roots. My method, on the other hand, proceeds upon the idea of treating the function as the product of factors retaining a constant sign for such values of the variable. In art. (55.), the concluding article of the fourth section, I point out a conceivable mode in which the theory of intercalations may be extended to systems of three or more functions.

In Section V. arts. (56.), (57.), I show how the total number of effective intercalations between the roots of two functions of the same degree is given by the inertia of that quadratic form which we agreed to term the Bezoutiant to \( f \) and \( \phi \); and in the following article (58.) the result is extended to embrace the case contemplated in M. Sturm&#x27;s theorem; that is to say, I show, that on replacing the function of \( x \) by a homogeneous function of \( x \) and \( y \), the Bezoutiant to the two functions, which are respectively the differential derivatives of \( f \) with respect to \( x \) and with respect to \( y \), will serve to determine by its form or inertia the total number of real roots and of equal roots in \( f(x) \). The subject is pursued in the following arts. (59.), (60.). The concluding portion of this section is devoted to a consideration of the properties of the Bezoutiant under a purely morphological point of view; for this purpose \( f \) and \( \phi \) are treated as homogeneous functions of two variables \( x, y \), instead of being regarded as functions of \( x \) alone. In arts. (61.), (62.), (63.), it is proved that the Bezoutiant is an invariantive function of the functions from which it is derived; and in art. (64.) the important remark is added, that it is an invariant of that particular class to which I have given the name of Combinants, which have the property of remaining unaltered, not only for linear transformations of the variables, but also for linear combinations of the functions containing the variables, possessing thus a character of double invariability. In arts. (65.), (66.), I consider the relation of the Bezoutiant to the differential determinant, so called by Jacobi, but which for greater brevity I call the Jacobian. On proper substitutions being made in the Bezoutiant of the \((m)\) variables which it contains \((m\) being the degree in \( x, y \) of \( f \) and \( \phi \)), the Bezoutiant becomes identical with the Jacobian to \( f \) and \( \phi \); but as it is afterwards
shown, this is not a property peculiar to the Bezoutiant; in fact there exists a whole family of quadratic forms of $m$ variables, lineo-linear (like the Bezoutiant) in respect of the coefficients in $f$ and $\varphi$, all of which enjoy the same property. The number of individuals of such family must evidently be infinite, because any linear combination of any two of them must possess a similar property; I have discovered, however, that the number of independent forms of this kind is limited, being equal to the number of odd integers not greater than the degree of the two functions $f$ and $\varphi$. In arts. (67.) and (68.), I give the means of constructing the scale of forms, which I term the constituent or fundamental scale, of which all others of the kind are merely numericolinear combinations. This scale does not directly include the Bezoutiant within it, and it becomes an object of interest to determine the numbers which connect the Bezoutiant with the fundamental forms; this calculation I have carried on (in arts. (69.), (70.), (71.)) from $m=1$ to $m=6$ inclusive, and added an easy method of continuing indefinitely. In this method the numbers in the linear equation corresponding to any value of $m$ are determined successively, and each made subject to a verification before the next is determined, there being always pairs of equations which ought to bring out the same result for each coefficient.

In the next and concluding art. (72.), I remark upon the different directions in which a generalization may be sought of the subject-matter of the ideas involved in M. Sturm&#x27;s theorem, and of which the most promising is, in my opinion, that which leads through the theory of intercalations. Some of the theorems given by me in this paper have been enunciated by me many years ago, but the demonstrations have not been published, nor have they ever before been put together and embodied in that compact and organic order in which they are arranged in this memoir,—the fruit of much thought and patient toil, which I have now the honour of presenting to the Royal Society.

June 16, 1853.

In a supplemental part to the third section I have given expressions in terms of the roots of $\varphi x$ and $fx$ for the quotients which arise in developing $\frac{\varphi x}{fx}$ under the form of a continued fraction, and some remarkable properties concerning these quotients. In a supplemental part to the fourth section I have given an extended theory of my new method of finding limits to the real roots of any algebraical equation. This method, so extended, possesses a marked feature of distinction from all preceding methods used for the same purpose, inasmuch as it admits in every case of the limits being brought up into actual coincidence with the extreme roots, whereas in other methods a wide and arbitrary interval is in general necessarily left between the roots and the limits.
Section I.

On the complete and simplified residues generated in the process of developing under the form of a continued fraction, an ordinary rational algebraical fraction.

Art. (1.). Let \( P \) and \( Q \) be two rational integral functions of \( x \), and suppose that the process of continued successive division leads to the equations

\[
\begin{align*}
P - M_0 Q + R_1 &amp;= 0 \\
Q - M_1 R_1 + R_2 &amp;= 0 \\
R_1 - M_2 R_2 + R_3 &amp;= 0 \\
&amp;\vdots \\
&amp;\vdots
\end{align*}
\]

so that

\[
\frac{Q}{P} = \frac{1}{M_0} - \frac{1}{M_1} - \frac{1}{M_2} - \ldots &amp;c.
\]

which is what I propose to call an improper continued fraction, differing from a proper only in the circumstance of the successive terms being connected by negative instead of positive signs.

\( M_0, M_1, M_2, \ldots, R_1, R_2, R_3, \ldots \) are, of course, functions of \( x \): the latter we may agree to call the 1st, 2nd, 3rd, \ldots residues (in order to avoid the use of the longer term &quot;residues with the signs changed&quot;); and by way of distinction from what they become when certain factors are rejected, we may call \( R_1, R_2, R_3, \ldots \) the complete residues. Each such complete residue will in general be of the form \( \frac{N_i \cdot g_i}{D_i} \), \( N_i \) and \( D_i \) being integral functions of the coefficients only of \( P \) and \( Q \), but \( g_i \) an integral function of these coefficients, and of \( x \): \( \rho_i \) may then be termed the \( i \)th simplified residue, and \( \frac{N_i}{D_i} \) the \( i \)th allotrious factor. Suppose \( P \) to be of \( m \) and \( Q \) of \( n \) dimensions in \( x \), and \( m - n = e \), the process of continued division may be so conducted, that all the residues may contain only integer powers of \( x \); and we may upon this supposition make \( M_0 \) of \( e \) dimensions, and \( M_1, M_2, M_3, \ldots \) each of one dimension only in \( x \); so that \( R_1, R_2, R_3, \ldots \) will be respectively of \((n-1), (n-2), (n-3), \ldots\) dimensions in \( x \).

\( P \) and \( Q \) are supposed to be perfectly unrelated, and each the most general function that can be formed of the same degree. From (1.) we obtain

\[
\begin{align*}
R_1 &amp;= M_0 \cdot Q - P \\
R_2 &amp;= M_1 R_1 - Q \\
&amp;= (M_0 M_1 - 1) Q - M_1 \cdot P \\
R_3 &amp;= (M_0 M_1 M_2 + M_0 + M_2) Q - (M_1 M_2 - 1) P \\
&amp;\vdots \\
&amp;\vdots
\end{align*}
\]

MDCCCLIII.
and in general we shall have

\[ R_i = Q_i \cdot Q + P_i \cdot P, \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots (4.) \]

where it is evident that \( Q_i \) will be of \( e + (i - 1) \), and \( P_i \) of \( (i - 1) \) dimensions in \( x \).

Art. (2.) Hence it follows that the ratios \( P_i : Q_i : R_i \) may be ascertained by the direct application of the method of indeterminate coefficients, for \( Q_i \) will contain \( e + i \), and \( P_i \) will contain \( i \) disposable constants, making \( e + 2i \) disposable constants in all.

Again, \( Q_i \cdot Q \) and \( P_i \cdot P \) will each rise to the degree \( n + e + 2 - 1 \) in \( x \); but their sum \( R_i \) is to be only of \( n - i \) dimensions in \( x \). Hence we have to make \( (n + e + i - 1) - (n - i) \), i.e., \( e + 2i - 1 \) quantities (which are linear in respect to the given coefficients in \( P \) and \( Q \), as well as in respect to the new disposable constants in \( P_i \) and \( Q_i \)) all vanish, that is to say, there will be \( e + 2i - 1 \) linear homogeneous equations to be satisfied by means of \( e + 2i \) disposable quantities; the ratios of these latter are, therefore, determinate, so that we may write

\[
\begin{align*}
P_i &amp;= \lambda_i(P_i) \\
Q_i &amp;= \lambda_i(Q_i) \\
R_i &amp;= \lambda_i(R_i)
\end{align*}
\]

and when \( (P_i), (Q_i), (R_i) \) are taken prime to one another, it is obvious that \( (R_i) \) will be in all of \( e + 2i \) dimensions in the given coefficients, i.e., of \( i \) in respect of the coefficients of \( P \), and of \( e + i \) in respect of those of \( Q \): \( \lambda_i \) will correspond to what I have previously called the allotrious factor; being in fact foreign to the value of \( R_i \) as determined by means of the equation (4.), and arising only from the particular method employed to obtain it through the medium of the system (1.): it becomes a matter of some interest and importance to determine the values of this allotrious factor for different values of \( i \)*.

---

* These are identical with what I termed quotients of succession in the London and Edinburgh Philosophical Magazine (December, 1839); but by an easily explicable error of inadvertence, the quantities &quot; \( Q_1 \)&quot; &quot; \( Q_2 \)&quot; &amp;c. therein set out are not as they are therein stated to be, the quotients of succession or allotrious factors themselves, but the ratios of each such to the one preceding, if in the series; so that—

&quot; \( Q_1 \)&quot; is \( \lambda_1 \)

&quot; \( Q_2 \)&quot; is \( \lambda_2 \)

&quot; \( Q_3 \)&quot; is \( \lambda_3 \)

&amp;c. . . .

This error is corrected by my distinguished friend M. Sturm (Liouville&#x27;s Journal, tom. viii. 1842. Sur un théorème d&#x27;Algèbre de M. Sylvester), who appears, however, to have overlooked that I was obviously well acquainted with the existence and nature of these factors, and their essential character, of being perfect squares in the case contemplated in his memoir and my own. MM. Borchardt, Terquem, and other writers, in quoting my formulæ for M. Sturm&#x27;s auxiliary functions, have thus been led into the error of alluding to them as completed by M. Sturm.
Art. (3.). This may be done by the following method, which is extremely simple, and would admit of a considerable extension in its applications, were it not beside my immediate purpose to digress from the objects set out in the title to the memoir, by entering upon an investigation of the special or singular cases which may arise in the process of forming the continued fraction, when one or more of the leading coefficients in any of the residues vanish; such an inquiry would require a more general character to be imparted to the values of the quotients and residues than I shall for my present purposes care to suppose.

Let us begin with supposing \( e = 1 \), and write

\[
f = ax^n + bx^{n-1} + cx^{n-2} + \ldots + \text{&amp;c.}
\]

\[
\varphi = \alpha x^n + \beta x^{n-1} + \gamma x^{n-2} + \ldots + \text{&amp;c.}
\]

Let \( \psi \) be the first residue of \( \frac{f}{\varphi} \), and \( \omega \) of \( \frac{\varphi}{\psi} \), and therefore of \( \frac{\varphi}{\alpha^2 \psi} \), so that \( \omega \) is the second residue of \( \frac{f}{\varphi} \).

Let \( \omega = \lambda(\omega) \), \( \omega \) being entirely integer, and \( \lambda \) a function of the coefficients in \( f \) and \( \varphi \).

If we make \( \lambda = \frac{N}{D} \), \( N \) and \( D \) being integer functions, \( D \) will evidently be \( L^2 \); where \( L \) denotes the first coefficient in the simplified residue \( \alpha^2 \varphi \), and is evidently of two dimensions in \( \alpha, \beta, \&amp;c. \), and of one in \( a, b, \&amp;c. \); \( D\omega \) is therefore of \( 2 \times 2 + 1 \), i.e., five dimensions in \( \alpha, \beta, \&amp;c. \), and of two dimensions in \( a, b, \&amp;c. \); but \( \omega \) (by virtue of what has been observed of the equations in system (5.)) is of three dimensions in \( \alpha, \beta, \&amp;c. \), and of two in \( a, b, \&amp;c. \). Hence \( N \) is of two dimensions in \( \alpha, \beta, \&amp;c. \), and of none in \( a, b, \&amp;c. \). This enables us at once to perceive that \( N = \alpha^2 \),

for \( \psi \) is of the form \( f - (px + q)\varphi \),

and \( \omega \) is of the form \( \varphi - (p&#x27;x + q&#x27;)\psi \)

But \( N = 0 \) makes \( \omega \) vanish, and therefore, upon this supposition, \( f \) and \( \varphi \) would appear to have a common algebraical factor \( \psi \), that is to say, \( N \) vanishing, would appear to imply that the resultant of \( f \) and \( \varphi \) must vanish, so that \( N \) would appear to be contained as a factor in this general resultant, which latter is, however, clearly indecomposable into factors—a seeming paradox—the solution of which must be sought for in the fact, that the equation \( N = 0 \) is incompatible with the existence of the usual equations (7.) connecting \( f, \varphi, \psi \) and \( \omega \): but this failure of the existence of the equations (7.) (bearing in mind that \( N \) has been shown to be a function only of the set of coefficients \( \alpha, \beta, \&amp;c. \)), can only happen by reason of \( \alpha \) vanishing whenever \( N \) vanishes; \( \alpha \) must therefore be a root of \( N \), or which is the same thing, \( N \) a power of \( (\alpha) \) and hence \( N = \alpha^2 \).

The same result may be obtained à posteriori by actually performing the successive divisions; if the coefficients of any dividend be \( a, b, c, d, \&amp;c. \), and of the divisor
α, β, γ, δ, &amp;c., the first remainder forming the second divisor will be easily seen to have for its coefficients—

\[
\frac{1}{a^2} \begin{vmatrix}
a &amp; b &amp; c \\
0 &amp; α &amp; β \\
α &amp; β &amp; γ
\end{vmatrix}, \quad \frac{1}{a^2} \begin{vmatrix}
a &amp; b &amp; d \\
0 &amp; α &amp; β \\
α &amp; β &amp; δ
\end{vmatrix}, \quad \frac{1}{a^2} \begin{vmatrix}
a &amp; b &amp; e \\
0 &amp; α &amp; β \\
α &amp; β &amp; ε
\end{vmatrix} &amp;c.
\]

Hence the coefficients in the next remainder (making \[
\begin{vmatrix}
a &amp; b &amp; c \\
0 &amp; α &amp; β \\
α &amp; β &amp; γ
\end{vmatrix} = m
\]) will be each of the form of the compound determinant,—

\[
\frac{1}{m^3} \begin{vmatrix}
α &amp; β &amp; γ \\
a &amp; b &amp; c &amp; a &amp; b &amp; d \\
0 &amp; α &amp; β &amp; 0 &amp; α &amp; γ \\
α &amp; β &amp; γ &amp; α &amp; β &amp; δ \\
a &amp; b &amp; c &amp; a &amp; b &amp; d &amp; a &amp; b &amp; e \\
0 &amp; α &amp; β &amp; 0 &amp; α &amp; γ &amp; 0 &amp; α &amp; δ \\
α &amp; β &amp; γ &amp; α &amp; β &amp; δ &amp; α &amp; β &amp; ε
\end{vmatrix}.
\]

The compound determinant above written will be the first coefficient in the remainder under consideration; the subsequent coefficients will be represented by writing \(f, φ; g, γ, &amp;c.\), respectively in lieu of \(e, ε\). Omitting the common multiplier \(\frac{1}{m^3}\), the determinant above written is equal to

\[
\begin{vmatrix}
a &amp; b &amp; e &amp; a &amp; b &amp; e &amp; a &amp; b &amp; d &amp; a &amp; b &amp; d \\
0 &amp; α &amp; β &amp; × &amp; 0 &amp; α &amp; d &amp; − &amp; 0 &amp; α &amp; γ &amp; × &amp; 0 &amp; α &amp; γ \\
α &amp; β &amp; γ &amp; α &amp; β &amp; ε &amp; α &amp; β &amp; δ &amp; α &amp; β &amp; δ \\
a &amp; b &amp; c &amp; a &amp; b &amp; d &amp; a &amp; b &amp; c \\
0 &amp; α &amp; β &amp; 0 &amp; α &amp; γ &amp; −γ &amp; 0 &amp; α &amp; β \\
α &amp; β &amp; γ &amp; α &amp; β &amp; δ &amp; α &amp; β &amp; γ
\end{vmatrix}.
\]

The last written pair of terms are together equal to

\[
\begin{vmatrix}
a &amp; b &amp; c \\
0 &amp; α &amp; β \\
α &amp; β &amp; γ
\end{vmatrix} \times \left\{ -dβα^2 + cγα^2 + aα(βδ − γ^2) \right\},
\]

which is of the form \(α^2A − a^2β^2(βδ − γ^2)α\), and the sum of the first written pair is of the form \(α^2B + (aβ^2.aβδ − aγβ.aγβ)α\). Hence the entire determinant is of the form \(α^2(A + B)\), showing that \(α^2\) will enter as a factor into this and every subsequent coefficient in the second remainder, as previously demonstrated above.

It may, moreover, be noticed, that this remainder, when \(α^2\) has been expelled, will for general values of the coefficients be numerically as well as literally in its lowest
terms, as evinced by the fact that there exist terms (ex.gr. \(aa^2\gamma e\)) having \(\pm 1\) for their numerical part. The same explicit method might be applied to show, that if the first divisor were \(e\) degrees instead of being only one degree in \(x\) lower than the first dividend, \(a^{e+1}\) would be contained in every term of the second residue; the difficulty, however, of the proof by this method augments with the value of \(e\); but the same result springs as an immediate consequence from the method first given, which remains good mutatis mutandis for the general case, as may easily be verified by the reader. Applying now this result to the functions \(P\) and \(Q\), supposed to be of the respective degrees \(n\) and \(n-e\) in \(x\), and calling the coefficients of the leading terms in the successive simplified residues \(a_1, a_2, a_3, \&amp;c.\), and the leading coefficient in \(Q\) \(a\), and before denoting the successive allotrious factors by \(\lambda_1, \lambda_2, \&amp;c.\), it will readily be seen that

\[
\lambda_1 = \frac{1}{a^{e+1}} \quad \lambda_2 = \frac{1}{a_1} \quad \lambda_3 = \frac{1}{a_2} \quad \lambda_4 = \frac{1}{a_3}, \&amp;c.,
\]

i.e. \(\lambda_1 = \frac{1}{a^{e+1}} \quad \lambda_2 = \frac{a^{e+1}}{a_1} \quad \lambda_3 = \frac{a_1^2}{a^{e+1}a_2} \quad \lambda_4 = \frac{a^{e+1}a_2}{a_1^2a_3}, \&amp;c.\),

and in general

\[
\lambda_{2m+1} = \frac{1}{a^{e+1}} \quad \lambda_{2m} = \frac{1}{a_1a_2a_3\cdots a_{2m-1}}
\]

(8.)

Art. (4.). Strictly speaking, we have not yet fully demonstrated that the complete allotrious factors are represented by the values above given for \(\lambda\), but only that these latter are contained as factors in the allotrious factors; we must further prove that there exist no other such factors. This may be shown as follows: it is obvious from the nature of the process that the complete residues will always remain of one dimension in respect of the given coefficients, i.e. first of one dimension in the set \(a, b, c, \&amp;c.\), and of zero dimensions in \(\alpha, \beta, \gamma, \&amp;c.\); then conversely, of one dimension in \(a, \beta, \gamma, \&amp;c.\), and of zero dimensions in \(a, b, c, \&amp;c.\), and so on, the residues being evidently required to conform in their dimensions to those of the first dividend and the first divisor alternately. These coefficients then are always of unit dimensions in respect to the given coefficients; whereas it has been shown (art. 2.) that the simplified residues in respect to these coefficients are successively of the dimensions \(2+e, 4+e, 6+e, \&amp;c.\).

Let the complete residue corresponding to \(\lambda_{2m}\) be \(M.\lambda_{2m}\cdot a_{2m}\),

\[
i.e. M.\frac{a^{e+1}}{a_1^2a_3^2a_5^2\cdots a_{2m-1}^2}
\]

or say \(M.L\); in passing from \(a_{2q}\) to \(a_{2q+1}\) the dimensions rise 2 units for all values of \(q\) except zero, and when \(q=0\) the dimensions increase per saltum from 1 to \(2+e\); hence the total dimensions of \(L\) in the joint coefficients will be

\[
(e+1)-(2e+2)-(m-1)4+4m+e=1,
\]
and therefore $M$ is of zero dimensions, and $\lambda_{2m}$ is the complete allotrious factor. In like manner if the complete residue corresponding to $\lambda_{2m+1}$ be $M.\lambda_{2m+1}.\alpha_{2m+1}$,

\[ i.e. \quad M \frac{1}{\alpha^{e+1}} \cdot \frac{\alpha^2}{\alpha_2} \cdot \frac{\alpha^3}{\alpha_3} \cdot \ldots \cdot \frac{\alpha_{2m-1}}{\alpha_{2m}} \cdot \alpha_{2m+1}, \]

or say $M.L$, the dimensions of $L$ will be

\[ -(e+1)-m.4+(e+2.(2m+1)), \quad i.e. \quad 1, \]

and hence, as in the preceding case, $M$ is of zero dimensions, and $\lambda_{2m+1}$ is the complete allotrious factor.

Art. (5.). I proceed to show how the simplified residues may be most conveniently obtained by a direct process, identical with that which comes into operation in applying to the two given functions of $x$ the method familiarly known under the name of Bezout&#x27;s abridged method of elimination. Let us call the two given functions $U$ and $V$, and commence with the case where $U$ and $V$ are of equal dimensions ($n$) in $x$. The simplified $r$th residue will then be a function of $n-r$ dimensions in $x$, and of $r$ dimensions in respect of each given set of coefficients, and may be taken equal to $V_r.U+U_r.V$, where $V_r$ and $U_r$ are each of $(r-1)$ dimensions in $x$.

Let

\[ U = a_0.x^n + a_1.x^{n-1} + a_2.x^{n-2} + \ldots + a_n, \]
\[ V = b_0.x^n + b_1.x^{n-1} + b_2.x^{n-2} + \ldots + b_n, \]

we may write in general \{ $m$ being taken any positive integer not exceeding $n$\},

\[ U = (a_0x^m + a_1x^{m-1} + \ldots + a_m)x^{n-m} + (a_{m+1}x^{n-m-1} + a_{m+2}x^{n-m-2} + \ldots + a_n) \]
\[ V = (b_0x^m + b_1x^{m-1} + \ldots + b_m)x^{n-m} + (b_{m+1}x^{n-m-1} + b_{m+2}x^{n-m-2} + \ldots + b_n). \]

Hence

\[ (b_0x^m + b_1x^{m-1} + \ldots + b_m)U - (a_0x^m + a_1x^{m-1} + \ldots + a_m)V = mK_1x^{n-1} + mK_2x^{n-2} + mK_3x^{n-3} + \ldots + mK_n, \]  

where if we use $(r, s)$ to denote $a_r.b_s-a_s.b_r$ for all values of $r$ and $s$, we have

\[ mK_1=(0,m+1), \quad mK_2=(0,m+2)+(1,m+1), \quad mK_3=(0,m+3)+(1,m+2)+(2,m+1), \]

and in general $mK_i=\Sigma(r,s)$, the values of $r$ and $s$ admissible within the sign of summation being subject to the two conditions, one the equality $r+s=m+i$, the other the inequality $r$ less than $i$. By giving to $m$ all the different values from 0 to $m-1$ in succession, and calling $b_0x^m+b_1x^{m-1}+\ldots+b_m$, $a_0x^m+a_1x^{m-1}+\ldots+a_m$ respectively $Q_m$ and $P_m$, we have

\[ Q_0.U-P_0.V=K_1x^{n-1}+K_2x^{n-2}+\ldots+K_n \]
\[ Q_1.U-P_1.V=K_1x^{n-1}+K_2x^{n-2}+\ldots+K_n \]
\[ Q_2.U-P_2.V=K_1x^{n-1}+K_2x^{n-2}+\ldots+K_n \]
\[ \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \]
\[ Q_{n-1}.U-P_{n-1}.V=n_1K_1x^{n-1}+n_1K_2x^{n-2}+\ldots+n_1K_n \]
The right-hand members of these \( n \) equations I shall henceforth term the Bezoutians to \( U \) and \( V \).

[The determinant formed by arranging in a square the \( n \) sets of coefficients of the \( n \) Bezoutians, and which I shall term the Bezoutian matrix, gives, as is well known, the Resultant (meaning thereby the Result in its simplest form of eliminating the variables out) of \( U \) and \( V \).]

Eliminating dialytically, first \( x^{n-1} \) between the first and second, then \( x^{n-1} \) and \( x^{n-2} \) between the first, second and third, and so on, and finally, all the powers of \( x \) between the 1st, 2nd, 3rd, \( n \)th of these Bezoutians, and repeating the first of them, we obtain a derived set of \( n \) equations, the right-hand members of which I shall term the secondary Bezoutians to \( U \) and \( V \), this secondary system of equations being

\[
Q_0 \cdot U - P_0 \cdot V = K_1 x^{n-1} + K_2 x^{n-2} + K_3 x^{n-3} + \ldots + K_n
\]

\[
(K_1 Q_0 - K_1 Q_1) U - (K_1 P_0 - K_1 P_1) V = L_1 x^{n-2} + L_2 x^{n-3} + \ldots + L_{n-1}
\]

\[
((K_1, K_2 - K_1, K_2) Q_0 + (K_1, K_2 - K_1, K_2) Q_1 + (K_1, K_2 - K_1, K_2) Q_2) U
\]

\[
-(K_1, K_2 - K_1, K_2) P_0 + (K_1, K_2 - K_1, K_2) P_1 + (K_1, K_2 - K_1, K_2) P_2) V
\]

\[
= M_1 x^{n-3} + M_2 x^{n-4} + \ldots + M_{n-2}
\]

\&amp;c. = &amp;c.

And we can now already without difficulty establish the important proposition, that the successive simplified residues to \( \frac{U}{V} \), expanded under the form of an improper continued fraction, abstracting from the algebraical sign (the correctness of which also will be established subsequently), will be represented by the \( n \) successive Secondary Bezoutians to the system \( U, V \).

For if we write the system of equations (11.) under the general form

\[
S_i \cdot U - H_i \cdot V = A_i x^{n-i} + B_i x^{n-i-1} + \ldots + \text{&amp;c.},
\]

the degree of \( S_i \) and \( H_i \) in \( x \) will be that of \( Q_{i-1} \) and \( P_{i-1} \), i.e., \( i-1 \); and the dimensions of \( A_i, B_i, \ldots \), in respect of each set of coefficients is evidently (\( i \)); consequently, by virtue of art. (2.), \( A_i x^{n-i} + B_i x^{n-i-1} + \ldots + \text{&amp;c.} \), which is the \( i \)th Bezoutian, will (saving at least a numerical factor of a magnitude and algebraical sign to be determined, but which (when proper conventions are made) will be subsequently proved to be +1) represent the \( i \)th simplified residue to \( \frac{U}{V^*} \), as was to be shown.

Art. (6.). More generally, suppose \( U \) and \( V \) to be respectively of \( n+e \) and \( n \) dimensions in \( x \).

* \( V \) is supposed to be taken as the first divisor, and the term residue is used, as hitherto in this paper, throughout in the sense appertaining to the expansion conducted, so as to lead to an improper continued fraction, in that sense, in fact, in which it would, more strictly speaking, be entitled to the appellation of excess rather than that of residue.
Let

\[ U = a_0 x^n + a_1 x^{n-1} + \ldots + a_e x^{n-e} + \ldots \]

\[ V = b_0 x^n + b_1 x^{n-1} + \ldots \]

Making

\[ U = (a_0 x^m + a_1 x^{m-1} + \ldots + a_{m+e}) x^{n-m} + (a_{m+1} x^{n-m-1} + \ldots + a_{m+e}) \]

\[ V = (b_0 x^m + b_1 x^{m-1} + \ldots + b_m) x^{n-m} + (b_{m+1} x^{n-m-1} + \ldots + b_n), \]

we obtain the equation

\[ Q_m \cdot U - P_{e+m} \cdot V = K_1 x^{n+e-1} + K_2 x^{n+e-2} + \ldots + K_m, \ldots \quad (12.) \]

where

\[ Q_m = (b_0 x^m + \ldots + b_m) P_{e+m} = (a_0 x^m + \ldots + a_{m+e}) \]

\[ K_1 = a_0 \cdot b_{m+1}; \quad K_2 = a_0 \cdot b_{m+2} + a_1 \cdot b_{m+1}; \quad \ldots \quad K_e = a_0 \cdot b_{m+e} + a_1 \cdot b_{m+e-1} + \ldots + a_e \cdot b_m \]

\[ K_{e+1} = a_0 \cdot b_{m+e+1} + \ldots + a_{e+1} \cdot b_m - a_{e+1} \cdot b_{m+1} \cdot b_0 \&amp;c.; \ldots \]

By giving \( m \) every integer value from 0 to \( (n-1) \) inclusive, we thus obtain \( n \) equations of the form of (12.), each of the degree \( n+e-1 \) in \( x \), and of one dimension in regard to each set of coefficients.

In addition to these equations we have the (e) equations of the form

\[ x^\mu \cdot V = b_0 x^{n+\mu} + b_1 x^{n+\mu-1} + \ldots + b_\mu x^\mu, \ldots \quad (13.) \]

in which \( \mu \) may be made to assume every value from 0 to \( (e-1) \) inclusive, and the left right-hand side of the equation for all such values of \( \mu \) will remain of a degree in \( x \) not exceeding \( n+e-1 \), the degree of the equations of the system above described.

There will thus be (e) equations in which only the (b) set of coefficients appear, and (n) equations containing in every term one coefficient out of each of the two sets.

The total number of equations is of course \( n+e \). Between the (e) equations of the second system (13.) and the (r) occurring first in order of the first system (12.), we may eliminate dialytically the \( e+r-1 \) highest powers of \( x \), and there will thus arise an equation of the form

\[ \theta_{r-1} \cdot U - \omega_{e+r-1} \cdot V = Lx^{n-r} + L&#x27;x^{n-r-1} + \ldots + L \quad (14.), \]

where \( \theta_{r-1} \) and \( \omega_{e+r-1} \) are respectively of the degrees \( r-1 \) and \( e+r-1 \) in \( x \), and \( L, L&#x27;, \ldots \) (L) are of (r) dimensions in the (a) set, and of (e+r) dimensions in the (b) set of coefficients, and consequently \( Lx^{n-r} + L&#x27;x^{n-r-1} + \ldots + L \) must satisfy the conditions necessary and sufficient to prove its being (to a numerical factor près) a simplified residue to \( (U, V) \).

Thus suppose

\[ U = a_0 x^4 + a_1 x^3 + a_2 x^2 + a_3 x + a_4 \]

\[ V = b_0 x^2 + b_1 x + b_2. \]

Then, corresponding to the system of which equation (13.) is the type, we have

\[ V = b_0 x^3 + b_1 x^2 + b_2 x. \]
Again, to form the system of which equation (12.) is the type, we write

\[ b_0 \cdot U - (a_0 x^3 + a_1 x^2 + a_2 x + a_3) V = b_0 (a_3 x + a_4) - (a_0 x^3 + a_1 x^2 + a_2 x + a_3)(b_1 x + b_2) \]

\[ = -a_0 b_1 x^3 - (a_0 b_2 + a_1 b_1)x^2 + (b_0 a_3 - a_1 b_2 - a_2 b_1)x + (b_0 a_4 - a_2 b_2). \]

\[ (b_0 x + b_1) \cdot U - (a_0 x^3 + a_1 x^2 + a_2 x + a_3) V = (b_0 x + b_1)a_4 - (a_0 x^3 + a_1 x^2 + a_2 x + a_3)b_2 \]

\[ = -a_0 b_2 x^2 - a_1 b_2 x + (b_0 a_4 - a_2 b_2)x + (b_1 a_4 - b_2 a_3). \]

Combining the two equations of the first system with the first of the second system, we obtain the first simplified residue \( Lx + L&#x27; \), where

\[
L = \begin{vmatrix}
0 &amp; b_0 &amp; b_1 \\
b_0 &amp; b_1 &amp; b_2 \\
a_0 b_1 &amp; a_0 b_2 + a_1 b_1 &amp; a_1 b_2 + a_2 b_1 - b_0 a_3
\end{vmatrix}
\]

and

\[
L&#x27; = \begin{vmatrix}
0 &amp; b_0 &amp; b_2 \\
b_0 &amp; b_1 &amp; 0 \\
a_0 b_1 &amp; a_0 b_2 + a_1 b_1 &amp; a_2 b_2 - b_0 a_4
\end{vmatrix}.
\]

By again combining the two equations of the first system with both of the second system, we have the determinant

\[
R = \begin{vmatrix}
0 &amp; b_0 &amp; b_1 &amp; b_2 \\
b_0 &amp; b_1 &amp; b_2 &amp; 0 \\
a_0 b_1 &amp; a_0 b_2 + a_1 b_1 &amp; a_1 b_2 + a_2 b_1 - b_1 a_3 &amp; a_2 b_2 - b_0 a_4 \\
a_0 b_2 &amp; a_1 b_2 &amp; a_2 b_2 - b_0 a_4 &amp; a_0 b_2 - a_4 b_1
\end{vmatrix},
\]

which is the last simplified residue, or in other terms, the resultant to the system \( U, V \).

Art. (7.). It is most important to observe that the Bezoutian matrix to two functions of the same degree \( n \) is a symmetrical matrix, the terms similarly disposed in respect to one of the diagonals being equal.

Thus retaining the notation of art. (5.), so that

\[
(0, 1) = a_3 - b_2 \quad (1, 2) = b_3 - c_2 \quad (2, 3) = c_3 - d_2
\]

\[
(0, 2) = a_2 - c_1 \quad (1, 3) = b_2 - d_1 \quad \text{&amp;c.}
\]

\[
(0, 3) = a_1 - d_0 \quad \text{&amp;c.}
\]

&amp;c. &amp;c., when \( n = 1 \) the Bezoutian matrix consists of a single term \((0, 1)\); when \( n = 2 \), it becomes

\[
(0, 1) \quad (0, 2)
\]

\[
(0, 2) \quad (1, 2);
\]

when \( n = 3 \), it becomes

\[
(0, 1) \quad (0, 2) \quad (0, 3)
\]

\[
(0, 2) \quad (0, 3) \quad (1, 3)
\]

\[
(0, 3) \quad (1, 3) \quad (2, 3);
\]
when \( n = 4 \), it becomes

\[
\begin{array}{cccc}
(0, 1) &amp; (0, 2) &amp; (0, 3) &amp; (0, 4) \\
(0, 2) &amp; (0, 3) &amp; (0, 4) &amp; (1, 4) \\
(1, 2) &amp; (1, 3) &amp; (2, 3) &amp; (2, 4)
\end{array}
\]

when \( n = 5 \), it becomes

\[
\begin{array}{ccccc}
(0, 1) &amp; (0, 2) &amp; (0, 3) &amp; (0, 4) &amp; (0, 5) \\
(0, 2) &amp; (0, 3) &amp; (0, 4) &amp; (0, 5) &amp; (1, 5) \\
(1, 2) &amp; (1, 3) &amp; (2, 3) &amp; (2, 4) &amp; (2, 5) \\
(0, 3) &amp; (0, 4) &amp; (0, 5) &amp; (1, 5) &amp; (2, 5) \\
(0, 4) &amp; (0, 5) &amp; (1, 5) &amp; (2, 5) &amp; (3, 5) \\
(0, 5) &amp; (1, 5) &amp; (2, 5) &amp; (3, 5) &amp; (4, 5)
\end{array}
\]

and so forth. Every such square it is apparent may be conceived as a sort of sloped pyramid, formed by the successive superposition of square layers, which layers possess not merely a simple symmetry about a diagonal (such as is proper to a multiplication table), but the higher symmetry (such as exists in an addition table), evinced in all the terms in any line of terms parallel to the diagonal transverse to the axis of symmetry being alike*. Thus for \( n = 5 \), the three layers or stages in question will be seen to be, the first—

\[
\begin{array}{ccccc}
(0, 1) &amp; (0, 2) &amp; (0, 3) &amp; (0, 4) &amp; (0, 5) \\
(0, 2) &amp; (0, 3) &amp; (0, 4) &amp; (0, 5) &amp; (1, 5) \\
(0, 3) &amp; (0, 4) &amp; (0, 5) &amp; (1, 5) &amp; (2, 5) \\
(0, 4) &amp; (0, 5) &amp; (1, 5) &amp; (2, 5) &amp; (3, 5) \\
(0, 5) &amp; (1, 5) &amp; (2, 5) &amp; (3, 5) &amp; (4, 5)
\end{array}
\]

the second—

\[
\begin{array}{ccc}
(1, 2) &amp; (1, 3) &amp; (1, 4) \\
(1, 3) &amp; (1, 4) &amp; (2, 4) \\
(1, 4) &amp; (2, 4) &amp; (3, 4)
\end{array}
\]

and the third—

\[
(2, 3).
\]

In general, when \((n)\) is odd, say \(2p+1\), the pyramid will end with a single term

* A square arrangement having this kind of symmetry, viz. such as obtains in the so-called Pythagorean addition table as distinguished from that which obtains in the multiplication table, may be universally called Persymmetric.
\((p, (p+1))\), and when even, as \(2p\), with a square of 4 terms,

\[
\begin{align*}
&amp;((p-2), (p-1)), \quad ((p-2), p) \\
&amp;((p-2), p), \quad ((p-1), p).
\end{align*}
\]

Each stage may be considered as consisting of three parts, a diagonal set of equal terms transverse to the axis of symmetry, and two triangular wings, one to the left, and the other to the right of this diagonal; the terms in each such diagonal for the respective stages will be

\[
(0, n); \quad (1, n-1); \quad (2, (n-2)); \ldots; \quad (p, (p+1)),
\]

\(p\) being \(\frac{n}{2} - 1\) when \(n\) is even, and \(\frac{n-1}{2}\) when \(n\) is odd.

If we change the order of the coefficients in each of the two given functions, it will be seen that the only effect will be to make the left and right triangular wings to change places, the diagonals in each stage remaining unaltered. The mode of forming these triangles is an operation of the most simple and mechanical nature, too obvious to need to be further insisted on here.

Art. (8.). When we are dealing with two functions of unequal degrees, \(n\) and \(n+e\), we can still form a square matrix with the coefficients of the two systems of \((e)\) and \((n)\) equations respectively, but this will no longer be symmetrical about a diagonal; it is obvious, however, that if we treat the function of the lower degree, as if it were of the same degree as the other function, which we may do by filling up the vacant places with terms affected with zero coefficients, the symmetry will be recovered; and it is somewhat important (as will appear hereafter) to compare the values of the Bezoutian secondaries as obtained, first in their simplest form by treating each of the two functions as complete in itself, and secondly, as they come out, when that of the functions, which is of the lower degree, is looked upon as a defective form of a function of the same degree as the other. A single example will suffice to make the nature of the relation between the two sets of results apparent.

Take

\[
\begin{align*}
f(x) &amp;= ax^4 + bx^3 + cx^2 + dx + e \\
\varphi(x) &amp;= 0x^4 + 0x^3 + \gamma x^2 + \delta x + \varepsilon.
\end{align*}
\]

The general method of art. (7.) then gives for the Bezoutian matrix

\[
\begin{array}{cccc}
0 &amp; a\gamma &amp; a\delta &amp; a\varepsilon \\
a\gamma &amp; (a\delta) &amp; (a\varepsilon) &amp; b\varepsilon \\
b\gamma &amp; (b\delta) &amp; (b\varepsilon) &amp; c\varepsilon - e\gamma \\
a\delta &amp; (a\varepsilon) &amp; (b\varepsilon) &amp; c\varepsilon - d\gamma \\
a\varepsilon &amp; b\varepsilon &amp; c\varepsilon - e\gamma &amp; d\varepsilon - e\delta.
\end{array}
\]

We shall not affect the value either of the complete determinant, or of any of the minor determinants appertaining to the above matrix, by subtracting the second line of terms, each increased in the ratio of \(b:a\) from the first line of terms respectively;
the matrix so modified becomes

\[
\begin{array}{cccc}
0; &amp; a\gamma; &amp; a\delta; &amp; a\varepsilon \\
a\gamma; &amp; a\delta; &amp; a\varepsilon; &amp; 0 \\
a\delta; &amp; a\varepsilon + b\delta; &amp; \left( \begin{array}{c} b\varepsilon \\ c\delta - d\gamma \end{array} \right); &amp; c\varepsilon - e\gamma \\
a\varepsilon; &amp; b\varepsilon; &amp; c\varepsilon - e\gamma; &amp; d\varepsilon - e\delta.
\end{array}
\]

Again, adopting the method of art. (6.), we should obtain the matrix

\[
\begin{array}{cccc}
0; &amp; \gamma; &amp; \delta; &amp; \varepsilon \\
\gamma; &amp; \delta; &amp; \varepsilon; &amp; 0 \\
\delta; &amp; a\varepsilon - b\delta; &amp; \left( \begin{array}{c} b\varepsilon \\ c\delta - d\gamma \end{array} \right); &amp; c\varepsilon - e\gamma \\
a\varepsilon; &amp; b\varepsilon; &amp; c\varepsilon - e\gamma; &amp; d\varepsilon - e\delta.
\end{array}
\]

Hence it is apparent that the secondary Bezoutians obtained by the symmetrizing method will differ from those obtained by the unsymmetrical method by a constant factor \(a^2\); and so in general it may readily be shown that the secondary Bezoutians, by the use of the symmetrizing method, will each become affected with a constant irrelevant factor \(a^\omega\), where \((\omega)\) is the difference of the degrees of the two functions, and \((a)\) the leading coefficient of the higher one of the two. When \((a)\) is taken unity, the Bezoutian secondaries, as obtained by either method, will of course be identical.

Art. (9.). There is another method* of obtaining the simplified residues to anytwo functions \(U\) and \(V\) of the degrees \(n\) and \(n+e\) respectively, which, although less elegant, ought not to be passed over in silence. This method consists in forming the identical equations (of which for greater brevity the right-hand members are suppressed).

\[
\begin{align*}
V &amp;= &amp;c. \\
xV &amp;= &amp;c. \\
\vdots \\
x^{e-1}.V &amp;= &amp;c. \\
U &amp;= &amp;c. \\
x^e.V &amp;= &amp;c. \\
x.U &amp;= &amp;c. \\
x^{e+1}.V &amp;= &amp;c. \\
x^2.U &amp;= &amp;c. \\
x^{e+2}.V &amp;= &amp;c. \\
&amp;c. &amp;= &amp;c. \\
x^{n-1}.U &amp;= &amp;c. \\
x^{e+n-1}.V &amp;= &amp;c.
\end{align*}
\]

* Originally given by myself in the London and Edinburgh Philosophical Magazine, as long ago as 1839 or 1840; and some years subsequently in unconsciousness of that fact, reproduced by my friend Mr. Cayley, to whom the method is sometimes erroneously ascribed, and who arrived at the same equations by an entirely different circle of reasoning.
If we equate the right-hand members of \((e+2i)\) of the above equations to zero, and then eliminate dialytically the several powers of \(x\) from \(x^{n+i-1}\) to \(x^{n-i+1}\) (both inclusive), the result of this process will evidently be of \((e+i)\) dimensions in respect of the coefficients in \(V\), and of \(i\) dimensions in respect of the coefficients in \(U\); and of the degree \(x^{n-i}\) in \(x\) it will also be of the form

\[(A+Bx+\ldots Lx^{e-1})U+(F+Gx+\ldots +Qx^{e+i-1}),\]

and by virtue of art. (2.) must consequently be the \(i\)th simplified residue to the system \(U, V\).

Art. (10.). The most general view of the subject of expansion by the method of continued division, consists in treating the process as having reference solely to the two systems of coefficients in \(U\) and \(V\), which themselves are to be regarded in the light of generating functions. To carry out this conception, we ought to write

\[U=a_0+a_1.y+a_2.y^2+a_3y^3+\&amp;c.\ ad\ inf.\]
\[V=b_0+b_1.y+b_2.y^2+b_3y^3+\&amp;c.\ ad\ inf.,\]

and might then suppose the process of successive division applied to \(U\) and \(V\), so as to obtain the successive equations

\[U-M_1V+R_1=0\]
\[V-M_2R_1+R_2=0\]
\[R_1-M_3R_2+R_3=0\]
\&amp;c. \&amp;c.,

\(M_1, M_2, M_3, \&amp;c.\) being each severally of any degree whatever in \(y\), and in general the degree of \(y\) in \(M_i\) being any given arbitrary function \(\phi(i)\) of \(i\). The values of the coefficients of the residues \(R_1, R_2, R_3 \ldots\), or of these forms simplified by the rejection of detachable factors, becomes then the distinct object of the inquiry, and will, of course, depend only upon the coefficients in \(P\) and \(Q\) and the nature of the arbitrary continuous or discontinuous function \(\phi(i)\), which regulates the number of steps through which each successive process of division is to be pursued. Following out this idea in a particular case, if we again reduce to our two initial functions the forms previously employed, and write

\[U=a_0.x^n+a_1.x^{n-1}+\&amp;c.\]
\[V=b_0.x^n+b_1.x^{n-1}+\&amp;c.;\]

and if, instead of making, according to the more usual course of proceeding, the divisions proceed first through one step and ever after through two steps at a time which is tantamount to making \(\phi(1)=1 \phi(1+\omega)=2\), we push each division through one step only at a time, and no more (so that in fact \(\phi(i)\) is always 1), we shall have

\[U-m_1. V+R_1=0\]
\[V-m_2x. R_1+R_2=0\]
\[R_1-m_3. R_2+R_3=0\]
\[R_2-m_4.x. R_3+R_4=0\]
\&amp;c. \&amp;c.,
$m_1, m_2, m_3, \&amp;c.$ being functions of the coefficients only of $U$ and $V$; and it is not without interest to observe (which is capable of an easy demonstration) that the simplified residues contained in $R_1, R_2, \&amp;c.$, found according to this mode of development, will be the successive dialytic resultants obtained by eliminating the $(i-1)$th highest powers of $x$ between the first of the system of the annexed equations (supposed to be expressed in terms of $x$)

$$\begin{align*}
U &amp;= 0 \\
V &amp;= 0 \\
x \cdot U &amp;= 0 \\
x \cdot V &amp;= 0 \\
x^2 U &amp;= 0 \\
x^2 V &amp;= 0 \\
&amp;\&amp;c. \&amp;c. \\
x^{n-i} U &amp;= 0 \\
x^{n-i} V &amp;= 0.
\end{align*}$$

If we combine together $2i+1$ of the above equations, the highest power of $x$ entering on the left-hand side will be $x^{n+i}$, and we shall be able to eliminate $2i$ of these factors, leaving $x^{n-i}$ the highest power remaining uneliminated. If we take $2i$, i.e. $i$ pairs of the equations, the highest power of $x$ appearing in any of them will be $x^{n+i-1}$, and we shall be able to eliminate between them so as still to leave $x^{n+i-1-(2i-1)}$, i.e. $x^{n-i}$ as before, the highest power of $x$ remaining uneliminated; and it will be readily seen that such of the simplified residues corresponding to this mode of development as occupy the odd places in the series of such residues, will be identical with the successive simplified residues resulting from the ordinary mode of developing $\frac{U}{V}$ under the form of a continued fraction.

Art. (11.). It has been shown that the simplified residues of $fx$ and $\phi x$ resulting from the process of continued division are identical in point of form with the secondary Bezoutians of these functions, but it remains to assign the numerical relations between any such residue and the corresponding secondary.

To determine this numerical relation, it will of course be sufficient to compare the magnitude of the coefficient of any one power of $x$ in the one, with that of the same power in the other; and for this purpose I shall make choice of the leading coefficients in each. In what follows, and throughout this paper, it will always be understood that in calculating the determinant corresponding to any square the product of the terms situated in the diagonal descending from left to right will always be taken with the positive sign, which convention will serve to determine the sign of all the other products entering into such determinant. Now adopting the umbral notation for determinants*, we have, by virtue of a much more general theorem for compound

---

* See London and Edinburgh Philosophical Magazine, April 1851.
determinants, the following identical equation:

\[ \frac{a_1 a_2 a_3 \ldots a_{m-1}}{\alpha_1 \alpha_2 \alpha_3 \ldots \alpha_{m-1}} \times \frac{a_1 a_2 a_3 \ldots a_m}{\alpha_1 \alpha_2 \alpha_3 \ldots \alpha_m} = \left( \frac{a_1 a_2 a_3 \ldots a_{m-1} a_m}{\alpha_1 \alpha_2 \alpha_3 \ldots \alpha_{m-1} \alpha_m} \right) \times \left( \frac{a_1 a_2 \ldots a_{m-1} a_m + 1}{\alpha_1 \alpha_2 \ldots \alpha_{m-1} \alpha_m + 1} \right) - \left( \frac{a_1 a_2 \ldots a_{m-1} a_m}{\alpha_1 \alpha_2 \ldots \alpha_{m-1} \alpha_m} \right) \times \left( \frac{a_1 a_2 \ldots a_{m-1} a_m + 1}{\alpha_1 \alpha_2 \ldots \alpha_{m-1} \alpha_m + 1} \right) \]

and consequently

\[ \frac{a_1 a_2 a_3 \ldots a_{m-1}}{\alpha_1 \alpha_2 \alpha_3 \ldots \alpha_{m-1}} \times \frac{a_1 a_2 a_3 \ldots a_{m-1} a_m a_{m+1}}{\alpha_1 \alpha_2 \alpha_3 \ldots \alpha_{m-1} \alpha_m a_{m+1}} = \left( \frac{a_1 a_2 a_3 \ldots a_{m-1} a_m}{\alpha_1 \alpha_2 \alpha_3 \ldots \alpha_{m-1} \alpha_m} \right) \times \left( \frac{a_1 a_2 \ldots a_{m-1} a_m + 1}{\alpha_1 \alpha_2 \ldots \alpha_{m-1} \alpha_m + 1} \right) - \left( \frac{a_1 a_2 \ldots a_{m-1} a_m}{\alpha_1 \alpha_2 \ldots \alpha_{m-1} \alpha_m} \right)^2 \]

and consequently when

\[ \left\{ \begin{array}{c}
a_1 a_2 \ldots a_{m-1} a_m \\
\alpha_1 \alpha_2 \ldots \alpha_{m-1} \alpha_m + 1
\end{array} \right\} = 0 \]

will have different algebraical signs, it being of course understood that all the quantities entering into the determinants thus umbrally represented above are supposed to be real quantities. This theorem, translated into the ordinary language of determinants, may be stated as follows:—Begin with any square of terms whether symmetrical or otherwise, say of \( r \) lines and \( r \) columns; let this square be bordered laterally and longitudinally by the same \( r \) new quantities symmetrically disposed in respect to one of the diagonals, the term common to the superadded line and column being filled up with any quantity whatever; we thus obtain a square of \((r+1)\) lines and columns; let this be again bordered laterally and longitudinally by \((r+1)\) quantities symmetrically disposed above the same diagonal as that last selected, the place in which this new line and column meet being also filled up with any arbitrary quantity; and proceeding in this manner, let the determinants corresponding to the square matrices thus formed be called \( D_{r-1}, D_r, D_{r+1}, D_{r+2}, \ldots \). This series of quantities will possess the property, that no term in it can vanish without the terms on either side of that so vanishing having contrary signs. Thus if we begin with a square consisting of one single term, we may suppose that by accretions formed after the above rule it has been developed into the square (M) below written, and which of course may be
indefinitely extended:

\[
\begin{array}{cccc}
a &amp; l &amp; m &amp; p \\
l &amp; b &amp; n &amp; q \\
m &amp; n &amp; c &amp; r \\
p &amp; q &amp; r &amp; d \\
s &amp; t &amp; u &amp; v \\
\end{array}
\]

\(r\) here begins with the value (1), and \(D_0, D_1, D_2, D_3, D_4, D_5\) will represent the progression,

\[
\begin{array}{cccc}
a &amp; l &amp; m &amp; p \\
l &amp; b &amp; n &amp; q \\
m &amp; n &amp; c &amp; r \\
p &amp; q &amp; r &amp; d \\
s &amp; t &amp; u &amp; v \\
\end{array}
\]

so if we use the matrix

\[
\begin{array}{cccc}
a &amp; l &amp; m &amp; p \\
l&#x27; &amp; b &amp; n &amp; q \\
m &amp; n &amp; c &amp; r \\
p &amp; q &amp; r &amp; d \\
s &amp; t &amp; u &amp; v \\
\end{array}
\]

the determinants \(D_1, D_2, D_3, D_4, D_5\) representing

\[
\begin{array}{cccc}
a &amp; l &amp; m &amp; p \\
l&#x27; &amp; b &amp; n &amp; q \\
m &amp; n &amp; c &amp; r \\
p &amp; q &amp; r &amp; d \\
s &amp; t &amp; u &amp; v \\
\end{array}
\]

will possess the property in question; the line and column \(l, b; l&#x27;, b\) not being identical, the first determinant \(D_0\) representing (1) must not be included in the progression.

We shall have occasion to use this theorem as applicable to the case of a matrix symmetrical throughout, and we may term the progression \((\Pi)\) above written a progression of the successive principal determinants about the axis of symmetry of the square matrix \((M)\), and so in general. Now it is obvious that the leading coefficients of the successive Bezoutian secondaries are the successive principal determinants about the axis of symmetry of the Bezoutian squares; they will therefore have the property which has been demonstrated of such progressions; to wit, if the first of them vanishes, the second will have a sign contrary to that of \(+1\); if the second vanishes, the third will have a sign contrary to that of the first, and so on.

Art. (12.). Now let \(f(x)\) and \(\phi(x)\) be any two algebraical functions of \(x\) with the leading coefficients in each, for greater simplicity supposed positive: and in the course of developing \(\frac{\phi(x)}{f(x)}\) under the form of an improper continued fraction by the common process of successive division, let any two consecutive residues (the word residue being
used in the same conventional sense as employed throughout) be

\[ A x + B x^{r-1} + C x^{r-2} + \&amp;c. \]

\[ B&#x27; x^{r-1} + C&#x27; x^{r-2} + D&#x27; x^{r-3} + \&amp;c. \]

The residue next following, obtained by actually performing the division and duly changing the sign of the remainder will be

\[ \left( \frac{AD}{B&#x27;} - C \right) - \left( \frac{AC&#x27;}{B&#x27;} - B \right) \frac{C&#x27;}{B&#x27;} x^{r-2} + \&amp;c., \]

which is of the form

\[ \frac{1}{B&#x27;^2} \left[ B&#x27;M - AC&#x27;^2 \right] x^{r-2} + \&amp;c. \]

Thus the leading coefficients in the complete unreduced residues will be

\[ A; B&#x27;; \frac{1}{B&#x27;^2} \left[ B&#x27;M - AC&#x27;^2 \right], \]

and when reduced by the expulsion of the allotrious factor will become \( A; B&#x27;; B&#x27;.M - A C&#x27;^2 \), and consequently, when \( B&#x27; \) the leading coefficient of one of the simplified residues vanishes, the leading coefficients of the residues immediately preceding and following that one will have contrary signs.

First, let

\[ f x = ax^n + bx^{n-1} + \&amp;c., \quad \phi x = ax^n + \beta x^{n-1} + \&amp;c. \]

As regards the numerical ratio of each Bezoutian secondary to the corresponding simplified residue, it has been already observed that there are always unit coefficients in the latter of these, and the same is obviously true of the former; hence if we call the progression of the leading coefficients of the simplified residues

\[ R_1; R_2; R_3; R_4; \&amp;c., \]

and that of the leading coefficients of the Bezoutian secondaries

\[ B_1; B_2; B_3; B_4; \&amp;c., \]

we have

\[ B_1 = \pm R_1, \quad B_2 = \pm R_2, \quad B_3 = \pm R_3, \quad B_4 = \pm R_4, \&amp;c. \]

It may be proved by actual trial that \( B_1 = R_1 \) and \( B_2 = R_2 \). Moreover, since the signs are invariable, and do not depend upon the values of the coefficients, we may suppose \( B_2 = 0 \) (which may always be satisfied by real values of the quantities, of which \( B_2 \) is a function); we shall also, therefore, have \( R_2 = 0 \), and consequently \( B_3 \) has the opposite sign to that of \( B_1 \), and \( R_3 \) the opposite sign to that of \( R_1 \), which is equal to \( B_1 \); hence when \( B_2 = 0 \), \( B_3 \) and \( R_3 \) are equal, and consequently are always equal; in like manner we can prove that \( R_4 \) and \( B_4 \) have the same sign when \( R_3 \) and \( B_3 \) vanish, and consequently are always equal, and so on ad libitum, which proves that the series \( B_1, B_2, \ldots B_n \) is identical with the series \( R_1, R_2, \ldots R_n \), and consequently that the Bezoutian secondaries are identical in form, magnitude and algebraical sign with the simplified residues. Secondly, when \( f x \) and \( \phi x \) are not of the same degree, it has been shown that the secondaries formed from the non-
symmetrical matrix corresponding to this case will be the same as those formed from
the symmetrical matrix corresponding to $fx$ and $\Phi(x)$ (where $\Phi x$ is $\phi(x)$ treated by
aid of evanescent terms, as of the same degree as $fx$), with the exception merely of a
constant multiplier (a power of the leading coefficient of $fx$) being introduced into
each secondary. By aid of this observation, the proposition established for the case
of two functions of the same degree may be readily seen to be capable of being
extended, from the case of $f$ and $\phi$ being of the equal dimensions in $x$, to the
general case of their dimensions being any whatever.

Art. (13.). Before closing this section, it may be well to call attention to the nature
of the relation which connects the successive residues of $fx$ and $\phi x$ with these
functions themselves, and with the improper continued fractional form into which
$\frac{\phi x}{fx}$ is supposed to be developed in the process of obtaining these residues.

If $\phi x$ be of $n$ degrees, and $fx$ of $n+e$ degrees in $(n)$, we shall have

$$\frac{\phi x}{fx} = \frac{1}{Q_1 - \frac{1}{q_2 - \frac{1}{q_3 - \cdots \frac{1}{q_n}}}},$$

where $Q_1$ may be supposed to be a function of $x$ of the degree $(e)$, and $q_2, q_3, \ldots q_n$
are all linear functions of $x$; the total number of the quotients $Q_1, q_2, \ldots q_n$ being of
course $(n)$ when the process of continued division is supposed to be carried out until
the last residue is zero. Upon this supposition the last but one residue is a constant,
the preceding one a function of $x$ of the first degree, the one preceding that a function
of $x$ of the second degree, and so on.

Let us call the residue of the degree $\varepsilon$ in $x$, $\mathcal{S}_\varepsilon$; it will readily be seen that the
successive complete residues arranged in an ascending order will be

$$\mathcal{S}_0, \mathcal{S}_0 \cdot q_n, \mathcal{S}_0(q_{n-1} \cdot q_n - 1), \mathcal{S}_0(q_{n-2} \cdot q_{n-1} \cdot q_n - q_{n-2} - q_n); \text{ &amp;c.,}$$

being in the ratios of the quantities

$$1; q_n; q_{n-1} - \frac{1}{q_n}; q_{n-2} - \frac{1}{q_{n-1}} \frac{1}{q_n}; \text{ &amp;c.}$$

Again, we shall have in general

$$\Lambda_i f - L_i \phi = \mathcal{S}_i, \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots (15.)$$

$\Lambda_i$ being an integral function of $x$ of the degree $n-i-1$, and $L_i$ an integral function
of $x$ of the degree $(n+e)-i-1$; and it is easy to see that the successive convergents
to the continued fraction—

$$\frac{1}{Q_1 - \frac{1}{q_2 - \frac{1}{q_3 - \cdots \frac{1}{q_n}}}} \&amp;c.$$

have their respective numerators and denominators identical with those of the
fractions

$$\frac{\Lambda_{n-1}}{L_{n-1}}, \frac{\Lambda_{n-2}}{L_{n-2}}, \frac{\Lambda_{n-3}}{L_{n-3}} \&amp;c.$$

Adopting the language which I have frequently employed elsewhere, I call $\mathcal{S}_i$ a
syzygetic function, or more briefly, a conjunctive of $f$ and $\phi$, and $\Lambda_i$ and $L_i$ may be termed the syzygetic factors to $\Sigma_i$, so considered. If we divide each term of the equation (15.) by the allotrious factor $(M)$, we have

$$\frac{\Lambda_i}{M} f - \frac{L_i}{M} \phi = R_i,$$

where $R_i$ is the $i$th simplified residue to $(f, \phi)$; and if we call $\frac{\Lambda_i}{M} = \tau_i$, and $\frac{L_i}{M} = t_i$, so as to obtain the equation

$$\tau_i f - t_i \phi = R_i,$$

we see that $\frac{\tau_i}{t_i}$, the fraction formed by the component factors to any simplified residue of $(f, \phi)$, will be identical in value (although no longer in its separate terms) with one of the corresponding convergents to $\phi f$, exhibited under the form of an improper continued fraction. I shall in the next section show how, not only the successive simplified residues, but also the component syzygetic factors of each of them, and consequently the successive convergents, may be expressed in terms of the roots of the two given functions.

Since the preceding section was composed the valuable memoir of the lamented Jacobi, entitled &quot;De Eliminatione Variabilis è duabus Equationibus Algebraicis,&quot; Crelle, vol. xvi., has fallen under my notice. That memoir is restricted to the consideration of two equations of the same degree, and the principal results in this section as regards the Bezoutian square and the allotrious factors applicable to that case will be found contained therein. The mode of treatment however is sufficiently dissimilar to justify this section being preserved unaltered under its original form.

Section II.

On the general solution in terms of the roots of any two given algebraical functions of $x$ of the syzygetic equation, which connects them with a third function, whose degree in ($x$) is given, but whose form is to be determined.

Art. (14.). Let $f$ and $\phi$ be two given functions in $x$ of the degrees $m$ and $n$ respectively in $x$, and for the sake of greater simplicity let the coefficients of the highest power of $x$ in $f$ and $\phi$ be each taken unity, and let it be proposed to solve the syzygetic equation

$$\tau_i f - t_i \phi + S_i = 0,$$

where $S_i$ is given only in the number of its dimensions in $x$, which I suppose to be $(i)$; but the forms of $\tau_i$, $t_i$, $S_i$ are all to be determined in terms of $h_1, h_2, \ldots, h_m$ the roots of $f$ and $z_1, z_2, \ldots, z_n$ the roots of $\phi$.

I shall begin with finding $S_i$; and before giving a more general representation of $S_i$, I propose now to demonstrate that we may make

$$S_i = \Sigma \{P_{q_1 q_2 \ldots q_i} \times (x-h_{q_1})(x-h_{q_2}) \ldots (x-h_{q_i})\},$$

(18.)
where $P_{q_1 q_2 \ldots q_i}$ is used to denote

$$\begin{align*}
&amp; (h_{q_1+1} - \eta_1)(h_{q_1+1} - \eta_2) \ldots (h_{q_1+1} - \eta_n) \\
\times &amp; (h_{q_1+2} - \eta_1)(h_{q_1+2} - \eta_2) \ldots (h_{q_1+2} - \eta_n) \\
\times &amp; (h_{q_1+3} - \eta_1)(h_{q_1+3} - \eta_2) \ldots (h_{q_1+3} - \eta_n) \\
\times &amp; \ldots \ldots \ldots \ldots \ldots \ldots \ldots \\
\times &amp; (h_{q_m} - \eta_1)(h_{q_m} - \eta_2) \ldots (h_{q_m} - \eta_n)
\end{align*}$$

$R(h_{q_1}, h_{q_2}, \ldots, h_{q_i})$, denoting any rational symmetrical form of function whatever of the quantities preceded by the symbol $R$, and $q_1 q_2 \ldots q_i q_{i+1} \ldots q_m$ being any permutation of the $m$ indices $1, 2, \ldots m$.

Suppose $f = 0$ and $\phi = 0$, then $x$ is equal to one of the series of roots

$h_1 h_2 \ldots h_m,$

and also to one of the series of roots

$\eta_1 \eta_2 \ldots \eta_n.$

Suppose then that

$x = h_a = \eta_w,$

and consider any term of $\mathfrak{S}_i$.

If in any such term $(a)$ is found in the series $q_1 q_2 \ldots q_i$, then

$$(x - h_{q_1})(x - h_{q_2}) \ldots (x - h_{q_i}) = 0.$$  

But if not, then $(a)$ must be found in the complementary series $h_{q_1+1}, h_{q_1+2}, \ldots, h_{q_m}$, and consequently $P_{q_1 q_2 \ldots q_i}$ will contain a factor $h_a - \eta_w$ and $P_{q_1 q_2 \ldots q_i} = 0$; in every case therefore

$$P_{q_1 q_2 \ldots q_i} \times (x - h_{q_1})(x - h_{q_2}) \ldots (x - h_{q_i}) = 0,$$

and therefore $\mathfrak{S}_i$ as expressed in equation (18.) is a syzygetic function of $f$ and $\phi$; accordingly we have found a function of the $i$th degree in $x$, and of course expressible by calculating the symmetric functions as a function only of $x$ and of the coefficients of $f$ and $\phi$, which will satisfy the equation

$$\sigma_i f - t_i \phi + \mathfrak{S}_i = 0.$$  

[It will be remembered that by virtue of art. (2) we know \textit{a priori} that all the values of $\mathfrak{S}_i$ satisfying this equation are identical, save as to an allotrious factor, which is a function only of the coefficients in $f$ and $\phi$.] It is clear that we may interchange the $h$ and $\eta$, $m$ and $n$, and thus another representation of a value of $\mathfrak{S}_i$ satisfying the equation (17.) will be

$$\mathfrak{S}_i = \Sigma R(\eta_{q_1} \eta_{q_2} \ldots \eta_{q_i}) \times \begin{align*}
&amp; (\eta_{q_1+1} - h_1)(\eta_{q_1+1} - h_2) \ldots (\eta_{q_1+1} - h_m) \\
\times &amp; (\eta_{q_1+2} - h_1)(\eta_{q_1+2} - h_2) \ldots (\eta_{q_1+2} - h_m) \\
\times &amp; (\eta_{q_1+3} - h_1)(\eta_{q_1+3} - h_2) \ldots (\eta_{q_1+3} - h_m) \\
\times &amp; \ldots \ldots \ldots \ldots \ldots \ldots \ldots \\
\times &amp; (\eta_{q_m} - h_1)(\eta_{q_m} - h_2) \ldots (\eta_{q_m} - h_m)
\end{align*}$$

$(x - \eta_{q_1})(x - \eta_{q_2}) \ldots (x - \eta_{q_i}).$

Art. (15.). If we employ in general the condensed notation

$$\begin{bmatrix} l, m, n, \ldots p \\ \lambda, \mu, \ldots \nu \end{bmatrix}$$
to denote the product of the differences resulting from the subtraction of each of the quantities $\lambda$, $\mu$, ... $\nu$ in the lower line from all of those in the upper line $l$, $m$, $n$, ... $p$, the two values above given for $\Phi$, may be written under the respective forms

$$\Sigma R(h_{q_1}h_{q_2}\ldots h_{q_m}) \cdot \begin{bmatrix} h_{q_1+1} &amp; h_{q_1+2} &amp; \ldots &amp; h_{q_m} \\ \eta_1 &amp; \eta_2 &amp; \ldots &amp; \eta_n \end{bmatrix} (x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_m})$$

and

$$\Sigma R(\eta_{\xi_1}\eta_{\xi_2}\ldots \eta_{\xi_n}) \cdot \begin{bmatrix} \eta_{\xi_1+1} &amp; \eta_{\xi_1+2} &amp; \ldots &amp; \eta_{\xi_n} \\ h_1 &amp; h_2 &amp; \ldots &amp; h_m \end{bmatrix} \times (x-\eta_{\xi_1})(x-\eta_{\xi_2})\ldots(x-\eta_{\xi_n})$$

in each of which equations disjunctively and in some order of relation each with each

$$q_1, q_2, q_3, \ldots, q_m = 1, 2, 3, \ldots, m,$$

and

$$\xi_1, \xi_2, \xi_3, \ldots, \xi_n = 1, 2, 3, \ldots, n.$$

These two forms are only the two extremities of a scale of forms all equally well adapted to express $\Phi_i$; for let $v$ and $v&#x27;$ be any two integers so taken as to satisfy the equation

$$v + v&#x27; = i,$$

and let $R(\ldots;\ldots)$, where the dots denote any quantities whatever, be used to denote a rational form of function which remains unaltered in value when any two of the quantities under each and either (the same one) of the two bars are mutually interchanged, then we may write

$$\Phi_i = \Sigma \left\{ R(h_{q_1}h_{q_2}\ldots h_{q_m}; \eta_{\xi_1}\eta_{\xi_2}\ldots \eta_{\xi_n}) \times \begin{bmatrix} h_{q_1+1} &amp; h_{q_1+2} &amp; \ldots &amp; h_{q_m} \\ \eta_{\xi_1+1} &amp; \eta_{\xi_1+2} &amp; \ldots &amp; \eta_{\xi_n} \end{bmatrix} \right\} \times (x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_m}) \times (x-\eta_{\xi_1})(x-\eta_{\xi_2})\ldots(x-\eta_{\xi_n}).$$

For if, as above, we suppose $x=h_a=\eta_w$, any term of $\Phi_i$ in which $q_1, q_2, \ldots q_v$ comprise among them $h_a$, or in which $\xi_1\xi_2\ldots \xi_w$ comprise among them $\eta_w$, will vanish by virtue of the factors $(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_v}) \times (x-\eta_{\xi_1})(x-\eta_{\xi_2})\ldots(x-\eta_{\xi_w})$; but if neither $h_a$ nor $\eta_w$ is so comprised, then $h_a$ must be one of the terms in the complementary series $q_{v+1}, q_{v+2}, \ldots q_m$, and $\eta_w$ one of the terms in the complementary series $\xi_{w+1}, \xi_{w+2}, \ldots \xi_n$, and therefore one of the quantities $h_{q_{v+1}}, h_{q_{v+2}}, \ldots h_{q_m}$ will equal one of the quantities $\eta_{\xi_{w+1}}, \eta_{\xi_{w+2}}, \ldots \eta_{\xi_n}$, and consequently the term of $\Phi_i$ in question will vanish by virtue of the factor $\begin{bmatrix} h_{q_{v+1}} &amp; h_{q_{v+2}} &amp; \ldots &amp; h_{q_m} \\ \eta_{\xi_{w+1}} &amp; \eta_{\xi_{w+2}} &amp; \ldots &amp; \eta_{\xi_n} \end{bmatrix}$ vanishing. In either case therefore every term included within the sign of summation vanishes when $x=h_a=\eta_w$, i.e. whenever $f(x)=0$ and $\phi=(x)=0$. Hence $\Phi_i$, as given by equation (19.), will satisfy the syzygetic equation
for all values of \( v \) and \( u \) which make \( v + u = l \), and for all symmetrical forms of the function denoted by the symbol \( R(\ldots; \ldots) \).

Art. (16.). I shall now proceed to show how to assign the arbitrary function whose form is denoted by this symbol in such a manner as to make \( S_i \) become identical with a simplified residue to \( f \) and \( \phi \). To this end I take for \( R(h_1 h_2 \ldots h_q; k_1 k_2 \ldots k_r) \) the value

\[
R = \begin{bmatrix}
h_1 &amp; h_2 &amp; \ldots &amp; h_q \\
h_{q+1} &amp; h_{q+2} &amp; \ldots &amp; h_m \\
\end{bmatrix} \times \begin{bmatrix}
k_1 &amp; k_2 &amp; \ldots &amp; k_r \\
k_{r+1} &amp; k_{r+2} &amp; \ldots &amp; k_n \\
\end{bmatrix},
\]

we shall then have

\[
S_i = \sum \left[ \begin{bmatrix}
h_1 &amp; h_2 &amp; \ldots &amp; h_q \\
h_{q+1} &amp; h_{q+2} &amp; \ldots &amp; h_m \\
\end{bmatrix} \times \begin{bmatrix}
\eta_1 &amp; \eta_2 &amp; \ldots &amp; \eta_q \\
\eta_{q+1} &amp; \eta_{q+2} &amp; \ldots &amp; \eta_m \\
\end{bmatrix} \right] \{(x-h_1)(x-h_2)\ldots(x-h_q)\} \{(x-\eta_1)(x-\eta_2)\ldots(x-\eta_q)\}.
\]

I shall first show this sum of fractions is in substance an integral function of the quantities \( h_1 h_2 \ldots h_m; k_1 k_2 \ldots k_m \). For greater conciseness write in general \( x-h=E, x-\eta=H \), we have then, since \( h-\eta=H-E, h_2-h_3=E_2-E_3, \eta_2-\eta_3=H_2-H_3 \),

\[
S_i = \sum \left[ \begin{bmatrix}
H_1 &amp; H_2 &amp; \ldots &amp; H_q \\
E_1 &amp; E_2 &amp; \ldots &amp; E_q \\
\end{bmatrix} \times \begin{bmatrix}
H_{q+1} &amp; H_{q+2} &amp; \ldots &amp; H_m \\
E_{q+1} &amp; E_{q+2} &amp; \ldots &amp; E_m \\
\end{bmatrix}, E_1 E_2 \ldots E_q, \ldots \right].
\]

On reducing the fractions contained within the sign of summation to a common denominator, \( S_i \) will take the form \( \frac{N}{D.A} \), where \( D \) will be the product of the \( m \cdot \frac{m-1}{2} \) differences of \( E_1, E_2, \ldots E_m \) subtracted each from each, and \( A \) the corresponding product of the differences inter se of \( H_1, H_2, \ldots H_m \).

Hence, unless the sum in question is an integral function of the \( E \)&#x27;s and \( H \)&#x27;s, it will become infinite when any two of the \( E \) series, or any two of the \( H \) series of quantities are made equal. Suppose now \( E_1=E_2 \); the terms in (22.) which contain \( E_1-E_2 \) in the denominator will evidently group themselves into pairs of the respective forms,

\[
(E_1 E_2 \ldots E_q) \times (H_1 H_2 \ldots H_q) \times \begin{bmatrix}
E_1 &amp; E_2 &amp; \ldots &amp; E_q \\
H_1 &amp; H_2 &amp; \ldots &amp; H_q \\
\end{bmatrix} \times \begin{bmatrix}
E_{q+1} &amp; E_{q+2} &amp; \ldots &amp; E_m \\
H_{q+1} &amp; H_{q+2} &amp; \ldots &amp; H_m \\
\end{bmatrix},
\]

\[
\begin{bmatrix}
E_1 E_2 \ldots E_q \\
E_{q+1} E_{q+2} \ldots E_m \\
\end{bmatrix} \times \begin{bmatrix}
H_1 &amp; H_2 &amp; \ldots &amp; H_q \\
H_{q+1} &amp; H_{q+2} &amp; \ldots &amp; H_m \\
\end{bmatrix}.
\]
and

\[
(E_2, E_{q_3}, \ldots, E_{q_v}) \times (H_{\xi_1}, H_{\xi_2}, \ldots, H_{\xi_v}) \times \begin{bmatrix} E_1 &amp; E_{q_{v+1}}, \ldots, E_{q_m} \\ H_{\xi_1}, H_{\xi_2}, \ldots, H_{\xi_v} \end{bmatrix}
\]

the sum of this pair of terms will be of the form

\[
P \cdot Q \left\{ \frac{E_1}{E_1 - E_2} \cdot \begin{bmatrix} E_1 \\ H_{\xi_1}, H_{\xi_2}, \ldots, H_{\xi_v} \end{bmatrix} \times \begin{bmatrix} E_2 \\ H_{\xi_{v+1}}, H_{\xi_{v+2}}, \ldots, H_{\xi_n} \end{bmatrix} \right\}
\]

\[
+ P \cdot Q \left\{ \frac{E_2}{E_2 - E_1} \cdot \begin{bmatrix} E_2 \\ H_{\xi_1}, H_{\xi_2}, \ldots, H_{\xi_v} \end{bmatrix} \times \begin{bmatrix} E_1 \\ H_{\xi_{v+1}}, H_{\xi_{v+2}}, \ldots, H_{\xi_n} \end{bmatrix} \right\},
\]

where \(Q\), it may be observed, does not contain \(H_1 - H_2\), so that \(P/Q\) remains finite when \(H_1 = H_2\).

The above pair of terms together make up a sum of the form

\[
\frac{P}{Q} \cdot \frac{1}{E_1 - E_2} \cdot \varphi(E_1, E_2) \psi E_2 - \varphi(E_2, E_1) \psi E_1,
\]

which (as the numerator of the third factor vanishes when \(E_1 = E_2\)) remains finite on that supposition. Hence the whole sum of terms in (22.) which is made up of such pairs of terms, and of other terms in which \(E_1 - E_2\) does not enter, remains finite when \(E_1 - E_2 = 0\), and therefore generally when \(D = 0\), and similarly when \(H_1 - H_2 = 0\), and therefore also when \(\Delta = 0\); hence the expression for \(S\) in (22.) is an integral function of the \(E\) and \(H\) series of quantities, as was to be proved.

Art. (17.). Let us now proceed to determine the dimensions of the coefficient of \(x&#x27;\), the highest power of \(x\) in this value of \(S\), when supposed to be expressed under the form of an integral function (as it has been proved to be capable of being expressed) of \(h_1 h_2 \ldots h_m; n_1 n_2 \ldots n_n; x\).

This coefficient is the sum of fractions the numerators of each of which consist of two factors, which are respectively of \(v \times v\) and of \((m-v) \times (n-v)\) dimensions in respect of the two sets of roots taken conjointly, and the denominators of two factors respectively of \(v \cdot (m-v)\) and \(v \times (n-v)\) dimensions in respect of the same.

Consequently, the exponent of the total dimensions of the coefficient in question

\[
= v \times v + (m-v)(n-v) - v(m-v) - (v(n-v))
\]

\[
= (m-v-v) \times (n-v-v)
\]

\[
= (m-i) \cdot (n-i),
\]
and thus is seen to depend only on the degree \( i \) in \( x \) of \( S_i \), and not upon the mode of partitioning \( i \) into two parts \( u \) and \( v \), for the purpose of representing \( S_i \), by means of formula (19.)

Art. (18.). I shall now demonstrate that every form in this scale (to a numerical factor près) is identical with a simplified residue to \( f \), \( \phi \) of the same degree \( i \) in \( x \). Any such simplified residue is like \( S_i \), a syzygetic function, or to use a briefer form of speech, a conjunctive of \( f \), \( \phi \); and if we agree to understand by the &quot;weight&quot; of any function of the coefficients of \( f \) and \( \phi \) its joint dimensions in respect of the roots of \( f \) and \( \phi \) combined, I shall prove,—1st, that any simplified residue of \( f \) and \( \phi \) of a given degree in \( x \) is that conjunctive, whose weight in respect of the roots of \( f \) and \( \phi \) is less than the weight of any other such conjunctive; and 2nd, that \( S_i \), as determined above (in equation 24.), is of the same weight as the simplified residue, and can therefore only differ from it by some numerical factor. For the purpose of comparison of weights, it will of course be sufficient to confine our attention to the coefficients of the highest (or any other, the same power, for each) in \( x \) of the forms whose weights are to be compared.

Suppose \( f \) to be of \( m \) dimensions, and \( \phi \) to be of \( n \) dimensions in \( x \); and let \( m = n + e \).

Suppose

\[
\Delta \cdot f + L \cdot \phi = A x^i + B x^{i-1} + \ldots + K \\
\Delta = \lambda_0 x^q + \lambda_1 x^{q-1} + \ldots + \lambda_q \\
L = l_0 x^{q+e} + l_1 x^{q+e-1} + \ldots + l_{q+e}
\]

the number of homogeneous equations to be satisfied by the \( q + 1 \) quantities \( \lambda_0, \lambda_1, \ldots, \lambda_q \), and the \( q + e + 1 \) quantities \( \mu_0, \mu_1, \ldots, \mu_{q+e} \) will be \( m + q - i \), and therefore \( q + 1 \) and \( q + e + 1 \) taken together must be not less than \( m + q - i + 1 \), i.e. \( 2q + e + 2 \) must be not less than \( q + m - i + 1 \), i.e. \( q \) not less than \( m - i - e - 1 \); and if this inequality be satisfied \( 2q + e + 2 - (q + m - i - 1) + 1 \), i.e. \( q + i + e - m + 2 \) will be the number of arbitrary constants entering into the solution of equation (23.).

If \( q \) be greater than \( (n - 1) \), let \( q = (n - 1) + t \);

and let

\[
(\Lambda) = (\lambda_0) x^{n-1} + (\lambda_1) x^{n-2} + \ldots + (\lambda_{n-1}) \\
(L) = l_0 x^{n-e-1} + l_1 x^{n-e-2} + \ldots + l(x_{e+n-1})
\]

and let \( (\Lambda) \), \( (L) \) be so taken as to satisfy the equation

\[
(\Lambda) f + (L) \cdot \phi = A x&#x27; + B x^{-1} + \ldots + K ;
\]

and make

\[
X = (\Lambda) + (f + g x + \ldots + h x^{t-1}) \cdot \phi \\
X = (L) - (f + g x + \ldots + h x^{t-1}) f ,
\]

\( f, g, \ldots, h \) being arbitrary constants;

then

\[
X \cdot f + X \cdot \phi = (\Lambda) f + (L) \phi = A x&#x27; + B x^{-1} + \ldots + K .
\]

Now the total number of arbitrary constants in the system \( (\Lambda) \) and \( (L) \) will be \( n - 1 + i + e - m + 2 \), i.e. \( i + 1 \); hence the total number of arbitrary constants in \( X \) and
X will be \(i+1+t\), i.e. \(q-n+i+2\), which is equal to \(q+i+e-m+2\), the number of arbitrary constants in the most general values of \(\Delta\) and \(L\). Hence \(\{\Delta=\Xi; L=X\}\) is the general solution of \(\Delta f+L\varphi=Ax^i+Bx^{i-1}+\ldots+K\); and consequently the most general form of \(Ax^i+Bx^{i-1}+\ldots+K\), which is evidently independent of the \((t)\) arbitrary quantities \(f, g\ldots h\), will contain the same number of arbitrary constants as enter into the system \((\Lambda)\) and \((L)\), i.e. \(i+1\).

Art. (19.). Let us now begin with the case of greater simplicity when \(m=n\), i.e. \(e=0\); and let us revert to the system of equations marked (10.) in Section I., in which \(U\) and \(V\) are to be replaced by \(f\) and \(\varphi\).

1st. Let \(i=n-1\), and therefore \(i+1\), the number of arbitrary quantities in the conjunctive is \(n\).

From the system of equations (10.), we have for all values of \(\varepsilon_1, \varepsilon_2, \varepsilon_3\ldots \varepsilon_n\),

\[
(\varepsilon_1Q_0+\varepsilon_2Q_1+\ldots+\varepsilon_nQ_{n-1})f \\
-(\varepsilon_1P_0+\varepsilon_2P_1+\ldots+\varepsilon_nP_{n-1})\varphi \\
=(\varepsilon_1K_1+\varepsilon_2K_1+\ldots+\varepsilon_nK_{n-1})x^{n-1}+\&amp;c.,
\]

and consequently the most general value of \(\mathfrak{S}_{n-1}\) in the equation

\[
\tau_{n-1}f-t_{n-1}\varphi+\mathfrak{S}_{n-1}=0,
\]

where

\[
\mathfrak{S}_{n-1}=Ax^{n-1}+Bx^{n-2}+\ldots+L
\]

will be obtained by making

\[
\tau_{n-1}=\varepsilon_1Q_0+\varepsilon_2Q_1+\ldots+\varepsilon_nQ_n \\
t_{n-1}=-\varepsilon_1P_0-\varepsilon_2P_1\ldots-\varepsilon_nP_n,
\]

which solution contains \(n\), i.e. the proper number of arbitrary contents.

Again, if \(i=n-2\) \(i+1=n-1\), which will therefore be the number of arbitrary constants in the most general value of \(\mathfrak{S}_{n-2}\) of the equation

\[
\tau_{n-2}f-t_{n-2}\varphi+\mathfrak{S}_{n-2}=0.
\]

This most general value of \(\mathfrak{S}_{n-2}\) is therefore found by making

\[
\tau_{n-2}=\varepsilon&#x27;_1Q_0+\varepsilon&#x27;_2Q_1+\ldots+\varepsilon&#x27;_nQ_n \\
t_{n-1}=-\varepsilon&#x27;_1P_0-\varepsilon&#x27;_2P_1\ldots-\varepsilon&#x27;_nP_n,
\]

where \(\varepsilon&#x27;_1, \varepsilon&#x27;_2,\ldots\varepsilon&#x27;_n\) are no longer entirely independent, but subject to the equation

\[
\varepsilon&#x27;_1K_1+\varepsilon&#x27;_2K_1+\ldots+\varepsilon&#x27;_nK_{n-1}=0,
\]

so as to leave \((n-1)\) constants arbitrary.

We thus obtain \(\mathfrak{S}_{n-2}=(\varepsilon&#x27;_1K_1+\varepsilon&#x27;_2K_2+\ldots+\varepsilon&#x27;_nK_{n-1})x^{n-2}+\&amp;c.\). In like manner, and for the same reasons, the most general values of \(\mathfrak{S}_{n-3}\) in the equation

\[
\tau_{n-3}f-t_{n-3}\varphi+\mathfrak{S}_{n-3}=0
\]

will be found by making

\[
\tau_{n-3}=\varepsilon&#x27;&#x27;_1Q_0+\varepsilon&#x27;&#x27;_2Q_1+\ldots+\varepsilon&#x27;&#x27;_nQ_{n-1} \\
t_{n-3}=-\varepsilon&#x27;&#x27;_1P_0-\varepsilon&#x27;&#x27;_2P_1\ldots-\varepsilon&#x27;&#x27;_nP_{n-1},
\]
where \( \varepsilon_1&#x27;&#x27;, \varepsilon_2&#x27;&#x27;, \ldots \varepsilon_n&#x27;&#x27; \) are subject to satisfying the two equations

\[
\varepsilon_1&#x27;&#x27;.K_1 + \varepsilon_2&#x27;&#x27;.K_1 + \ldots + \varepsilon_n&#x27;&#x27;.K_1 = 0 \\
\varepsilon_1&#x27;&#x27;.K_2 + \varepsilon_2&#x27;&#x27;.K_2 + \ldots + \varepsilon_n&#x27;&#x27;.K_2 = 0,
\]

so as to leave \((n-2)\) constants arbitrary; and we thus obtain

\[
S_{n-3} = (\varepsilon_1&#x27;&#x27;.K_3 + \varepsilon_2&#x27;&#x27;.K_3 + \ldots + \varepsilon_n&#x27;&#x27;.K_3)x^{n-3} + &amp;c.,
\]

and so on, the number of independent arbitrary constants in \( S \) decreasing (as it ought) each time by one unit as the degree of \( S \) descends, until finally, if \( \sigma_0.f - t_0.\varphi + S_0 = 0 \), \( S_0 \) being a constant, the general value for \( S_0 \) is found by making

\[
\tau_0 = (\varepsilon_1).Q_0 + (\varepsilon_2).Q_1 + \ldots + (\varepsilon_n).Q_{n-1} \\
t_0 = -(\varepsilon_1).P_0 - (\varepsilon_2).P_1 - \ldots - (\varepsilon_n).P_{n-1},
\]

where \( \varepsilon_1, \varepsilon_2, \ldots \varepsilon_n \) are subject to satisfy the \((n-1)\) equations

\[
(\varepsilon_1).K_1 + &amp;c. = 0 \\
(\varepsilon_1).K_2 + &amp;c. = 0 \\
\vdots \\
(\varepsilon_1).K_{n-1} + &amp;c. = 0,
\]

which gives

\[
S_0 = K_n(\varepsilon)_1 + K_n(\varepsilon)_n + \ldots + K_n(\varepsilon)_n.
\]

Now evidently the lowest weight in respect to the roots of \( U \) and \( V \) that can be given to \((\varepsilon_1.K_1 + \varepsilon_2.K_1 + \ldots + \varepsilon_n.K_1)x^{n-1} + &amp;c.\), when the multipliers \( \varepsilon_1, \varepsilon_2, \ldots \varepsilon_n \) are absolutely independent, is found by taking \( \varepsilon_1 = 1 \) \( \varepsilon_2 = 0 \) \( \varepsilon_3 = 0 \ldots \varepsilon_n = 0 \), which makes the weight of the leading coefficient in \( S_{n-1} \), the same as that of \( K_1 \), i.e. 1.

Again, when one equation,

\[
\varepsilon_1.K_1 + \varepsilon_2&#x27;.K_1 + \ldots + \varepsilon_n&#x27;.K_1 = 0,
\]

exists between the \((\varepsilon&#x27;)\)’s, the lowest weight will be found by making

\[
\varepsilon_1&#x27; = K_1 \quad \varepsilon_2&#x27; = -K_1 \quad \varepsilon_3&#x27; = 0 \quad \varepsilon_4&#x27; = 0 \ldots \varepsilon_n&#x27; = 0,
\]

which makes the weight of the leading coefficient in \( S_{n-2} \) depend on

\[
K_1 K_2 - K_1 K_2,
\]

which is of the weight 1+3, i.e. 4 in respect of the roots of \( f \) and \( \varphi \).

Similarly, \( S_{n-3} \) will have its lowest weight when its leading coefficient is the determinant

\[
\begin{array}{ccc}
K_1 &amp; K_2 &amp; K_3 \\
K_1 &amp; K_2 &amp; K_3 \\
K_1 &amp; K_2 &amp; K_3,
\end{array}
\]

the weight of which is 1+3+5=9; and finally, the lowest weighted value of \( S_0 \) is the determinant represented by the complete Bezoutian square; the weight in general of \( S_{n-i} \) being 1+3+...+(2i-1), i.e. \( i^2 \), or which is the same thing otherwise expressed, the weight of the leading coefficient of the lowest-weighted conjunctive of \( f \) and \( \varphi \) of the degree \( i \) in \( x \) is \((n-i)(m-i)*\). It will of course have been seen in the fore-

* \( n \) and \( m \) are supposed equal and \( i=n-i \).
going demonstration, that the weight of \( K&#x27; \) [which means \( \Sigma (a_r b_s - a_s b_r) a_r a_s \)] being the coefficients of \( x^{n-r} \), \( x^{n-s} \) in \( f \); and \( b_r, b_s \) of the same in \( \varphi \)] has been correctly taken to be \( r+s \) in respect of the roots of \( f \) and \( \varphi \) conjoined.

Art. (20.). If now we proceed in like manner with the general case of \( m=n+e \), it may be shown, in precisely the same way as in the preceding article, that the most general value of any conjunctive of \( f \) and \( \varphi \) will be a linear function of \((e)\) functions,

\[
\begin{align*}
x^n &amp; + a_1 x^{n-1} + a_2 x^{n-2} + \ldots + a_n \\
x^{n+1} &amp; + a_1 x^n + a_2 x^{n-1} + \ldots + a_n x \\
x^{n+2} &amp; + a_1 x^{n+1} + a_2 x^n + \ldots + a_n x^2 \\
&amp; \cdots \cdots \cdots \cdots \cdots \cdots \cdots \\
x^{m-1} &amp; + a_1 x^{m-2} + \ldots + a_n x^{e-1},
\end{align*}
\]

and of the \((n)\) functions,

\[
\begin{align*}
K_1 x^{n-1} &amp; + K_2 x^{n-2} + \ldots + K_n \\
K_1 x^n &amp; + K_2 x^{n-1} + \ldots + K_n \\
&amp; \cdots \cdots \cdots \cdots \cdots \cdots \cdots \\
K_{n-1} x^{n-1} &amp; + K_{n-2} x^{n-2} + \ldots + K_n,
\end{align*}
\]

and that consequently, if the degree of such conjunctive in \( x \) be \((n-i)\), it will be of the lowest weight when it is a linear function of the entire \((e)\) upper set of functions, and \((i)\) of the lower set; and consequently, the coefficient of the highest power of \( x \) in such conjunctive will be the determinant

\[
\begin{array}{cccccc}
K_1 &amp; K_2 &amp; K_3 &amp; \ldots &amp; K_i &amp; \ldots \\
K_1 &amp; K_2 &amp; K_3 &amp; \ldots &amp; K_i &amp; \ldots \\
K_1 &amp; K_2 &amp; K_3 &amp; \ldots &amp; K_i &amp; \ldots \\
&amp; \vdots &amp; &amp; &amp; &amp; \\
&amp; \vdots &amp; &amp; &amp; &amp; \\
K_1 &amp; K_2 &amp; K_3 &amp; \ldots &amp; K_i &amp; \ldots \\
1 &amp; a_1 &amp; a_2 &amp; \ldots &amp; a_{i-1} &amp; a_i &amp; \ldots &amp; a_{i+e} \\
1 &amp; a_1 &amp; a_2 &amp; \ldots &amp; a_{i-1} &amp; a_i &amp; \ldots &amp; a_{i+e-1} \\
&amp; \vdots &amp; &amp; &amp; &amp; \\
&amp; \vdots &amp; &amp; &amp; &amp; \\
1 &amp; a_1 &amp; \ldots &amp; a_{i-2} &amp; a_i &amp; \ldots &amp; a_{i+e-2} \\
&amp; \vdots &amp; &amp; &amp; &amp; \\
&amp; \vdots &amp; &amp; &amp; &amp; \\
1 &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; a_i,
\end{array}
\]

the weight of which is evidently that of

\[
K_1 \times K_2 \times K_3 \ldots \times K_i \times (a_i)^e,
\]

i.e. \( 1+3+5+\ldots+(2i-1)+e.i \)

i.e. \( i^2+ei \), or \( i(e+i) \), which is \((n-i)(m-i)\) if \( i=n-i \).
Hence the weight of the leading coefficient in the lowest-weighted conjunctive of \( f \) and \( \varphi \) of the degree \( i \) in \( x \) is \((m-i)(n-i)\), \( m \) being the degree of \( f \) and \( n \) of \( \varphi \).

From this we infer that any conjunctive of \( f \) and \( \varphi \) of the degree \( i \), of which the leading coefficient is of the weight \((m-i)(n-i)\) (all the coefficients being of course understood to be integral functions of the roots of \( f \) and \( \varphi \)), must, to a numerical factor près, be equivalent to any other of the same weight; and furthermore, any supposed function of \( x \) of the \( i \)th degree which possesses the property characteristic of a conjunctive of vanishing, when \( f \) and \( \varphi \) vanish simultaneously, but of which the weight of the leading coefficient would be less than \((m-i)(n-i)\), must be a mere nugatory form and have all its terms identically zero*.

Art. (21.). We have previously shown, art. (16.), that \( S \), as defined by equation (21.), is an integral function of the roots \( f \) and \( \varphi \), and vanishes when \( f \) and \( \varphi \) vanish. Moreover, its weight in the roots has been proved to be \((m-i)(n-i)\), and consequently, if by way of distinguishing the several forms of \( S \), we name that one where \( i \) in the equation above cited is supposed to be divided into two parts, \( v \) and \( \nu \), \( S_{v,\nu} \), we have for all values of \( v \) and \( \nu \), such that \( v+\nu \) is not greater than \( n \), \( S_{v,\nu} \) to a constant numerical factor près identical with the \((v+\nu)\)th simplified residue to \((f, \varphi)\), so that the form of \( S_{v,\nu} \) depends only upon the value of \( v+\nu \).

Art. (22.). It must be well borne in mind that this permanency of the value of \( S_{v,i-\nu} \) for different values of \( v \) has only been established for the case where \( i \) can be the degree of a residue to \( f \) and \( \varphi \), that is to say, when \( i \) is less than the lesser of the two indices \( m \) and \( n \). When \( i \) does not satisfy this condition of inequality, the theorem ceases to be true. It is clear that when \( m=n \) and \( v+\nu=m=n \), \( S_{v,\nu} \) which always remains a conjunctive of \( f \) and \( \varphi \), can only be a numerical linear function of \( f \) and \( \varphi \); and I have ascertained when \( m=n \) on giving to \( v \) and \( \nu \) the respective values successively \((0, n), (1, n-1), (2, n-2), \ldots (n, 0)\)

that

\[
S_{0,n}=f; \quad S_{1,n-1}=(n-1)f+\varphi; \quad S_{2,n-2}=\frac{(n-1)(n-2)}{1.2}f+(n-1)\varphi\ldots
\]

\[
S_{i-1,1}=f+(n-1)\varphi; \quad S_{n,0}=\varphi.
\]

Thus, by way of a simple example, let

\[
f=x^2+ax+b=(x-h_1)(x-h_2)
\]

\[
\varphi=x^2+\alpha x+\beta=(x-\eta_1)(x-\eta_2)
\]

\[
S_{0,2}=(x-h_1)(x-h_2)\begin{bmatrix}
h_1 &amp; h_2 \\
\vdots &amp; \vdots \\
k_1 &amp; k_2 \\
\vdots &amp; \vdots \\
k_1 &amp; k_2
\end{bmatrix} = (x-h_1)(x-h_2)=f&#x27;
\]

* And more generally it admits of being demonstrated by precisely the same course of reasoning, that the number of arbitrary parameters in a conjunctive of the degree \( i \), and of the weight \((m-i)(n-i)+\varepsilon\) in the roots cannot (abstraction being supposed to be made of an arbitrary numerical multiplier) exceed the number \( \varepsilon \).
\[
S_{1,1} = \Sigma (x-h_1)(x-k_1) \begin{bmatrix} h_1 \\ k_1 \\ h_2 \\ k_2 \end{bmatrix} \times \begin{bmatrix} h_2 \\ k_2 \\ h_1 \\ k_1 \end{bmatrix}
\]

\[= \Sigma \frac{x-h_1}{h_1-h_2} \frac{x-k_1}{k_1-k_2} \{(h_1-k_1)(h_2-k_2)\},\]

i.e.,

\[= \Sigma \frac{x-h_1}{h_1-h_2} \left\{ \frac{1}{k_1-k_2} \left( (x-h_1)(h_1-k_1)(h_2-k_2) - (x-k_2)(h_1-k_1)(h_2-k_1) \right) \right\}\]

\[= \Sigma \frac{x-h_1}{h_1-h_2} \left\{ (h_1-h_2)x + \{(k_1+k_2)h_2-(h_1h_2+k_1k_2)\} \right\}\]

\[= (x-h_1)x+(x-h_2)x-(k_1+k_2)x+(h_1h_2+k_1k_2)\]

\[= (x^2-(h_1+h_2)x+h_1h_2)+(x^2-(k_1+k_2)x+k_1k_2)\]

\[= (x^2+ax+b)+(x^2+\alpha x+\beta)\]

\[= f+\varphi;\]

so we find also \(S_{0,0}=\varphi.\)

Art. (23.). The expression \(S_{v,v}\), which is universally a conjunctive of \(f\) and \(\varphi\), continues algebraically interpretable so long as \(v+v\) has any value intermediate between (0) and \(m+n\); when \(v+v=0\), we must of course have \(v=0\) and \(v=0\), and \(S_{0,0}\) becomes the resultant of \(f\) and \(\varphi\) when \(v+v=m+n\); we must also have the unique solution \(v=m\) and \(v=n\), and \(S_{m,n}\) becomes necessarily \(f\times\varphi\), which we thus see stands in a sort of antithetical relation to the resultant of \(f\) and \(\varphi\), say \((f,\varphi)\). Nor is it without interest to remark that \(f\times\varphi=0\) implies that a root of \(f\) or else of \(\varphi\) is zero; and \((f,\varphi)=0\) implies that if a root of the one of the functions is zero, so also is a root of the other, i.e. that a root of each or of neither is zero. As \(i\) increases from 0 to \(n\) or decreases from \(m+n\) to \(m-1\), the number of solutions of the equation \(v+v=i\) in the one case, and the number of admissible solutions of the equation \(v+v=i\) in the other case, which is subject to the condition that \(v\) must not exceed \(n\), continues to increase by a unit at each step; there being thus \(n+1\) different forms \(S_{v,v}\) when \(v+v=n\), and the same number when \(v+v=m-1\). For all values of \(i\) intermediate between \(n\) and \((m-1)\) (both taken exclusively) it is very remarkable that \(S_{v,v}\) will vanish, as I proceed to demonstrate.

Art. (24.). The weight of the coefficient of the highest power of \(S_{v,v}\) (\(v+v\) being equal to \(i\)) is \((m-i)(n-i)\), and consequently, when \(i\) is greater than \(n\), and less than \(m\), \(S_{v,v}\) would contain fractional functions of the roots of \(f\) and \(\varphi\), if there were in it a power \(x^i\), but \(S_{v,v}\) has been proved to be always an integer function of the roots. Hence the coefficient of \(x^i\) will be zero, and so more generally the first power of \(x\) in \(S_{v,v}\), of which the coefficient is not zero, will be \(x^\omega\), subject to the condition (since evidently the weight of the several coefficients goes on increasing by units as the degree of the terms in \(x\) decreases by the same) that \(\omega\) be not less than \((m-i)(i-n)\); let then \(\omega=(m-i)(i-n)\), \(S_{v,v}\) becomes of the form \(Ax^{i-\omega}+Bx^{i-\omega-1}+\&amp;c.\), where \(A\) is of zero dimensions; but this is impossible if \(i-\omega&lt;n\), for then \(Ax^{i-\omega}+\&amp;c.\) is a conjunctive of
weight lower than the lowest-weighted simplified residue of the degree \( i - \omega \). Hence \( \omega \) is not greater than \( i - n \) or \((m-i)(i-n)\) is not greater than \( i - n \), i.e., \( m - i \) cannot be greater than 1, i.e., when intermediate between \( m \) and \( n \) cannot be less than \( m - 1 \), otherwise \( S_{n,v} \) will vanish identically. Moreover, when \( i = m - 1 \), \( \omega = i - n \), and \( i - \omega = n \), and accordingly \( S_{n,m+1-v} \) is not merely, as we might know, \( a \) priori an algebraical, but more simply a numerical multiple of \( \varphi \) for all values of \( v \). The same is of course true also, \( m \) being greater than \( n \), for every form \( S_{v,n-v} \), since this is always a conjunctive of \( f \) and \( \varphi \), of which the former is of a degree higher than the \( S \) in question, so that the multiplier of \( f \) in this conjunctive must be zero*.

Art. (25.). To enter into a further or more detailed examination of the values assumed by \( S_{v,v} \) for the most general values of \( m, n, i \), would be to transcend the limits I have proposed to myself in drawing up the present memoir. What we have established is, that to every form of \( S_{v,i-v} \) appertaining to a value of \( i \) between 0 and \( n \), there is a sort of conjugate form for which \( i \) lies between \( m + n \) and \( m \); that for \( i = m - 1 \) or \( i = n \), \( S_{v,i-v} \) becomes a numerical multiplier of \( \varphi \); and that when \( i \) lies in the intermediate region between \( n \) and \( m - 1 \), \( S_{v,i-v} \) vanishes for all values of \( v \). I pause only for a moment to put together for the purpose of comparison the forms corresponding to \( i \) and to \( m + n - i \). By art. (16.), making \( i = v + v \),

\[
S_i = \Sigma(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_v}) \times (x-\eta_{\xi_1})(x-\eta_{\xi_2})\ldots(x-\eta_{\xi_v})
\]

The conjugate form for which \( i = m + n - i \) and \( m - v \) \( n - v \) take the places of \( v \) and \( v \)

\[
(m-v)(n-v) \text{ will be got by taking}
\]

\[
S_v = \Sigma(x-h_{q_{v+1}})(x-h_{q_{v+2}})\ldots(x-h_{q_m}) \times (x-\eta_{\xi_{v+1}})(x-\eta_{\xi_{v+2}})\ldots(x-\eta_{\xi_n})
\]

which it will be perceived are identical, term for term, in the fractional constant factor, and differ only in the linear functions of \( x \), which in \( S_i \) and in \( S_v \) are complementary to one another. Our proper business is only with those forms for which \( i &lt; n \).

Art. (26.). It will presently be seen to be necessary to ascertain the numerical relations between \( S_{0,i} \) and \( S_{i,0} \) when \( i &lt; n \), and this naturally brings under our notice the

* It thus appears that if the indices \( m \) and \( n \) do not differ by at least 3 units, \( S \) will have an actual quantitative existence for all values of \( i \) between 0 and \( m + n \); or in other words, the failure in the quantitative existence of the forms \( S_i \) only begins to show itself when this difference is 3; thus if \( m = n + 3 \), \( S_n \) exists, and \( S_{n+2} \) exists, but \( S_{n+1} = 0 \).
inquiry into the numerical relations which exist between the entire series of forms $\mathcal{S}_{n,i-v}$ for a given value of $i$, corresponding to all values of $v$ between 0 and $i$ inclusive.

In order to avoid a somewhat oppressive complication of symbols, I shall take a particular numerical example, i.e., $m=7$ $n=6$ $i=4$, and compare the values of $\mathcal{S}_{0,4}$; $\mathcal{S}_{1,3}$; $\mathcal{S}_{2,2}$; $\mathcal{S}_{3,1}$; $\mathcal{S}_{4,0}$, all of which we know to be identical, [to a numerical factor près] with one another and with the second simplified residue to $f$ and $\varphi$, that being of the fourth degree in $x$; our object in the subjoined investigation is to determine the numerical ratios of these several forms of $\mathcal{S}$ to one another.

First. Let $v=0$ $v=4$. The leading coefficient $\mathcal{S}_{0,4}$ is

$$\sum_{h_1 h_2 h_3 h_4 h_5 h_6 h_7} \frac{n_5 n_6}{n_1 n_2 n_3 n_4},$$

which we know à priori (it should be observed) to be essentially an integral function of the $h$ and the $n$ system. In this, the term containing $n_0^3$ will be evidently

(A.)

$$\sum_{h_1 h_2 h_3 h_4 h_5 h_6 h_7} \frac{n_5}{n_1 n_2 n_3 n_4},$$

the $n$ system to which the latter summation relates being now reduced to consist of $n_1 n_2 n_3 n_4 n_5$. In this expression, again, the coefficient of $n_5^3$ is evidently 1. Hence, therefore, the leading coefficient in $\mathcal{S}_{0,4}$ contains the term $n_0^3 n_5^3$.

Secondly. Let $v=1$ $v=3$. The leading coefficient in $\mathcal{S}_{1,3}$ becomes

$$\sum_{h_1 h_2 h_3 h_4 h_5 h_6 h_7} \left[ \begin{array}{c} n_1 n_2 n_3 \\ h_1 \end{array} \right] \times \left[ \begin{array}{c} n_4 n_5 n_6 \\ h_2 h_3 h_4 h_5 h_6 h_7 \end{array} \right],$$

In this, the factor affecting $n_6^3$ will be

$$\sum_{h_1 h_2 h_3 h_4 h_5 h_6 h_7} \left[ \begin{array}{c} n_1 n_2 n_3 \\ h_1 \end{array} \right] \times \left[ \begin{array}{c} n_4 n_5 \\ h_2 h_3 h_4 h_5 h_6 h_7 \end{array} \right],$$

$n_6$ being now understood to be eliminated out of the $n$ system included within the above summation. Again, in this latter sum the factor affecting $n_5^3$ will be

(B.)

$$\sum_{h_1 h_2 h_3 h_4 h_5 h_6 h_7} \left[ \begin{array}{c} n_1 n_2 n_3 \\ h_1 \end{array} \right] \times \left[ \begin{array}{c} n_4 \\ h_2 h_3 h_4 h_5 h_6 h_7 \end{array} \right],$$

$n_5$ and $n_6$ being now both eliminated out of the $n$ system. This last sum can of course only represent a numerical quantity.
So in like manner, again, if \( v = 2 \) \( r = 2 \), the coefficient of \( n_6^3 n_5^2 \) will be similarly reducible to the form

\[
(C.) \quad \sum \begin{bmatrix} n_1 &amp; n_2 \\ h_1 &amp; h_2 \end{bmatrix} \times \begin{bmatrix} n_3 &amp; n_4 \\ h_3 &amp; h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 \\ h_5 &amp; h_6 \end{bmatrix} \times \begin{bmatrix} n_7 \\ h_7 \end{bmatrix} \text{ in } S_{2,2}.
\]

So, again, when \( v = 3 \) \( r = 1 \), the coefficient of \( n_6^3 n_5^3 \) will be

\[
(D.) \quad \sum \begin{bmatrix} n_1 &amp; n_2 &amp; n_3 \\ h_1 &amp; h_2 &amp; h_3 \end{bmatrix} \times \begin{bmatrix} n_4 &amp; n_5 &amp; n_6 \\ h_4 &amp; h_5 &amp; h_6 \end{bmatrix} \times \begin{bmatrix} n_7 \\ h_7 \end{bmatrix} \text{ in } S_{3,1};
\]

and finally, the coefficient of \( n_6^3 n_5^3 \) will be

\[
(E.) \quad \sum \begin{bmatrix} n_1 &amp; n_2 &amp; n_3 &amp; n_4 \\ h_1 &amp; h_2 &amp; h_3 &amp; h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 &amp; n_7 \\ h_5 &amp; h_6 &amp; h_7 \end{bmatrix} \text{ in } S_{0,4},
\]

out of all which sums it is to be remembered that \( n_5 \) and \( n_6 \) are supposed excluded from appearing. All these several coefficients being numbers in disguise, we may determine them by giving any values at pleasure to the terms in the \( h \) and \( n \) system.

Let now \( n_1 = h_1 \) \( n_2 = h_2 \) \( n_3 = h_3 \) \( n_4 = h_4 \), then in (B.) it will readily be seen that all the terms included within the sign of summation vanish identically, except the following, viz.—

\[
\begin{align*}
&amp;\begin{bmatrix} n_1 &amp; n_2 &amp; n_3 \\ h_1 &amp; h_2 &amp; h_3 \end{bmatrix} \times \begin{bmatrix} n_4 \\ h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 &amp; n_7 \\ h_5 &amp; h_6 &amp; h_7 \end{bmatrix}, \\
&amp;\begin{bmatrix} n_1 &amp; n_2 &amp; n_3 \\ h_1 &amp; h_2 &amp; h_3 \end{bmatrix} \times \begin{bmatrix} n_4 \\ h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 &amp; n_7 \\ h_5 &amp; h_6 &amp; h_7 \end{bmatrix}, \\
&amp;\begin{bmatrix} n_1 &amp; n_2 &amp; n_3 \\ h_1 &amp; h_2 &amp; h_3 \end{bmatrix} \times \begin{bmatrix} n_4 \\ h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 &amp; n_7 \\ h_5 &amp; h_6 &amp; h_7 \end{bmatrix}, \\
&amp;\begin{bmatrix} n_1 &amp; n_2 &amp; n_3 \\ h_1 &amp; h_2 &amp; h_3 \end{bmatrix} \times \begin{bmatrix} n_4 \\ h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 &amp; n_7 \\ h_5 &amp; h_6 &amp; h_7 \end{bmatrix}, \\
&amp;\begin{bmatrix} n_1 &amp; n_2 &amp; n_3 \\ h_1 &amp; h_2 &amp; h_3 \end{bmatrix} \times \begin{bmatrix} n_4 \\ h_4 \end{bmatrix} \times \begin{bmatrix} n_5 &amp; n_6 &amp; n_7 \\ h_5 &amp; h_6 &amp; h_7 \end{bmatrix}.
\end{align*}
\]

In each of these expressions the first factor of the numerator is identical in value
(by reason of the equations \( h_1 = \eta_1, h_2 = \eta_3, h_3 = \eta_3, h_4 = \eta_4 \)) with \((-)^3 \times\) the second factor of the denominator, and the second factor of the numerator with \((-)^6 \times\) the first factor of the denominator; hence the coefficient of \(\eta_5^3\eta_6^3\) in \(\mathfrak{S}_{1,3}\) is \(-4\).

In like manner the only effective terms of \(\mathfrak{S}_{2,2}\) will be

\[
\begin{bmatrix}
\eta_1 &amp; \eta_2 \\
h_3 &amp; h_4
\end{bmatrix} \times \begin{bmatrix}
\eta_3 &amp; \eta_4 \\
h_1 &amp; h_2
\end{bmatrix}, \quad \begin{bmatrix}
\eta_3 &amp; \eta_4 \\
h_1 &amp; h_2
\end{bmatrix} \times \begin{bmatrix}
\eta_1 &amp; \eta_2 \\
h_3 &amp; h_4
\end{bmatrix},
\]

\[
\begin{bmatrix}
\eta_1 &amp; \eta_3 \\
h_2 &amp; h_4
\end{bmatrix} \times \begin{bmatrix}
\eta_2 &amp; \eta_4 \\
h_1 &amp; h_3
\end{bmatrix}, \quad \begin{bmatrix}
\eta_2 &amp; \eta_4 \\
h_1 &amp; h_3
\end{bmatrix} \times \begin{bmatrix}
\eta_1 &amp; \eta_3 \\
h_2 &amp; h_4
\end{bmatrix},
\]

\[
\begin{bmatrix}
\eta_1 &amp; \eta_4 \\
h_2 &amp; h_3
\end{bmatrix} \times \begin{bmatrix}
\eta_2 &amp; \eta_3 \\
h_1 &amp; h_4
\end{bmatrix}, \quad \begin{bmatrix}
\eta_2 &amp; \eta_3 \\
h_1 &amp; h_4
\end{bmatrix} \times \begin{bmatrix}
\eta_1 &amp; \eta_4 \\
h_2 &amp; h_3
\end{bmatrix}.
\]

Any other term will necessarily contain in the numerator a factor, whose symbolical representation will contain one of the quantities \(\eta_1, \eta_2, \eta_3, \eta_4\) in the upper line, and one of the quantities \(h_1, h_2, h_3, h_4\), having the same subscript index in the lower line, and which will therefore vanish; the number of effective terms being evidently the number of ways in which four things can be combined 2 and 2 together, and the value of each term is evidently \((-)^{2 \cdot 2} \cdot (-1)^{2 \cdot 5} \cdot 1\), so that the entire value of the coefficient of \(\eta_5^3\eta_6^3\) in \(\mathfrak{S}_{2,2}\) is \(+6\).

Precisely in the same manner, we shall find that the leading coefficient in \(\mathfrak{S}_{3,1}\) will contain the term \(-4\eta_5^3\eta_6^3\), the \((-1)\) resulting from the operation \((-1)^{1 \cdot 3} \cdot (-1)^{3 \cdot 4}\), and in \(\mathfrak{S}_{4,0}\) the term \(+\eta_5^3\eta_6^3\), the \(+1\) resulting from the operation \((-1)^{4 \cdot 3}\). Hence it appears that \(\mathfrak{S}_{0,i}; \mathfrak{S}_{1,3}; \mathfrak{S}_{2,2}; \mathfrak{S}_{3,1}; \mathfrak{S}_{4,0}\) are to one another in the ratios of \(1; -4; 6; -4; 1\); and so in general for any values of \(m, n, i\) (\(i\) being less than \(m\) and less than \(n\)) it will be found that

\[
\mathfrak{S}_{0,i} : \mathfrak{S}_{1,i-1} : \mathfrak{S}_{2,i-2} : \ldots : \mathfrak{S}_{i,0}
\]

will be in the ratios of the numbers

\[
1; \quad (-1)^{m-i} \cdot i; \quad (-1)^{2(m-2)} \cdot i \cdot \frac{i-1}{2}; \quad (-1)^{3(m-3)} \cdot i \cdot \frac{i-1}{2} \cdot \frac{i-2}{3}, \ldots; \quad (-1)^{i(m-i)}.
\]

Art. (27.). The method employed in the preceding investigation will enable us to affix the proper sign and numerical factor to \(\mathfrak{S}_{0,i}\) or \(\mathfrak{S}_{i,0}\), or in general to \(\mathfrak{S}_{n,i-n}\), in order that it may represent the Bezoutian secondary of the degree \(i\) in \(x\). [This latter has been already identified with the simplified residue obtained by expanding \(\phi x / f x\) under the form of an improper continued fraction.] For this purpose, it will be sufficient to compare a single term of any such \(\mathfrak{S}\) with the corresponding one in the Symmorphic Bezoutian secondary. Let us first suppose that \(m=n, f\) and \(\phi\) being of
the same degree. A glance at the form of the Bezoutian square will show that if we form the Bezoutian secondary of the degree \((n-i)\) in \(x\), the coefficient of its leading term will contain the term \((-)^{(i-1)/2}(0,i)\); \((0,i)\) as usual denoting the product of the coefficient of \(x^n\) in \(f\) by the coefficient of \(x^{n-i}\) in \(\phi\), less the product of the coefficient of \(x^n\) in \(\phi\) by that of \(x^{n-i}\) in \(f\); and as we suppose the first coefficients in \(f\) and \(\phi\) to be each 1, if we term the other coefficients last spoken of \(a_i\) and \(\alpha_i\) respectively, this said coefficient of the leading term of the \(i\)th Bezoutian secondary will contain the term \((-)^{(i-1)/2}(a_i-\alpha_i)\), and consequently \((-1)^{(i-1)/2}a_i^i\) and \((-)^{i+1/2}a_i^i\).

Now by the like reasoning as that employed in the preceding article, the coefficient of the leading term in \(\Phi_{m-i,0}\) i.e.

\[
\Sigma(x-h_{q_i+1})(x-h_{q_i+2})\ldots(x-h_{q_m})\begin{bmatrix}
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
\eta_1, \eta_2, \ldots, \eta_m \\
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m}
\end{bmatrix}
\]

will contain the quantity \(\Sigma(h_1,h_2,h_3\ldots h_i)^i\), and therefore will contain a term \((\Sigma(h_1,h_2,h_3\ldots h_i))^i\), i.e. \((-)^ia_i^i\) which is equal to \((-)^ia_i^i\) since \((i-1)i\) is always even.

Hence \(\Phi_{m-i,0}=(-)^{i-1/2}\times\) the corresponding Bezoutian secondary.

Art. (28.). The above applies to the case where we have supposed \(m=n\). When this equality does not exist we may proceed as follows. Prefix to \(\phi(x)\), the first coefficient of which is still supposed to be 1, a term \(\varepsilon-x^m\), where \(\varepsilon\) is positive and indefinitely small, and let \(\phi x\) so augmented be called \(\Phi(x)\). Then if \(k_1,k_2\ldots k_n\) are the roots of \(\phi x\), \(k_1,k_2\ldots k_n\), together with the \((m-n)\) values of \(\left(\frac{1}{\varepsilon}\right)^{\frac{1}{m-n}}\), will be the roots of \(\Phi(x)\).

But it has already been proved that when (as here supposed) the first coefficient of \(f x\) is 1, the Bezoutian secondaries to \(f\) and \(\phi\) will be identical with those to \(f\) and \(\Phi\) respectively; at least it has been proved that these latter, when \(\varepsilon=0\), but the form of \(\Phi\) is preserved, become identical with the former, and consequently the same is true when \(\varepsilon\) is taken indefinitely small. Now if we call the \((m-n)\) roots of \(\Phi\) which do not belong to \(\phi\), \(\eta_{n+1}, \eta_{n+2}\ldots \eta_m\), and make

\[
\Psi_{m-i,0}=\Sigma(x-h_{q_i+1})(x-h_{q_i+2})\ldots(x-h_{q_m})\begin{bmatrix}
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
\eta_1, \eta_2, \ldots, \eta_m \\
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m}
\end{bmatrix},
\]

we have \(\Psi_{m-i,0}=\Sigma P(h_{q_1}, h_{q_2}, \ldots, h_{q_i})\begin{bmatrix}
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
\eta_{n+1}, \eta_{n+2}, \ldots, \eta_m \\
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m}
\end{bmatrix}\),

where \(P(h_{q_1}, h_{q_2}, \ldots, h_{q_i})=(x-h_{q_i+1})(x-h_{q_i+2})\ldots(x-h_{q_m})\begin{bmatrix}
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
\eta_1, \eta_2, \ldots, \eta_m \\
h_{q_1}, h_{q_2}, \ldots, h_{q_i} \\
h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m}
\end{bmatrix}\).
But since $k_{n+1}, k_{n+2} \ldots k_m$ are infinite in value,

$$\begin{bmatrix}
h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_i} \\
k_{n+1} &amp; k_{n+2} &amp; \ldots &amp; k_m
\end{bmatrix} = ((-k_{n+1}) \cdot (-k_{n+2}) \ldots (-k_m))^i \left(\frac{1}{\varepsilon}\right)^i.$$  

Hence

$$\Psi_{m-i, 0} = \left(\frac{1}{\varepsilon}\right)^i \Sigma P(h_{q_1}, h_{q_2}, \ldots h_{q_i})$$

$$= \left(\frac{1}{\varepsilon}\right)^i S_{m-i, 0}$$

and

$$S_{m-i, 0} = \varepsilon^i \Psi_{m-i, 0}.$$  

But by what has been shown antecedently [taking account of the fact of the leading coefficient of $\Phi$ being $\varepsilon$ in place of 1, which introduces the factor $\varepsilon^i$], we have

$$\varepsilon^i \Psi_{m-i, 0} = (-)^{(i-1)\frac{i}{2}} B&#x27;_i,$$

where $B&#x27;_i$ is the Bezoutian secondary of the $(m-i-1)$th degree in $x$ to $f$ and $\phi$; but $B&#x27;_i$ it has been proved $= B_i$, the Bezoutian secondary of the same degree to $f$ and $\phi$; hence $S_{m-i, 0} = (-)^{\frac{i-1}{2}} B_i.$

Art. (29.). If now we return to the syzygetic equation, $\tau f - t \phi + S = 0$, $S$ may be treated as known, having in fact been completely determined as a function of the roots, as well in its most general form, as also so as to represent the simplified residues to $f$ and $\phi$ in the preceding articles; it remains to determine the values of $\tau$ and $t$ as functions of the roots corresponding to any allowable form of $S$, but I shall confine the investigation to the case where $S$ is the lowest-weighted conjunctive, or which is the same thing, a simplified residue to $t$ and $\phi$ of any given degree in $x$; each value of $\frac{\tau}{t}$ will then represent one of the convergents to $\frac{\phi}{f}$ when expanded under the form of a continued fraction. If $S$ be of the $i$th degree in $x$, $\tau$ is of the degree $(n-i-1)$ and $t$ of the degree $(m-i-1)$. This being supposed, and calling $n-i-1 = v$, $m-i-1 = \mu$, I say that $t$ will be represented by $G$ and $\tau$ by $\Gamma$, where

$$G = (-)^i \Sigma (x-h_{q_1})(x-h_{q_2}) \ldots (x-h_{q_\mu}) \begin{bmatrix}
h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_\mu} \\
\eta_1 &amp; \eta_2 &amp; \ldots &amp; \eta_n \\
h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_\mu} \\
h_{q_{\mu+1}} &amp; h_{q_{\mu+2}} &amp; \ldots &amp; h_{q_m}
\end{bmatrix},$$

and $\tau$ is an analogous form $\Gamma$; $h_1, h_2 \ldots h_m$, as heretofore, being the roots of $f$, and $\eta_1, \eta_2 \ldots \eta_n$ of $\phi$. To fix the ideas and make the demonstration more immediately seizable, give $m$ and $n$ specific values; thus let $m = 5$, $n = 4$, $i = 2$, so that $\mu = 5 - 2 - 1 = 2$. Put $S$ under the form $S_{i, 0}$, so that $S$ in the case before us

$$= \Sigma (x-h_{q_1})(x-h_{q_2}) \begin{bmatrix}
h_{q_3} &amp; h_{q_4} &amp; h_{q_5} \\
\eta_1 &amp; \eta_2 &amp; \eta_3 &amp; \eta_4 \\
h_{q_3} &amp; h_{q_4} &amp; h_{q_5} \\
h_{q_1} &amp; h_{q_2}
\end{bmatrix}.$$
Now make \( x = h \), then \( f = 0 \), and \( \Omega \) becomes

\[
\Sigma(h_1 - h_q)(h_1 - h_q) \begin{bmatrix}
h_{q_1} &amp; h_{q_2} &amp; h_{q_3} \\
h_{q_4} &amp; h_{q_5} &amp; h_{q_6}
\end{bmatrix},
\]

i.e.

\[
\Sigma \begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix} \begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix},
\]

\( h_1 \) being kept constant in the above sum, but \( h_2, h_3, h_4, h_5 \) being partitionable in all the six possible ways into two groups, as into \( h_4, h_5, h_2, h_3 \) in the term above expressed.

This sum is evidently identical with

\[
\Sigma \begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix}, \text{i.e. } \begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix} \times \Sigma \begin{bmatrix}
h_2 &amp; h_3 \\
h_4 &amp; h_5
\end{bmatrix}.
\]

Again, \( \phi \) becomes

\[
\begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix}.
\]

Hence \( t = \frac{s}{\phi} \) becomes

\[
\Sigma \begin{bmatrix}
h_2 &amp; h_3 \\
h_4 &amp; h_5
\end{bmatrix}.
\]

But when \( x = h_1 \), \( \frac{G}{(-)^i} \) becomes

\[
\begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix},
\]

i.e.

\[
\begin{bmatrix}
h_1 &amp; h_2 &amp; h_3 \\
h_4 &amp; h_5 &amp; h_6
\end{bmatrix},
\]

\[
= (-1)^i \cdot t.
\]

Thus when \( x = h_1 \), \( t = G \). In like manner, when \( x = h_2 \), or \( h_3 \), or \( h_4 \), or \( h_5 \), \( t \) always \( = G \); but \( t \) and \( G \) are both functions of \( x \) of the same degree, and of only two dimensions in \( x \). Hence \( t \) is identical with \( G \). So in general it may be proved, that whenever \( x = h_1 \), or \( h_2 \) or \( h_3 \ldots \) or \( h_n \), \( t \) and \( G \), which are each of only \((n-1-i)\) dimensions in \( x \),
are equal. Hence universally \( t = G \), as was to be shown. To find \( \tau \) we must avail ourselves of the symmorphic, or as we may better say (it being at the opposite extremity of the scale of forms, the antimorphic), value of \( S \) represented by \( S_0 \), taking care to preserve \( S \) strictly identical under both forms of representation, in point of sign as well as quantity. That is to say, we must make

\[
S_{0,i} = (-)^{i(m-n)} \sum (x - \eta_i)(x - \eta_{i+1}) \ldots (x - \eta_m)
\]

\[
= (-)^{\omega} \sum (x - \eta_i)(x - \eta_{i+1}) \ldots (x - \eta_m),
\]

where

\[
\omega = i(m-i) + m(n-i),
\]

so that

\[
(-)^{\omega} = (-)^{mi-i+mn-mi} = (-)^{mn-i};
\]

and consequently the same reasoning as was applied to \( t \) to prove \( t = G \), will serve to show that \( -\tau = \Gamma \), where

\[
\Gamma = (-)^{mn} \sum (x - \eta_{\xi_1})(x - \eta_{\xi_2}) \ldots (x - \eta_{\xi_n})
\]

or

\[
\tau = (-)^{\omega} \sum (x - \eta_{\xi_1})(x - \eta_{\xi_2}) \ldots (x - \eta_{\xi_n}),
\]

where

\[
\omega = mn - 1 - mn = mn - 1 - m(n-i-1)
\]

\[
= mi - m - 1.
\]

Art. (30.). I have not succeeded in throwing \( t \) and \( \tau \) under any other than the single forms for each above given, and it is remarkable that whilst apparently \( t \) and \( \tau \) admit only of this single representation, \( S \) admits of the variety of forms included under the general symbol \( S_{0,i} \) for a given value of \( i \); and it ought to be remarked that these forms (although the most perfectly symmetrical and exactly balanced representations) [and for that reason possibly the most commodious for the ascertainment of the allotrious factor belonging to them respectively] by no means exhaust the almost infinite variety of modes by which the simplified residues, i.e. the hekistobarytic, or if we like so to call them, the prime conjunctives, admit of being represented
as functions of the roots of the given functions; but if in art. (16.), instead of writing

\[ R = \frac{\begin{bmatrix} h_{q_1}, h_{q_2}, \ldots, h_{q_v} \\ \eta_{\varepsilon_1}, \eta_{\varepsilon_2}, \ldots, \eta_{\varepsilon_v} \end{bmatrix}}{\begin{bmatrix} h_{q_1}, h_{q_2}, \ldots, h_{q_v} \\ h_{q_{v+1}}, h_{q_{v+2}}, \ldots, h_{q_m} \end{bmatrix}} \times \frac{\begin{bmatrix} \eta_{\varepsilon_1}, \eta_{\varepsilon_2}, \ldots, \eta_{\varepsilon_v} \\ \eta_{\varepsilon_{v+1}}, \eta_{\varepsilon_{v+2}}, \ldots, \eta_{\varepsilon_m} \end{bmatrix}}, \]

we had made

\[ R = \frac{P(h_{q_1}, h_{q_2}, \ldots, h_{q_v}; \eta_{\varepsilon_1}, \eta_{\varepsilon_2}, \ldots, \eta_{\varepsilon_v})}{\begin{bmatrix} h_{q_1}, h_{q_2}, \ldots, h_{q_v} \\ h_{q_{v+1}}, h_{q_{v+2}}, \ldots, h_{q_m} \end{bmatrix}} \times \frac{\begin{bmatrix} \eta_{\varepsilon_1}, \eta_{\varepsilon_2}, \ldots, \eta_{\varepsilon_v} \\ \eta_{\varepsilon_{v+1}}, \eta_{\varepsilon_{v+2}}, \ldots, \eta_{\varepsilon_m} \end{bmatrix}}, \]

where \( P \) represents any function symmetrical in respect of \( h_{q_1}, h_{q_2}, \ldots, h_{q_v} \), and also in respect of \( \eta_{\varepsilon_1}, \eta_{\varepsilon_2}, \ldots, \eta_{\varepsilon_v} \), (the interchanges, that is to say, between one \( h \) and another \( h \), or between one \( \eta \) and another \( \eta \), leaving \( P \) unaltered), it might be shown that the value of \( S_{v,v} \) resulting from the introduction of this more general value of \( R \) would (as for the particular value assumed) always be expressible as an integral function of the roots, and consequently, if \( P \) be taken of the same dimensions in the roots as the numerator of \( R \) previously assumed, i.e. \( v \), \( S_{v,v} \) would continue to be (unless indeed it vanish) identical (to some numerical factor près) with the corresponding simplified residue. If, on the other hand, \( P \) be taken of less than \( v \) dimensions in \( h \) and \( k \), we know à priori that \( S_{v,v} \) must vanish, as otherwise we should have a conjunctive of a weight less than the minimum weight. When \( P \) is of the proper amount of weight \( v \), it is I think probable that another condition as to the distribution of the weight will be found to be necessary in order that \( S_{v,v} \) may not vanish, viz. that the highest power of any single (\( h \)) in \( P \) shall not exceed \( v \), nor the highest power of any single \( \eta \) exceed \( v \). But as I have not had leisure to enter upon the inquiry, the verification or disproof of this supposed law, and more generally the evolution of the allotrious numerical factor introduced into \( S_{v,v} \) by assigning any particular form to (\( P \)) satisfying the necessary conditions of amount and distribution of weight, must be reserved, amongst other points connected with the theory of the remarkable forms (19.) art. (15.), as a subject for future investigation.

Art. (31.). A property of continued fractions, which, if known, I have not met with in any treatise on the subject (but which has been already cursorily alluded to in these pages), gives rise to a remarkable property of reciprocity connecting \( r \) and \( t \) severally with \( S \) in the syzygetic equation \( rf - tf + S = 0 \).

Let the successive convergents to the ordinary continued fraction

\[ \frac{1}{q_1 + \frac{1}{q_2 + \frac{1}{q_3 + \cdots \frac{1}{q_{i-1} + \frac{1}{q_i}}}}} \]

be called

\[ \frac{l_1}{m_1}, \frac{l_2}{m_2}, \ldots, \frac{l_{i-1}}{m_{i-1}}, \frac{l_i}{m_i} \]

respectively, it is well known that

\[ m_{i-1}l_i - m_il_{i-1} = (-)^{i-1}.1; \]
but I believe that it has not been observed that this is only the extreme cases of a much more general equation, viz.

\[ m_{i-p} l_i - m_i l_{i-p} = (-)^{i-p} \mu_{p-1}^*, \]

where \( \mu_1, \mu_2, \ldots, \mu_i \) denote respectively the denominators to the convergents to the continued fractions formed with the quotients taken in a reverse order, i.e. the continued fraction

\[ \frac{1}{q_i + \frac{1}{q_{i-1} + \frac{1}{q_{i-2} + \cdots + \frac{1}{q_2 + \frac{1}{q_1}}}}}. \]

This is easily proved when \( \varepsilon = 1 \); \( \mu_0 \) is of course (as usual) to be considered 1. So more simply for the improper continued fraction,

\[ \frac{l_i}{m_i} = \frac{1}{q_1 - \frac{1}{q_2 - \cdots q_{i-1} - \frac{1}{q_i}}}, \]

of which the convergents are supposed to be

\[ \frac{l_1}{m_1}, \frac{l_2}{m_2}, \ldots, \frac{l_{i-1}}{m_{i-1}}, \frac{l_i}{m_i}, \]

and the reverse fraction

\[ \frac{1}{q_i - \frac{1}{q_{i-1} - \cdots q_2 - \frac{1}{q_1}}}, \]

of which the convergents are supposed to be

\[ \lambda_1, \lambda_2, \ldots, \lambda_i, \]

we have the more simple equation

\[ l_i m_{i-p} - l_{i-p} m_i + \mu_{p-1} = 0. \]

And it is well known, or at all events easily demonstrable, that

\[ \frac{l_{i-1}}{l_i} = \frac{1}{q_i - \frac{1}{q_{i-1} - \frac{1}{q_{i-2} - \cdots \frac{1}{q_2}}}}, \]

\[ \frac{m_{i-1}}{m_i} = \frac{1}{q_i - \frac{1}{q_{i-1} - \frac{1}{q_{i-2} - \cdots \frac{1}{q_2}}}}. \]

Art. (32.). If now we use subscript indices to denote the degree in \( x \) of the quantities to which they are affixed, we have the general syzygetic equation

\[ K \tau_{m-i-1} f_m - K t_{m-i-1} \varphi_n + K S_i = 0, \]

where \( K \), a constant (which I have given the means of determining in the first section), being rightly assumed \( K \tau_{n-i-1}, K \tau_{m-i-1} \), become the numerator and denominator respectively of one of the convergents to \( \frac{\varphi}{f} \) expressed as an improper continued fraction, and \( K S_i \) becomes the denominator to one of the convergents to \( \frac{t^{m-1}}{f} \), or,

* See London and Edinburgh Philosophical Magazine, &quot;On a Fundamental Theorem in the Theory of Continued Fractions,&quot; October, 1853.
which is the same thing, to \( \frac{\tau_{n-1}}{\varphi} \). Conversely, it is obvious that if we adopt as our primitive functions \( qf(m) \) and \( t_{m-1} \), (c) being the value of \( K \) when \( i=0 \), we shall obtain as the general form of our syzygetic equation, bearing in mind that \((m-1)\) now replaces \((n)\),

\[
c.K&#x27;(\tau_{m-i})f_{m}-K&#x27;\varphi_{m-i-1}t_{m-i-1}+K&#x27;\tau_i=0;
\]

and similarly, if we adopt as our primitive functions \( \tau_{n-1} \) and \( c\varphi_n \), we obtain for our general syzygetic equation, observing that \((n-1)\) now replaces \((m)\),

\[
K&#x27;\varphi_{n-i-1}\tau_{m-i-1}-cK&#x27;\varphi_{n-i-1}\varphi_n+K&#x27;\tau_i=0;
\]

so that (making abstraction of the constant factors and looking merely to the forms of the several functions which enter into the equations) we see that on the first hypothesis, viz. of \( t_{m-1} \) being substituted for \( \varphi_a \), the conjunctives of each degree in \( x \) change places with the second conjunctive factors, i.e. the original multipliers of \( \varphi \) of the same degree in \( x \), and vice versa; and in the second hypothesis, where \( \tau_{n-1} \) takes the place of \( f_m \), the conjunctives of each degree in \( x \) change places with the first conjunctive factors, i.e. the original multipliers of \( f \) of the same degree in \( x \), and vice versa; \( t_{m-1} \) and \( \tau_{n-1} \) being respectively multipliers of \( \varphi \) and \( f \); such that the difference of the respective products is independent of \( x \). These results ought to be capable of being verified by aid of our general formulae for \( t, \tau, \varphi \), and as this verification will serve to exhibit in a clearer light the nature of the reciprocity between the conjunctives and the conjunctive factors, it may be not uninteresting to set it out.

Art. (33.). As usual, let \( h_1 h_2...h_m \) be the roots of \( f(x) \), and \( \eta_1 \eta_2...\eta_{m-1} \) the roots of \( \varphi(x) \), the last conjunctive factor to \( \varphi \), which is of the degree \((m-1)\) in \( x \), will be represented, neglecting powers of \((-)\), by \( t_{m-1} \), where

\[
t_{m-1}=\Sigma(x-h_1)(x-h_2)...(x-h_{m-1})
\]

If now we for greater simplicity make \( t_{n-1}=t(x) \), and call the roots of \( t, \eta&#x27;_1 \eta&#x27;_2...\eta&#x27;_{m-1} \) any such quantity as

\[
\begin{bmatrix}
h_{q_m} &amp; h_{q_2} &amp; ... &amp; h_{q_{m-1}} \\
\eta&#x27;_1 &amp; \eta&#x27;_2 &amp; ... &amp; \eta&#x27;_{m-1}
\end{bmatrix}
\]

\( =t(h_{q_m})=(h_{q_m}-h_{q_1})(h_{q_m}-h_{q_2})...(h_{q_m}-h_{q_{m-1}}) \times \frac{\varphi(h_{q_1})\varphi(h_{q_2})...\varphi(h_{q_{m-1}})}{(h_{q_m}-h_{q_1})(h_{q_m}-h_{q_2})...(h_{q_m}-h_{q_{m-1}})}
\]

\( =\varphi(h_{q_1})\varphi(h_{q_2})...\varphi(h_{q_{m-1}}) \)

\( =R_{\varphi(h_{q_m})} \),

* Since \( i \) is always supposed less than \( n \) (a being the degree of the lower degree of the two functions \( f \) and \( \varphi \)), the fact of the last quotient to \( \frac{t_{m-1}}{f} \) being wanting to \( \frac{\tau_{n-1}}{\varphi} \) will not affect the accuracy of the statement in the text above, since this latter will contain as many quotients as can in any case be required for expressing \( S_i \).
R denoting a constant independent of the root $h_{qm}$ selected (and which constant is in fact the resultant of the two functions $f&#x27;(x)$ and $\phi(x)$), that is to say,

$$\phi(h_1)\phi(h_2)\phi(h_3)\ldots\phi(h_m).$$

But by our general formulæ (8.) the simplified residue to $f(x)$ and $t(x)$ of the $i$th degree in $x$ will be represented by

$$S&#x27;_{i,0} = \Sigma(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_i}) \left\{ R^{m-i} \frac{\phi(h_{q_{i+1}})^{-1}\phi(h_{q_{i+2}})^{-1}\ldots\phi(h_{q_m})^{-1}}{\begin{bmatrix} h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_i} \\ h_{q_{i+1}} &amp; h_{q_{i+2}} &amp; \ldots &amp; h_{q_m} \end{bmatrix}} \right\};$$

$$\therefore S&#x27;_{i,0} = \Sigma(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_i}) \times \left\{ R^{m-i} \frac{\phi(h_{q_{i+1}})\phi(h_{q_{i+2}})\ldots\phi(h_{q_m})}{\begin{bmatrix} h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_i} \\ h_{q_{i+1}} &amp; h_{q_{i+2}} &amp; \ldots &amp; h_{q_m} \end{bmatrix}} \right\}$$

or $$S&#x27;_i = R^{m-i-1}t_i,$$

the relation which was to be obtained. So conversely, in precisely the same manner, calling $t&#x27;_i$ the conjunctive factor of the degree $i$ in $x$ to $t(x)$ in the syzygetic equation, which connects $f(x)$ and $t(x)$ with a corresponding simplified residue, we have

$$t&#x27;_i = \Sigma(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_i}) \left\{ R^{i-1} \frac{\phi(h_{q_{i+1}})\phi(h_{q_{i+2}})\ldots\phi(h_{q_m})}{\begin{bmatrix} h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_i} \\ h_{q_{i+1}} &amp; h_{q_{i+2}} &amp; \ldots &amp; h_{q_m} \end{bmatrix}} \right\}$$

$$= R^{i-1}.S_i,$$

the conjugate equation to the one previously obtained*.

And evidently the same reasoning serves to establish the reciprocity, or rather reciprocal convertibility, between the $\Phi$ series and the $\tau$ series, when in lieu of the original primitives $f(x)$ and $\phi(x)$ we take as our primitives $\tau(x)$ and $\phi(x)$, $\tau(x)$ being the function which satisfies the equation

$$\tau(x)f(x) - t(x)\phi(x) + R = 0.$$

Art. (34.). It may be remarked that if $n=m-1$ (the last syzygetic equation being

---

* M. Hermite, by a peculiar method, first discovered one of these two conjugate relations of reciprocity, applicable to the case of Sturm&#x27;s theorem, where $\phi x=f&#x27;x$, and I am indebted to him for bringing the subject under my notice.

MDCCCLIII.
thus \( t_{m-1} \cdot \varphi_{m-1} - \sigma_{m-2} \cdot f_m + S_0 = 0 \), when \( t_{m-1} \) and \( f_m \) are taken as the primitives, the corresponding equation will be of the form

\[
t&#x27;_{m-1} \cdot t_{m-1} - \sigma&#x27;_{m-2} \cdot f_m + S&#x27;_0 = 0;
\]

these two equations must therefore be identical, and consequently \( t&#x27;_{m-1} = \varphi_{m-1} \) (to a numerical factor près), so that \( t_{m-1} \) and \( \varphi_{m-1} \) are reciprocal forms; this is also obvious from the consideration that \( t&#x27;_{m-1} \) must, by the general law of reciprocity (established above), be a residue to \( (f_m, \varphi_{m-1}) \), which the latter function itself may be considered to be. Or the same thing is obvious directly, by writing

\[
t_{m-1} = t(x) = \Sigma (x-h_q)(x-h_q) \ldots (x-h_{q_{m-1}}) \cdot \frac{\varphi(h_q)\varphi(h_q) \ldots \varphi(h_{q_{m-1}})}{(h_{q_{m-1}}-h_q)(h_{q_{m-1}}-h_q) \ldots (h_{q_{m-1}}-h_{q_{m-1}})^2}
\]

and then making

\[
t&#x27;_{m-1} = \Sigma (x-h_q)(x-h_q) \ldots (x-h_{q_{m-1}}) \cdot \frac{t(h_q)t(h_q) \ldots t(h_{q_{m-1}})}{(h_{q_{m-1}}-h_q)(h_{q_{m-1}}-h_q) \ldots (h_{q_{m-1}}-h_{q_{m-1}})}
\]

\[
= \Sigma (x-h_q)(x-h_q) \ldots (x-h_{q_{m-1}}) \cdot (\varphi(h_q) \cdot \varphi(h_q) \ldots \varphi(h_{q_{m-1}}) \cdot h_{q_{m-1}})
\]

where

\[
\Delta = (-)^{m \cdot m-1} (h_1-h_2)^2 \cdot (h_1-h_3)^2 \ldots (h_1-h_m)^2 \times (h_2-h_3)^2 \ldots (h_2-h_m)^2 \ldots \ldots \ldots \times (h_{m-1}-h_m)^2
\]

\[
= (-1)^{m \cdot m-1} D \quad (D \text{ being the Discriminant, more commonly called the Determinant to } f);
\]

or finally,

\[
t&#x27;_{m-1} = \frac{R_{m-1}}{D} \varphi,
\]

as was to be shown.

**Section III.**

*On the application of the Theorems in the preceding Section to the expression in terms of the roots of any primitive function of Sturm&#x27;s auxiliary functions, and the other functions which connect these with the primitive function and its first differential derivative.*

Art. (35.). The formulæ in the preceding Section had reference to the case of two absolutely independent functions and their respective systems of roots: when the functions become so related that the roots of the one system become explicitly or implicitly functions of the roots of the other system, the formulæ will become expressible in terms of these latter alone, and in some cases the terms (of which the sum is always essentially integral) will become separately and individually representable under an integral form. Such, as I shall proceed to show, is the case for two functions, of which one is the differential derivative of the other. When \( f \) and \( \varphi \) are
thus related, so that $\varphi = \frac{df}{dx}$, calling as before $h_1, h_2, \ldots, h_m$ the roots of $f$, and $\eta_1, \eta_2, \ldots, \eta_{m-1}$ the roots of $\varphi$, we shall have in general

$$\begin{bmatrix} h_{q_i+1} \\ \eta_1, \eta_2, \ldots, \eta_{m-1} \end{bmatrix} = (h_{q_i+1} - \eta_1)(h_{q_i} - \eta_2) \ldots (h_{q_i+1} - \eta_{m-1})$$

$$= f&#x27;&#x27; h_{q_i+1} = \begin{bmatrix} h_{q_i+1} \\ h_q, h_{q_2}, \ldots, h_{q_i}, h_{q_i+2}, \ldots, h_{q_m} \end{bmatrix} = \begin{bmatrix} h_{q_i+1} \\ h_q, h_{q_2}, \ldots, h_{q_i} \end{bmatrix} \times \begin{bmatrix} h_{q_i+1} \\ h_{q_i+2}, h_{q_i+3}, \ldots, h_{q_m} \end{bmatrix}.$$ 

Consequently

$$\begin{bmatrix} h_{q_i+1} &amp; h_{q_i+2}, \ldots, h_{q_m} \\ \eta_1 &amp; \eta_2, \ldots, \eta_{m-1} \end{bmatrix} = \begin{bmatrix} h_{q_i+1} \\ \eta_1, \eta_2, \ldots, \eta_{m-1} \end{bmatrix} \times \begin{bmatrix} h_{q_i+2} \\ \eta_1, \eta_2, \ldots, \eta_{m-1} \end{bmatrix} \times \ldots \times \begin{bmatrix} h_{q_m} \\ \eta_1, \eta_2, \ldots, \eta_{m-1} \end{bmatrix}$$

$$= \begin{bmatrix} h_{q_i+1} \\ h_q, h_{q_2}, \ldots, h_{q_i} \end{bmatrix} \times \begin{bmatrix} h_{q_i+1} \\ h_{q_i+2}, h_{q_i+3}, \ldots, h_{q_m} \end{bmatrix} \times \ldots \times \begin{bmatrix} h_{q_m} \\ h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m-1} \end{bmatrix}.$$ 

Hence

$$\begin{bmatrix} h_{q_i+1} &amp; h_{q_i+2}, \ldots, h_{q_m} \\ \eta_1, \eta_2, \ldots, \eta_{m-1} \end{bmatrix} = \begin{bmatrix} h_{q_i+1} \\ h_q, h_{q_2}, \ldots, h_{q_i} \end{bmatrix} \times \begin{bmatrix} h_{q_i+2} \\ h_{q_i}, h_{q_i+1}, \ldots, h_{q_m} \end{bmatrix} \times \ldots \times \begin{bmatrix} h_{q_m} \\ h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m-1} \end{bmatrix}$$

$$= (-)^{\frac{i(i-1)}{2}} \zeta(h_{q_i+1}, h_{q_i+2}, \ldots, h_{q_m}),$$

the $\zeta$ denoting the operation of taking the product of the squares of the differences of the quantities which this symbol governs. Hence the Bezoutian secondary to $f$ and $f&#x27;$ of the $(m-i-1)$th degree in $x$, viz.

$$(-)^{\frac{i(i-1)}{2}} \sum (x-h_{q_i+1})(x-h_{q_i+2}) \ldots (x-h_{q_m}) \begin{bmatrix} h_{q_i}, h_{q_2}, \ldots, h_{q_i} \\ \eta_1, \eta_2, \ldots, \eta_{m-1} \end{bmatrix},$$

becomes

$$(-)^{\frac{i(i-1)}{2}} \zeta(h_{q_i}, h_{q_2}, \ldots, h_{q_i}) \sum (x-h_{q_i+1})(x-h_{q_i+2}) \ldots (x-h_{q_m})$$

$$= \zeta(h_{q_i}, h_{q_2}, \ldots, h_{q_i}) \sum (x-h_{q_i+1})(x-h_{q_i+2}) \ldots (x-h_{q_m}).$$
since \((-)^{(i-1)}=1\), which gives the well-known formulæ (enunciated by me in the London and Edinburgh Philosophical Magazine for 1839) for expressing M. Sturm&#x27;s auxiliary functions in terms of the roots of the primitive, and which I therein stated were immediately deducible from the general formulæ (also enunciated in the same paper) applicable to any two functions. These more general formulæ appear to have completely escaped the notice of M. Sturm and others, who have used the special formulæ applicable to the case of one function becoming the first differential derivative of the other.

Art. (36.). In precisely the same manner, if we form as usual the ordinary syzygetic equation

\[ t.f&#x27;x - xf + g = 0, \]

we may find the different values of \(t\) given by the complementary formulæ; and using \(t_i\) to denote the multiplier of the degree \(i\) in \(x\), i.e. appertaining to the residue of the degree \((m-i-1)\) in \(x\), we have

\[ t_i = \sum \left[ \begin{array}{ccc}
h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_i} \\
\eta_1 &amp; \eta_2 &amp; \ldots &amp; \eta_{m-1} \\
h_{q_1} &amp; h_{q_2} &amp; \ldots &amp; h_{q_i} \\
h_{q_{i+1}} &amp; h_{q_{i+2}} &amp; \ldots &amp; h_{q_m}
\end{array} \right] (x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_i}). \]

\[ = \zeta(h_{q_1}, h_{q_2}, \ldots, h_{q_i})(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_i}). \]

Art. (37.). Thus, if we make \(i=m-1\),

\[ f&#x27;_1(x) = t_{m-1} = \zeta(h_{q_1}, h_{q_2}, \ldots, h_{q_{m-1}})(x-h_{q_1})(x-h_{q_2})\ldots(x-h_{q_{m-1}}). \]

It is evident from the form of \(f&#x27;_1.x\) that it possesses relative to \(fx\), the same property as \(fx\), I mean the property that when \(x\) is indefinitely near to a real root of \(fx\), and is passing from the inferior to the superior side of such root, \(f&#x27;_1x\) like \(f&#x27;(x)\) will pass from being negative to being positive, or in other words, \(f&#x27;_1x\) and \(f&#x27;x\) have always the same sign in the immediate vicinity to a real root of \(fx\). Hence it follows that \(f&#x27;_1(x)\) might be used instead of \(f&#x27;x\), to produce, by the Sturmian process of common measure, a series of auxiliary functions, which with \(fx\) and \(f&#x27;_1.x\) would form a rhizoristic series, i.e. a series for determining (as in the manner of M. Sturm&#x27;s ordinary auxiliaries) the number of real roots of \(fx\) comprised within given limits. The rhizoristic series generated by this process will, it is easily seen, be (to a constant factor près) the denominators (reckoning \(+1\) as the denominator in the zero place) of the successive convergents to \(f&#x27;_1x/fx\) thrown under the form of a continued fraction

\[ \frac{1}{q_1} - \frac{1}{q_2} - \ldots - \frac{1}{q_{n-1}} - \frac{1}{q_n}; \]

M. Sturm&#x27;s own rhizoristic series, on the contrary (will be to a constant factor près), the denominators of the convergents to the inverse fraction \(f&#x27;_1x/fx\), which will be of the form \(K \cdot \frac{1}{q_n} - \frac{1}{q_{n-1}} - \ldots - \frac{1}{q_2} - \frac{1}{q_1}\); accordingly these two
rhizoristic series will be equivalent as regards the number of changes and of combinations of sign (afforded by each) corresponding to any given value of \( x \), of which of course the \( q \)&#x27;s are linear functions. This result agrees with what has been demonstrated by me by a more general method (in the London and Edinburgh Philosophical Magazine, June and July 1853), where it has been proved, by means of a very simple theorem of determinants, that the two series

\[
\frac{1}{q_1}; \quad \frac{1}{q_1 - q_2}; \quad \frac{1}{q_1 - q_2 - q_3}; \quad \ldots; \quad \frac{1}{q_1 - q_2 - \cdots - q_n}
\]

and

\[
\frac{1}{q_n}; \quad \frac{1}{q_n - q_{n-1}}; \quad \frac{1}{q_n - q_{n-1} - q_{n-2}}; \quad \ldots; \quad \frac{1}{q_n - q_{n-1} - \cdots - q_1}
\]

always contain (for real values of \( q_1, q_2, q_3, \ldots, q_n \)) the same number of positive and negative signs.

Art. (38.). Having now determined the general values of \( \Phi \) and \( t \) in the equation \( tf&#x27;&#x27;(x) - \tau f&#x27;x + \Phi = 0 \) as explicit integral functions of the roots of \( f&#x27;x \), the more difficult task remains to assign to \( \tau \) its value similarly expressed. This cannot readily be effected by means of substitutions in the general formulæ, the method we adopted for finding \( t \) and \( \Phi \); but all the other quantities except \( \tau \) in the syzygetic equation being integral functions of the roots, it is evident that \( \tau \) also must be an integral function of the same, and to obtain it we may use the expression \( \tau = \frac{tf&#x27;x - \Phi}{f&#x27;x} \).

To obtain the general form of \( \tau \) by direct calculation from this formula would however be found to be impracticable; the mode I adopt therefore to discover the general expression for \( \tau \) corresponding to different values of \( \Phi \), is to ascertain its value on the hypothesis of particular relations existing between the roots of \( f&#x27;x \), and then from the particular values of \( \tau \) thus obtained to infer demonstratively its general form, as will be seen below. The demonstration of \( \tau \) is unavoidably somewhat long, \( \tau \) being in fact represented by a double sum of partial symmetrical functions.

Using the subscript indices of each function as the syzygetic equation to denote its degree in \( x \), we have in general

\[
t_{m-i-1}f&#x27;x - \tau_{m-i-2}f&#x27;x + \Phi_i = 0,
\]

where if we make

\[
h_1 - x = k_1; \quad h_2 - x = k_2; \quad \ldots; \quad h_m - x = k_m,
\]

so that

\[
h_i - h_\omega = k_i - k_\omega,
\]

and therefore

\[
\zeta(h_\theta, h_\phi, \ldots, h_\rho) = \zeta(k_\theta, k_\phi, \ldots, k_\rho),
\]

we have in effect found

\[
\Phi_i = \Sigma(k_{q_1}, k_{q_2}, \ldots, k_{q_i}) \zeta(k_{q_{i+1}}, k_{q_{i+2}}, \ldots, k_{q_m})
\]

and

\[
t_{m-i-1} = \pm \Sigma(k_{q_1}, k_{q_2}, \ldots, k_{q_{m-i-1}}) \zeta(k_{q_i}, k_{q_2}, \ldots, k_{q_{m-i-1}});
\]

we have also \( f&#x27;&#x27;(x) = (-)^{m-1}. \Sigma k_1 k_2 \ldots k_{m-1} \).
Let us commence with the case where \( i = 0 \), we have then

\[
S_0 = \zeta(k_1, k_2, \ldots, k_m)
\]

\[
t_{m-1} = \Sigma(k_1, k_2, \ldots, k_{m-1}) \zeta(k_1, k_2, \ldots, k_{m-1}),
\]

we have thus

\[
(-)^m \tau_{m-2}(k_1, k_2, \ldots, k_m) = -\Sigma(k_1, k_2, \ldots, k_{m-1}) \times \Sigma(k_1, k_2, \ldots, k_{m-1}) + \zeta(k_1, k_2, \ldots, k_m).
\]

[It may easily be verified that the negative sign interposed between the two parts of the right-hand member of the equation has been correctly taken, for

\[
\zeta(k_1, k_2, \ldots, k_m) \text{ contains a term } k_1^{(m-1)} \cdot k_2^{(m-2)} \cdots k_{m-2} \cdot k_{m-1},
\]

\[
\Sigma(k_1, k_2, \ldots, k_{m-1}) \text{ contains a term } k_1 \cdot k_2 \cdots k_{m-2} \cdot k_{m-1},
\]

and

\[
\Sigma(k_1, k_2, \ldots, k_{m-1}) \zeta(k_1, k_2, \ldots, k_{m-1}) \text{ contains a term } k_1^{m-3} \cdot k_2^{m-5} \cdots k_{m-2} \cdot k_{m-1},
\]

and thus the term \( k_1^{(m-1)} \cdot k_2^{(m-2)} \cdots k_{m-2} \cdot k_{m-1} \), which does not contain \( k_1, k_2, \ldots, k_m \), will (as it ought to do) disappear from the right-hand side of the equation.]

Now suppose

\[
k_1 = k_2,
\]

then

\[
\zeta(k_1, k_2, \ldots, k_m) = 0,
\]

and also

\[
\zeta(k_1, k_2, \ldots, k_{m-1}) = 0,
\]

except when one or the other of the two disjunctive equations

\[
q_1, q_2, q_3, \ldots, q_{m-1} = 1, 3, 4, \ldots, m
\]

\[
q_1, q_2, q_3, \ldots, q_{m-1} = 2, 3, 4, \ldots, m
\]

is satisfied (by a disjunctive equation, meaning an equation which affirms the equality of one set of quantities with another set the same in number, each with each, but in some unassigned order).

Hence

\[
\Sigma(k_1, k_2, \ldots, k_{m-1}) \zeta(k_1, k_2, \ldots, k_{m-1})
\]

\[
= 2k_1 \cdot k_2 \cdots k_m \zeta(k_1, k_2, \ldots, k_m).
\]

Hence when

\[
k_1 = (-)^m k_2 \tau_{m-2} \text{ becomes } \frac{2}{k_1} \Sigma(k_1, k_2, \ldots, k_{m-1}) \zeta(k_1, k_2, \ldots, k_m),
\]

i.e.

\[
2\zeta(k_1, k_2, \ldots, k_m) \{k_1 \Sigma(k_1, k_2, \ldots, k_{m-1}) + 2k_3 \cdot k_4 \cdots k_m\},
\]

the \( \Sigma \) referring to \( r_3, r_4, \ldots, r_m \) supposed to be disjunctively equal to 3, 4, \ldots, m.

Now \( \tau_{m-2} \) is of \((m-2)\) dimensions in \( x \), and whenever more than one equality exists between the \( k \)&#x27;s, \( S_0 \) and \( t_{m-1} \) both vanish (in fact every term in each vanishes separately), and therefore \( \tau_{m-2} \), which \( = \frac{S_0 + t_{m-1}}{k_1 \cdot k_2 \cdots k_m} \), will vanish.

Hence \((-)^m \tau_{m-2} \) must be always of the form

\[
\Sigma \zeta(h_1, h_2, \ldots, h_{m-1}) \times \Psi(k_1, k_2, \ldots, k_{m-1}; k_m),
\]
Ψ denoting some integral function of \((m-2)\) dimensions in respect of the system of quantities \(k_1, k_2, \ldots, k_m\). The result above obtained enables us to assign the value of

\[
\Psi(k_1, k_2, \ldots, k_m)
\]

when \(k_1 = k_2\),

\[
\text{viz. } k_1 \Sigma(k_3, k_4, \ldots, k_{m-1}) + 2k_3, k_4, \ldots, k_m.
\]

Now for a moment suppose, selecting \((m-1)\) terms \(k_1, k_2, \ldots, k_m\) out of the \(m\) terms of the \(k\) series, that

\[
\Omega(k_1, k_2, \ldots, k_m) = k_1^{m-2} - k_2^{m-3}S_1(n_1, n_2, \ldots, n_m) + k_3^{m-4}S_2(n_1, n_2, \ldots, n_m)
\]

\[
\pm \&amp;c. \mp k_2 S_{m-3}(k_1, k_2, \ldots, k_m) \pm 2S_{m-2}(k_1, k_2, \ldots, k_m),
\]

where \(S_1\) means that the quantities which it governs are to be simply added together, \(S_2\) denotes that their binary, \(S_3\) that their ternary, and in general \(S_r\) that their \(r\)-ary products are to be added together.

When \(k_1 = k_2\), \(\Omega\) becomes

\[
k_1^{m-2} - k_1^{m-3}(k_1 + S_1(k_3, k_4, \ldots, k_m)) + k_1^{m-4}(k_1 S_1(k_3, k_4, \ldots, k_m) + S_2(k_3, k_4, \ldots, k_m))
\]

\[
- k_1^{m-5}(k_1 S_2(k_3, k_4, \ldots, k_m) + S_3(k_3, k_4, \ldots, k_m)) \pm \&amp;c. \mp k_1(k_1 S_{m-4}(k_3, k_4, \ldots, k_m) + S_{m-3}(k_3, k_4, \ldots, k_m))
\]

\[
\pm 2S_{m-2}(k_3, k_4, \ldots, k_m),
\]

which evidently equals

\[
\pm \{2S_{m-2}(k_3, k_4, \ldots, k_m) + k_1 S_{m-3}(k_3, k_4, \ldots, k_m)\},
\]

i.e. \(\pm \{k_1 \Sigma(k_3, k_4, \ldots, k_{m-1}) + 2k_3, k_4, \ldots, k_m\}\).

Hence when \(k_1 = k_2\), \(\Psi = \Omega\), and

\[
(-)^m r_{m-2} = \Sigma(h_1, h_2, \ldots, h_{m-1}) \times \Omega(k_1, k_2, \ldots, k_{m-1}, k_m);
\]

and so in like manner, when \(k_1\) is equal to any one of the \((m-1)\) quantities \(k_2, k_3, \ldots, k_m\), the form of \(r_{m-2}\) above written will have been correctly assumed. But \(r_{m-2}\) may be treated as a function of \((m-2)\) dimensions in \(k_1\), and consequently any form of \((m-2)\) dimensions in \(k_1\), which fits it for \((m-1)\) different values of \(k_1\), must be its general form, and accordingly we have universally,

\[
(-)^m r_{m-2} = \Sigma(h_1, h_2, \ldots, h_{m-1}) \times \{(x-h_{m-1})^{m-2} - (x-h_{m-1})^{m-3}S_1(x-h_1, x-h_2, \ldots, x-h_{m-1})
\]

\[
+ (x-h_{m-1})^{m-4}S_2(x-h_1, x-h_2, \ldots, x-h_{m-1}) \pm \&amp;c.
\]

\[
\mp (x-h_{m-1})S_{m-3}(x-h_1, x-h_2, \ldots, x-h_{m-1}) \pm 2S_{m-2}(x-h_1, x-h_2, \ldots, x-h_{m-1})\}.
\]

Art. (39.). With a view to better paving our way to the general form of \(r\) for all values of \(i\), let us pass over the case of \(i=1\) and go at once to the equation

\[
t_{m-3}f&#x27;x - r_{m-4}fx + \Omega_2 = 0;
\]

and to better fix our ideas let \(m=7\), so that the equation becomes

\[
t_4.f&#x27;x - r_3.fx + \Omega_2 = 0;
\]

we have then, preserving the same relation as before [i.e. using \(h\) to denote any root
of \( f(x) \), and \( k \) to denote \( h-x \)], the equation

\[
\pm k_1 k_2 k_3 k_4 k_5 k_6 k_7 \tau_3 = \Sigma (k_1, k_2, k_3, k_4, k_5, k_6, k_7)
\]

and \( \tau_3 \) will vanish whenever more than three relations of equality exist between the \( k \)&#x27;s, for then each term in both of the two sums in the right-hand member of the equation above written will separately vanish; and of course three relations of equality between the same are sufficient to make all the terms in the first of these sums vanish. This relationship between the different \( k \)&#x27;s corresponding to a multiplicity 3 may arise in different ways; the multiplicity 3 may be divided into 3 units corresponding to 3 pairs of equal roots, or into 2 and 1 corresponding one set of 3 equal roots, and a second set of 2 equal roots, or may be taken &quot;en bloc,&quot; which corresponds to the case of one set of 4 equal roots. I shall make the first of these suppositions, which will sufficiently well answer our purpose in the case before us.

Thus I shall suppose \( k_1 = k_4 \), \( k_2 = k_5 \), \( k_3 = k_6 \),

then, as above remarked, \( \zeta(k_1, k_2, k_3, k_4, k_5, k_6, k_7) = 0 \) for all values of \( q_1, q_2, q_3, q_4, q_5, q_6, q_7 \), and therefore

\[
\Sigma (k_1, k_2, k_3, k_4, k_5, k_6, k_7) = 0 ;
\]

also \( \Sigma (k_1, k_2, k_3, k_4, k_5, k_6) \) becomes

\[
k_1 k_2 k_3 (k_1 + k_2 + k_3 + 2k_4 + k_5 + k_6),
\]

and \( \zeta(n_1, n_2, n_3, n_4) \) vanishes, except for the cases where \( q_1, q_2, q_3, q_4 \) represent respectively, \( q_1 \) the index 1 or 4, \( q_2 \) the index 2 or 5, \( q_3 \) the index 3 or 6, and \( q_4 \) the index 7.

Hence

\[
\Sigma (k_1, k_2, k_3, k_4, k_5, k_6, k_7) = 2^3 k_1 k_2 k_3 k_4 k_5 k_6 k_7,
\]

and consequently \( \tau_3 \) becomes

\[
\pm 8 \zeta(k_1, k_2, k_3, k_4) \times \{k_1 k_2 k_3 + 2k_4 (k_1 k_2 + k_1 k_3 + k_2 k_3)\}.
\]

Hence we are able to predict that the general expression for our \( \tau \) in the case before us will be

\[
\tau_3 = \mp \Sigma (\zeta(k_1, k_2, k_3, k_4)) \times \left\{ \begin{array}{l}
(k_1^3 + k_2^3 + k_3^3) - (k_1^2 + k_2^2 + k_3^2)(k_1 + k_2 + k_3 + k_4) \\
+ (k_1 + k_2 + k_3)(k_1 k_2 + k_1 k_3 + k_2 k_3 + k_4 k_5 + k_6 k_7) \\
- 4(k_1 k_2 k_3 + k_1 k_2 k_4 + k_1 k_3 k_4 + k_2 k_3 k_4 + k_5 k_6 k_7)
\end{array} \right\}.
\]

For in the first place, the fact that the \( \tau \) vanishes when more than three relations of equality exist between the \( k \)&#x27;s, proves that we may assume \( \tau_3 \) of the form

\[
\Sigma (\zeta(k_1, k_2, k_3, k_4)) \times \varphi(k_1, k_2, k_3, k_4; k_5, k_6, k_7),
\]

the semicolon (;) separating the \( k \)&#x27;s into two groups, in respect of each of which severally \( \varphi \) is a symmetrical form. But if in the expression last above written for \( \tau_3 \) we make \( k_1 = k_4 \), \( k_2 = k_5 \), \( k_3 = k_6 \),

it becomes

\[
\mp 8 \zeta(k_1, k_2, k_3, k_4) \times \left\{ \begin{array}{l}
(k_1^3 + k_2^3 + k_3^3) - (k_1^2 + k_2^2 + k_3^2)(k_1 + k_2 + k_3 + k_4) \\
+ (k_1 + k_2 + k_3)(k_1 k_2 + k_1 k_3 + k_2 k_3 + k_4 k_5 + k_6 k_7) \\
- 4(k_1 k_2 k_3 + k_1 k_2 k_4 + k_1 k_3 k_4 + k_2 k_3 k_4 + k_5 k_6 k_7)
\end{array} \right\}.
\]
Now in general if

\[ \sigma_r = a_1^r + a_2^r + a_3^r + \ldots + a_t^r, \]

and

\[ S_r = \Sigma_i (a_1, a_2, a_3, \ldots, a_r), \]

\[ \sigma_r - \sigma_{r-1}S_1 + \sigma_{r-2}S_2 \pm \ldots \pm rS_r = 0. \]

Consequently the sum of the terms constituting the second factor in the above expression

\[ = (3 - 4)k_1k_2k_3 + (2 - 4)k_7(k_1k_2 + k_1k_3 + k_2k_3). \]

Hence the above expression becomes

\[ \pm 8\zeta(k_1k_2k_3k_7)\{k_1k_2k_3 + 2(k_1k_2 + k_1k_3 + k_2k_3)k_7\}. \]

Thus, then, whenever \( k_1k_2k_3 \) are respectively equal to any three of the quantities \( k_4k_5k_6k_7 \), which may take place in twenty-four different ways (twenty-four being the number of permutations of four things), our \( \tau_3 \) will have been correctly assumed; but \( \zeta(k_1k_2k_3k_7) \) being replaceable by \( \zeta(h_1h_2h_3h_4) \), the \( \tau_3 \) may be treated as a cubic function in \( k_1, k_2, k_3 \), and arranged according to the powers of \( k_1k_2k_3 \) will contain only twenty terms; hence, since the assumed form is verified for more than twenty, i.e., for twenty-four values of \( h_1, h_2, h_3 \), it follows that the assumed form is universally identical with the form of \( \tau_3 \), which was to be determined.

Art. (40.). Now, again, in order to facilitate the conception of the general proof, let us suppose \( f(x) \) to be of only five dimensions in \( x \), \( i \) still remaining 3: it will no longer be possible when we suppose a multiplicity three to prevail among the roots, to conceive this multiplicity to be distributed into three parts, for that would require the existence of three pairs of roots, there being only five. But we may, if we please, make \( h_1 = h_2 = h_3 \), and \( h_4 = h_5 \), or else \( h_1 = h_2 = h_3 = h_4 \), or in any other mode conceive the multiplicity to be divided into two parts, 2 and 1 respectively, or to be taken collectively &quot;en bloc.&quot; As a mode of proceeding the more remote from that last employed, I shall choose the latter supposition. Then we obtain (\( \tau \) now becoming \( \tau_{5-2-2} \), i.e., \( \tau_1 \))

\[ k_1k_2k_3k_4k_5\tau_1 = \pm \Sigma k_{q_1}k_{q_2}k_{q_3}k_{q_4} \times \{\Sigma k_{q_1}k_{q_2}\zeta(k_{q_1}k_{q_2})\}, \]

and \( \zeta(k_{q_1}k_{q_2}) \) will vanish, except in the case where \( q_1 \) represent the indices 1 or 2 or 3 or 4, and \( q_2 \) the index 5; also

\[ \Sigma k_{q_1}k_{q_2}k_{q_3}k_{q_4} = k_{q_1} + 4k_{q_2}k_{q_3}. \]

Hence our equation becomes

\[ k_1k_2k_3\tau = \pm (k_1 + 4k_2k_3)4k_1k_2\zeta(k_1k_2), \]

and \( \tau \) becomes

\[ -4\zeta(k_1k_2)(k_1 + 4k_2). \]

If, now, we assume for the general value of \( \tau \) in the case before us

\[ \tau = \Sigma \zeta(k_{q_1}k_{q_2})\{k_{q_3} + k_{q_4} + k_{q_5} - 4(k_{q_1} + k_{q_2})\}, \]

when \( k_1 = k_2 = k_3 = k_4 \), \( \tau \) becomes

\[ \pm 4\zeta(k_1k_2)(3k_1 - (4k_1 + k_5)), \]

i.e., \( \pm 4\zeta(k_1k_2)(k_1 + 4k_5). \)

MDCCCLIII.
Hence then for the two systems of values of \( h_1, h_2, h_3 \), viz.

\[
\begin{align*}
h_1 &amp;= h_4 &amp; h_1 &amp;= h_5 \\
h_2 &amp;= h_4 &amp; h_2 &amp;= h_5 \\
h_3 &amp;= h_4 &amp; h_3 &amp;= h_5,
\end{align*}
\]

the form of \( \tau \) will have been correctly assumed. But since the derived form is a linear function of \( h_1, h_2, h_3 \), this is not enough to identify the assumed with the general form, since for such verification four systems of values must be taken, four being the number of terms in a function of three variables of the first degree. If, however, we had adopted a separation of the multiplicity three into two parts, and had started with supposing \( k_1 = k_2 = k_3, k_4 = k_5 \), we should have found that \( \tau \) would have become

\[ = 6 \zeta(k_1, k_5)(2k_1 + 3k_5). \]

Moreover, when these equalities subsist,

\[ k_1 k_2 k_3 k_4 + k_1 k_2 k_3 k_5 + k_1 k_2 k_4 k_5 + k_1 k_3 k_4 k_5 + k_2 k_3 k_4 k_5 \]

becomes \( 2k_1^3 k_5 + 3k_1^2 k_5^2 \), and the common factor \( k_1^2 k_5 \) disappears in the course of the operations for finding \( \tau \), and eventually we have to show (in order to support the universality of the previously assumed form for \( \tau \)) that

\[ n_{q_1} + n_{q_2} + n_{q_3} - 4(n_{q_1} + n_{q_3}) \]

becomes \(-2n_{q_1} - 3n_{q_5}\) when

\[ n_{q_2} = n_{q_3} = n_{q_4} = n_1 \]

and

\[ n_{q_4} = n_{q_5} = n_5, \]

which is evidently true. Hence then \( \tau \) will have been correctly assumed for the following cases,

\[ k_1 = k_3 = k_5 = k_2 \]
\[ k_1 = k_2 = k_5 = k_4; \]

and also for the cases

\[ k_1 = k_2 = k_3 \text{ and } k_5 = k_4 \]
\[ k_1 = k_5 = k_3 \text{ and } k_2 = k_4 \]
\[ k_2 = k_5 = k_3 \text{ and } k_1 = k_4 \]
\[ k_1 = k_3 = k_4 \text{ and } k_5 = k_3 \]
\[ k_1 = k_5 = k_4 \text{ and } k_2 = k_3 \]
\[ k_2 = k_5 = k_4 \text{ and } k_1 = k_3 \]

i.e. for eight cases in all, whereas four only would have sufficed. Hence, &quot;ex abundanti demonstrationis,&quot; the form assumed for \( \tau_1 \) is in the case before us the general form.

Art. (41.). We may now easily write down the general form which \( \tau \) assumes for all values of \( i \) and prove its correctness. If the roots be \( h_1, h_2, h_3, \ldots, h_m \), and

\[ t_{m-i-1} f&#x27;x - r_{m-i-2} f&#x27;x + S_i = 0, \]
we shall have

\[ \pm t_{m-i-1} = \sum \left[ \zeta(h_1, h_2, h_3, \ldots, h_{m-i-1}) \times \left( \sigma_{m-i-2} - \sigma_{m-i-3} S_1 + \sigma_{m-i-4} S_2 + \text{etc.} \right) \right] \]

where \( \sigma_r \) denotes in general the sum of the \( r \)th powers of the \((i+1)\) quantities

\[(x-h_{m-i}), (x-h_{m-i+1}), \ldots (x-h_m),\]

and \( S_r \) denotes in general the sum of the products of the complementary \((m-i-1)\) quantities

\[(x-h_1), (x-h_2) \ldots (x-h_{m-i-1})\]

combined, \( r \) and \( r \) together. It will of course also be understood that \( \sigma_0 = i+1 \), so that \( \sigma_0 + 1 = i+2 \).

Art. (42.). To prove the correctness of this general determination of the form of \( \sigma_{m-i-1} \), let us suppose in general that \( i+1 \) relations of equality spring up between the \((m)\) quantities \( k_1, k_2, \ldots, k_m \), we shall then easily obtain (N representing a certain numerical multiplier)

\[ \pm Q = N \cdot \zeta(k_1, k_2, \ldots, k_{m-i-1}) \frac{\Sigma k_{q_1}, k_{q_2}, \ldots, k_{q_{m-i-1}}}{k_1^{\mu_1}, k_2^{\mu_2}, \ldots, k_{m-i-1}^{\mu_{m-i-1}}}, \]

\( k_1, k_2, \ldots, k_{m-i-1} \) being what the \((k)\) system becomes when repetitions are excluded, and being respectively supposed to occur \( \mu_1, \mu_2, \ldots, \mu_{m-i-1} \) times respectively, so that

\[ \mu_1 + \mu_2 + \ldots + \mu_{m-i-1} = m; \]

the fractional part of the right-hand member of the equation immediately above written will be readily seen to be equivalent to

\[ \Sigma \mu_{m-i-1}(k_{q_1}, k_{q_2}, \ldots, k_{q_{m-i-1}}). \]

To establish the correctness of the assumed form, we must be able, as in the particular cases previously selected, to prove two things; the one, and the more difficult thing to be proved is, that when the series of distinct quantities \( k_1, k_2, k_3, \ldots, k_m \) become converted into \( \mu_1 \) groups of \( k_1 \); \( \mu_2 \) groups of \( k_2 \ldots \mu_{m-i-1} \) groups of \( k_{m-i-1} \), then that

\[ \Sigma \mu_{m-i-1}(k_{q_1}, k_{q_2}, \ldots, k_{q_{m-i-1}}), \]

or in other terms,

\[ \Sigma \pm k_{q_1}, k_{q_2}, \ldots, k_{q_{m-i-1}} \Sigma_{m-i-1}(\mu_0), \]

becomes identical with

\[ \sigma_{m-i-2} - \sigma_{m-i-3} S_1 \pm \text{etc.} + (\sigma_0 + 1) S_{m-i-2}. \]

The other step to be made, and with which I shall commence, consists in showing that the number of terms in the expression last above written, considered as a function of \((m-i-2)\)th degree of \((i+1)\) variables, is never greater than the entire number of ways in which \((2+1)\) quantities out of \( m \) quantities may be equated to the remaining \((m-i-1)\) quantities, viz. each of the first set respectively to all the same, or all different, or some the same and some different; in short, in any manner each of the \( i+1 \) quantities with some one or another (without restriction against repetitions) of the \( m-i-1 \) remaining quantities. This latter number being in fact the number of ways in which \((m-i-1)\) quantities may be combined \((i+1)\) together with repetitions
admissible by a well-known arithmetical theorem is \((m-i-1)^{i+1}\), and the first number is \(\frac{(i+1)(i+2)\ldots(m-2)}{1\cdot2\ldots(m-i-2)}\), which is always less than the other. It remains then only to prove the remaining step of the demonstration*.

Art. (43.). To fix the ideas let \(m=10\), \(i=5\), and consider the expression

\[
(k_5^3 + k_6^3 + k_7^3 + k_8^3 + k_9^3 + k_{10}^3) - (k_5^2 + k_6^2 + k_7^2 + k_8^2 + k_9^2 + k_{10}^2)(k_1 + k_2 + k_3 + k_4)
\]

\[
+ (k_5 + k_6 + k_7 + k_8 + k_9 + k_{10})(k_1 \cdot k_2 + k_1 \cdot k_3 + k_1 \cdot k_4 + k_2 \cdot k_3 + k_2 \cdot k_4 + k_3 \cdot k_4)
\]

\[
- 7(k_1 \cdot k_2 \cdot k_3 + k_1 \cdot k_2 \cdot k_4 + k_1 \cdot k_3 \cdot k_4 + k_2 \cdot k_3 \cdot k_4).
\]

Now suppose the six quantities \(k_5, k_6, k_7, k_8, k_9, k_{10}\) to become respectively equal each to some one or another of the four quantities \(k_1, k_2, k_3, k_4\), as for instance, I shall suppose

\[
k_5 = k_6 = k_7 = k_1
\]

\[
k_8 = k_9 = k_2
\]

\[
k_{10} = k_3.
\]

Then

\[
\mu_1 = 4, \quad \mu_2 = 3, \quad \mu_3 = 2, \quad \mu_4 = 1,
\]

and the formula of art. (41) becomes

\[
(3k_1^3 + 2k_2^3 + k_3^3) - (3k_1^2 + 2k_2^2 + k_3^2)(k_1 + k_2 + k_3 + k_4)
\]

\[
+ (3k_1 + 2k_2 + k_3)(k_1 \cdot k_2 + k_1 \cdot k_3 + k_1 \cdot k_4 + k_2 \cdot k_3 + k_2 \cdot k_4 + k_3 \cdot k_4)
\]

\[
- 7(k_1 \cdot k_2 \cdot k_3 + k_1 \cdot k_2 \cdot k_4 + k_1 \cdot k_3 \cdot k_4 + k_2 \cdot k_3 \cdot k_4)
\]

\[
= 3\{k_1^3 - k_1^2(k_2 + k_3 + k_4 + k_1) + k_1(k_2 k_3 + k_2 k_4 + k_3 k_4 + k_2 k_3 + k_2 k_4 + k_3 k_4)
\]

\[
+ 2(k_2^3 - k_2^2(k_1 + k_3 + k_4 + k_2) + k_2(k_1 k_3 + k_1 k_4 + k_2 k_3 + k_2 k_4 + k_3 k_4)
\]

\[
+ (k_3^3 - k_3^2(k_1 + k_2 + k_4 + k_3) + k_3(k_1 k_2 + k_1 k_4 + k_2 k_3 + k_2 k_4 + k_3 k_4)
\]

\[
- \{k_1 k_2 k_3 + k_1 k_2 k_4 + k_1 k_3 k_4 + k_2 k_3 k_4\}
\]

\[
= -k_1 k_2 k_3 k_4 \left\{\frac{\mu_1}{k_1} + \frac{\mu_2}{k_2} + \frac{\mu_3}{k_3} + \frac{\mu_4}{k_4}\right\}.
\]

In the above investigation the quantities which with their repetitions make up the \(k\)’s system, are \(k_4, k_1, k_2, k_3\), appearing respectively 1, 2, 3, 4 times, that is to say repeated 0, 1, 2, 3 times; 7 is 1 more than the sum of the repetitions 0+1+2+3, and the numbers 1, 2, 3, 4 arise from subtracting from 7 the sums 1+2+3; 0+2+3; 0+1+3; 0+1+2; respectively, so that the remainders 1, 2, 3, 4 denote respectively one more than the number of repetitions of \(k_4, k_1, k_2, k_3\), i.e. are the number of appear-

* If this first step of the demonstration appear unsatisfactory or subject to doubt, it may be dispensed with, and the result obtained in the succeeding article (the demonstration of which is wholly unexceptionable) being assumed, it may be proved that the formula there obtained on a particular hypothesis must be universally true, in precisely the same way and by aid of the same Lemma in and by aid of which the formula obtained in the Supplement to this section for the simplified quotients to \(f(x)\) upon a like particular hypothesis is shown to be of universal application, i.e. by showing that otherwise a function of \(2i-1\) variables would contain a function of \(2i\) variables as a factor.
ances of $k_4, k_1, k_2, k_3$; and thus with a slight degree of attention to the preceding process the reader may easily satisfy himself that the preceding demonstration (although not so expressed) is in essence universal, and the form of $\tau$ as an explicit function of $x$ and of the roots of $f(x)$ is thus completely established for all values of $m$ and of $i$.

**Supplement to Section III.**

*On the Quotients resulting from the process of continuous division ordinarily applied to two Algebraical Functions in order to determine their greatest Common Measure.*

[Received October 20, 1853.]

Art. (a.)* We have now succeeded in exhibiting the forms of the numerators and denominators of $\frac{f&#x27;x}{fx}$ developed into a continued fraction in terms of the differences of the roots and factors of $fx$. It remains to exhibit the quotients themselves of this continued fraction under a similar form.

Lemma.—An equation being supposed of an arbitrary degree $n$, there exists no function of $n$ and of less than $2i$ of the coefficients†, which vanishes for all values of $n$ whenever the $n$ roots reduce in any manner to $i$ distinct groups of equal roots; or in other words, any function of $n$ and the first $2i-1$ coefficients of an equation of the $n$th degree, which vanishes for all values of $n$ in every case where the roots retain only $i$ distinct names, must be identically zero.

To render the statement of the proof more simple, let $i$ be taken equal to 3. And let the roots be supposed to reduce to $p$ roots $a$, $q$ roots $b$, and $r$ roots $c$. And let $s_r$ in general denote the sum of the $r$th powers of the roots. Then we have evidently

$$\begin{align*}
p + q + r &amp;= s_0 \\
pa + qb + rc &amp;= s_1 \\
pa^2 + qb^2 + rc^2 &amp;= s_2 \\
pa^3 + qb^3 + rc^3 &amp;= s_3 \\
pa^4 + qb^4 + rc^4 &amp;= s_4 \\
&amp;\text{&amp;c. &amp;c., ad infinitum.}
\end{align*}$$

Eliminating $p$, $q$, $r$ between the first, second, third and fourth equations, we obtain

$$\begin{vmatrix}
1 &amp; 1 &amp; 1 &amp; s_0 \\
a &amp; b &amp; c &amp; s_1 \\
a^2 &amp; b^2 &amp; c^2 &amp; s_2 \\
a^3 &amp; b^3 &amp; c^3 &amp; s_3
\end{vmatrix} = 0.$$  

* The articles in this and subsequent sections to which Latin or Greek letters are prefixed, although in strict connexion with the context, are supplementary in the sense of having been supplied since the date when the paper was presented for reading to the Royal Society. All the articles marked with numbers (from 1 to 72), and the Introduction, appeared in the memoir as originally presented to the Society, June 16, 1853.

† In the proposition thus enunciated the coefficient of the highest power of $x$ is supposed to be a numerical quantity.
In like manner eliminating \( ap \), \( bq \), \( cr \) between the second, third, fourth and fifth equations, we have

\[
\begin{vmatrix}
1 &amp; 1 &amp; 1 &amp; s_1 \\
a &amp; b &amp; c &amp; s_2 \\
a^2 &amp; b^2 &amp; c^2 &amp; s_3 \\
a^3 &amp; b^3 &amp; c^3 &amp; s_4
\end{vmatrix} = 0;
\]

and so in general we have for all values of \( e \),

\[
\begin{vmatrix}
1 &amp; 1 &amp; 1 &amp; s_e \\
a &amp; b &amp; c &amp; s_{e+1} \\
a^2 &amp; b^2 &amp; c^2 &amp; s_{e+2} \\
a^3 &amp; b^3 &amp; c^3 &amp; s_{e+3}
\end{vmatrix} = 0;
\]

whence it may immediately be deduced, that, upon the given supposition of there being only three groups of distinct roots, we must have the following infinite system of coexisting equations satisfied, viz.—

\[
s_0 t + s_1 u + s_2 v + s_3 w = 0 \quad \text{say } L_0 = 0 \\
s_1 t + s_2 u + s_3 v + s_4 w = 0 \quad L_1 = 0 \\
s_2 t + s_3 u + s_4 v + s_5 w = 0 \quad L_2 = 0 \\
s_3 t + s_4 u + s_5 v + s_6 w = 0 \quad L_3 = 0 \\
s_4 t + s_5 u + s_6 v + s_7 w = 0, \quad L_4 = 0,
\]

&amp;c. &amp;c. &amp;c. &amp;c.,

and conversely, when this infinite system of equations is satisfied the roots must reduce themselves to three groups of equal roots.

Let now \( \phi \) be any function of \( s_0 \), \( s_1 \), \( s_2 \), ..., \( s_n \), which vanishes when this is the case. Then \( \phi \) must necessarily contain as a factor some derivee of the infinite system of equations above written, i.e. some function of \( s_0 \), \( s_1 \), \( s_2 \), &amp;c., which vanishes when these equations are satisfied; i.e. some conjunctive of the quantities \( L_0 \), \( L_1 \), \( L_2 \), \( L_3 \); but it is obviously impossible in any such conjunctive to exclude \( s_6 \) from appearing, unless by introducing some other \( s \) with an index higher than \( s \), and consequently \( \phi \) cannot be merely a function of \( s_0 \), \( s_1 \), \( s_2 \), \( s_3 \), \( s_4 \), \( s_5 \), nor consequently of \( n \), and the first five coefficients; or if such, it is identically zero, and so in general any function of \( n \), and only \( 2i - 1 \) of the coefficients, which vanishes when the roots reduce to \( i \) groups of equal roots, must be identically zero, as was to be proved.

Art. (b.) It ought to be observed that the preceding reasoning depends essentially upon the circumstance of \( n \) being left arbitrary. If \( n \) were given the proposition would no longer be true. In fact, on that supposition, the \( n \) roots reducing to \( i \) distinct roots would imply the existence of \( n - i \) conditions between the \( n \) roots; and consequently \( n - i \) independent equations would subsist between the \( n \) coefficients, and functions could be formed of \( i \) only of the coefficients, which would satisfy the prescribed condition of vanishing when the roots resolved themselves into \( i \) groups of distinct identities.
Art. (c.) Let $D_{r_1, r_2, \ldots, r_i}$ be used in general to denote the determinant

$$\begin{array}{cccc}
s_{r_1} &amp; s_{r_1+1} &amp; \cdots &amp; s_{r_1+i-1} \\
s_{r_2} &amp; s_{r_2+1} &amp; \cdots &amp; s_{r_2+i-1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
s_{r_i} &amp; s_{r_i+1} &amp; \cdots &amp; s_{r_i+i-1},
\end{array}$$

then the simplified $i$th Sturmian residue $R_i$ may be expressed under the form

$$D_{1, 2, \ldots, i} x^{n-i-1} - D_{2, 3, \ldots, i+1} x^{n-i-2} + D_{3, 4, \ldots, (i+2)} x^{n-i-3} \cdots \pm D_{n-i, n-i-1, \ldots, n},$$

which is easily identifiable with the known expression for such residue.

Now obviously the necessary and sufficient conditions in order that the $n$ roots may consist of only repetitions of $i$ distinct roots is, that $R_i$ shall be identically zero, that is to say, we must have

$$D_{1, 2, \ldots, i} = 0 \quad D_{2, 3, \ldots, i+1} = 0 \quad \ldots \quad D_{n-i, n-i-1, \ldots, n} = 0.$$

But the reasoning of the preceding article shows that although these equations are necessary and sufficient, they are but a selected system of equations of an infinite number of similar equations which subsist*, and that, in fact, whatever be the value of $(n)$, we may take $r_1, r_2, \ldots, r_i$ perfectly arbitrary and as great as we please, and the equation

$$D_{r_1, r_2, \ldots, r_i} = 0$$

must exist by virtue of the existence of the $n-i$ equations last above written.

Art. (d.) I now return to the question of expressing the successive quotients of $\frac{f&#x27;}{f}$ as functions of the differences of the roots and factors; that they must be capable of being so expressed is an obvious consequence of the fact, that the numerators and denominators of the convergents have been put under that form, since if

$$\frac{N_{i-2}}{D_{i-2}}, \frac{N_{i-1}}{D_{i-1}}, \frac{N_i}{D_i}$$

are any three consecutive convergents of the continued fraction

$$\frac{1}{Q_1} - \frac{1}{Q_2} - \cdots - \frac{1}{Q_i},$$

we must have

$$D_{i-2} \cdot N_i - N_{i-2} \cdot D_i = Q_i.$$

It would not, however, be easy to perform the multiplications indicated in the above equation, so as to obtain $Q_i$ under its reduced form as a linear function of $x$. I proceed therefore to find $Q_i$ constructively in the following manner.

Let $R_{i-2}, R_{i-1}, R_i$ be three consecutive residues, $f&#x27;/x$ counting as the residue in the zero place, then $Q_i = \frac{R_{i-2} - R_i}{R_{i-1}}$ and is of the form $\frac{p}{q}x + \frac{p&#x27;}{q&#x27;}$.

* But quere whether any other sufficient system can be found of equations so few in number as this system.
Now in general if we call the \( n \) roots of \( fx \), where the coefficient of \( x^n \) is supposed to be unity, \( h_1, h_2, \ldots, h_n \), and if we use \( Z_i \) to denote \( \Sigma \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_i}) \ast \), with the convention that \( Z_1 = n, Z_0 = 1 \), we have, employing (i) to denote \( \frac{1}{2}((-1)^i + 1) \),

\[
R_i = \frac{Z_{i-1}^2 \cdot Z_{i-3}^2 \cdots Z_{(i)}^2}{Z_{i-1}^2 \cdot Z_{i-2}^2 \cdots Z_{(i)+1}^2} \cdot \Sigma \{ \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_i})(x-h_{\theta_{i+1}})(x-h_{\theta_{i+2}}) \cdots (x-h_{\theta_n}) \}
\]

\[
R_{i-1} = \frac{Z_{i-2}^2 \cdot Z_{i-4}^2 \cdots Z_{(i)+1}^2}{Z_{i-2}^2 \cdot Z_{i-3}^2 \cdots Z_{(i)}^2} \cdot \Sigma \{ \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_i})(x-h_{\theta_{i+1}})(x-h_{\theta_{i+2}}) \cdots (x-h_{\theta_n}) \}
\]

\[
R_{i-2} = \frac{Z_{i-3}^2 \cdot Z_{i-5}^2 \cdots Z_{(i)}^2}{Z_{i-3}^2 \cdot Z_{i-4}^2 \cdots Z_{(i)+1}^2} \cdot \Sigma \{ \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_i})(x-h_{\theta_{i+1}})(x-h_{\theta_{i+2}}) \cdots (x-h_{\theta_n}) \}.
\]

The part of \( R_{i-1} \) within the sign of summation is

\[
Z_i x^{n-i} - \Sigma(h_{\theta_{i+1}} + h_{\theta_{i+2}} + \cdots + h_{\theta_n}) \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_i}) x^{n-i-1} + &amp;c.,
\]

say

\[
Z_i x^{n-i} - Z_{i-1} x^{n-i-1} + &amp;c.,
\]

and the part of \( R_{i-2} \) within the sign of summation is

\[
Z_{i-1} x^{n-i-1} - Z_{i-1} x^{n-i} + &amp;c.,
\]

and

\[
Z_i \cdot \frac{Z_{i-1} x^{n-i+1} - Z_{i-1} x^{n-i}}{Z_i x^{n-2} - Z_i x^{n-i-1}} = Z_{i-1} Z_i x + (Z_{i-1} Z_i - Z_i Z_{i-1}) + \text{an algebraic fraction}.
\]

Hence

\[
Q_i = \frac{1}{Z_i} \cdot \frac{Z_{i-1}^2 \cdot Z_{i-3}^2 \cdots Z_{(i)}^2}{Z_{i-1}^2 \cdot Z_{i-2}^2 \cdots Z_{(i)+1}^2} \cdot \left[ \frac{Z_{i-2}^2 \cdot Z_{i-4}^2 \cdots Z_{(i)+1}^2}{Z_{i-2}^2 \cdot Z_{i-3}^2 \cdots Z_{(i)}^2} \right]^{-1}
\]

\[
\times \{ Z_{i-1} Z_i x + (Z_{i-1} Z_i - Z_i Z_{i-1}) \}
\]

\[
= \frac{Z_{i-1}^2 \cdot Z_{i-3}^2 \cdots Z_{(i)}^2}{Z_i^2 \cdot Z_{i-2}^2 \cdots Z_{(i)+1}^2} \cdot T_i
\]

\( T_i \) denoting \( Z_{i-1} Z_i x + (Z_{i-1} Z_i - Z_i Z_{i-1}) \).

Art. (e.) If the process of obtaining the successive quotients and residues be considered, it will easily be seen that each step in the process imports two new coefficients into the quotients, the first quotient containing no literal quotient in the part multiplying \( x \) and containing the first literal coefficient in the other part, the second quotient containing two literal coefficients in the one part and three in the other, and in general the \( i \)th quotient containing \( 2i-2 \) of the letters in the one part and \( 2i-1 \) of them in the other. Hence \( T_i \) being made equal to \( L_i x + M_i \), \( L_i \) contains \( 2i-2 \) and \( M_i \) contains \( 2i-1 \) of the literal coefficients of \( fx \).

Moreover, we have

\[
Z_i \text{ of the form } T_i^2 \cdot \frac{P_{i-2} - m P_i}{P_{i-1}},
\]

where

\[
P_{i-1} = \Sigma \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_i}) n_{\theta_{i+1}} n_{\theta_{i+2}} \cdots n_{\theta_n}
\]

\[
P_{i-2} = \Sigma \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_{i-1}}) n_{\theta_1} n_{\theta_{i+1}} \cdots n_{\theta_n},
\]

* \( \zeta \) it will be remembered is the symbol of the operation of taking the product of the squares of the differences of the quantities which it governs.
and \( P_i \), which is the \( i \)th simplified residue, vanishes when the \( n \) roots in any manner become reduced to only \( i \) distinct groups.

I proceed to show that if we make

\[
A_i x + B_i = U_i = A_{i,1}^2(x-h_1) + A_{i,2}^2(x-h_2) + \ldots + A_{i,n}^2(x-h_n),
\]

where in general

\[
A_{i,e} \text{ represents } \Sigma \zeta(h_{\theta_1}, h_{\theta_2}, \ldots, h_{\theta_{i-1}})(h_e - h_{\theta_1})(h_e - h_{\theta_2}) \ldots (h_e - h_{\theta_{i-1}}),
\]

then will

\[
T_i = U_i.
\]

It will be observed that \( A_{i,e} \) is identical with what the simplified denominator of the \((i-1)\)th convergent becomes when we write \( h_e \) in place of \( x \), and consequently, when arranged according to the powers of \( h_e \), will be of the form

\[
c_1 h_e^{i-1} + c_2 h_e^{i-2} + \ldots + c_i
\]

where \( c_1, c_2, \ldots, c_i \) are functions of the coefficients, but containing no more of them than enters into \( Q_{i-1} \), i.e., containing only \( 2i-2 \) of them.

Now \( A_i \) is made up of terms, each consisting of some binary product of

\[
c_1, c_2, \ldots, c_i
\]

combined with some term of the series

\[
\Sigma h^{2i-2}, \Sigma h^{2i-3} \ldots \Sigma h^0;
\]

and any one of this latter set of terms expressed as a function of the coefficients of \( f(x \) contains at most \( 2i-2 \) of them.

Hence only \( 2i-2 \) of the coefficients enter into \( A_i \), and in like manner only \( 2i-1 \) of them into \( B_i \).

The number of letters, therefore, in \( A_i \) and in \( B_i \) is the same as in \( L_i \) and in \( M_i \), viz. \( 2i-2 \) and \( 2i-1 \) respectively.

Now let the roots consist of only \( i \) distinct groups of equal roots, so that \( T_i \) becomes \( = Z_i^2 \frac{P_{i-2}}{P_{i-1}} \).

I shall show that in whatever way the equal roots are supposed to be grouped upon this supposition, there will result the equation

\[
T_i = U_i,
\]

where

\[
T_i = \left\{ \Sigma \zeta(\eta_{\theta_1}, \eta_{\theta_2}, \ldots, \eta_{\theta_i}) \right\}^2 \cdot \frac{P_{i-2}}{P_{i-1}}
\]

\[
P_{i-2} = \Sigma \{ \eta_{\theta_1}, \eta_{\theta_2}, \ldots, \eta_{\theta_i} \zeta(\eta_{\theta_1}, \eta_{\theta_2}, \ldots, \eta_{\theta_{i-1}}) \}
\]

\[
P_{i-1} = \Sigma \{ \eta_{\theta_1}, \eta_{\theta_2}, \ldots, \eta_{\theta_i} \zeta(\eta_{\theta_1}, \eta_{\theta_2}, \ldots, \eta_{\theta_{i-1}}) \},
\]

and

\[
H_i = A_{i,1}^2 \cdot \eta_1 + A_{i,2}^2 \cdot \eta_2 + \ldots + A_{i,n}^2 \cdot \eta_n,
\]

\( A_e \) meaning

\[
\Sigma \{ (\eta_e - \eta_{\theta_1})(\eta_e - \eta_{\theta_2}) \ldots (\eta_e - \eta_{\theta_{i-1}}) \zeta(\eta_{\theta_1}, \eta_{\theta_2}, \ldots, \eta_{\theta_{i-1}}) \},
\]

and \( \eta_{\omega} \) meaning \( x - h_{\omega} \).

MDCCCLIII.
Let the \( n \) factors be constituted of \( m_1 \) factors \( \eta_1 \), \( m_2 \) factors \( \eta_2 \ldots m_i \) factors \( \eta_i \). Then

\[ Z_i = \mu \zeta(\eta_1 \eta_2 \ldots \eta_i), \]

where

\[ \mu = m_1 \cdot m_2 \ldots m_i, \]

and

\[ P_{i-1} = \mu \zeta(\eta_1 \eta_2 \ldots \eta_i) \eta_1^{m_1-1} \eta_2^{m_2-1} \ldots \eta_i^{m_i-1}, \]

\[ P_{i-2} = \mu_1 \cdot \zeta(\eta_2 \eta_3 \ldots \eta_i) \eta_1^{m_1} \eta_2^{m_2-1} \ldots \eta_i^{m_i-1} + \mu_2 \cdot \zeta(\eta_1 \eta_3 \ldots \eta_i) \eta_1^{m_1-1} \eta_2^{m_2} \ldots \eta_i^{m_i-1} + \&amp;c. \&amp;c. \]

\[ + \mu_i \zeta(\eta_1 \eta_2 \ldots \eta_{i-1}) \eta_1^{m_1-1} \eta_2^{m_2-1} \ldots \eta_i^{m_i}, \]

where

\[ \mu_1 = \frac{\mu}{m_1}, \mu_2 = \frac{\mu}{m_2}, \ldots, \mu_i = \frac{\mu}{m_i}. \]

Hence

\[ T_i = \mu^2 \zeta(\eta_1 \eta_2 \ldots \eta_i) \left\{ \frac{\eta_1 \zeta(\eta_2 \eta_3 \ldots \eta_i)}{m_1} + \frac{\eta_2 \zeta(\eta_1 \eta_3 \ldots \eta_i)}{m_2} + \ldots + \frac{\eta_i \zeta(\eta_1 \eta_2 \ldots \eta_{i-1})}{m_i} \right\}. \]

Again, in \( U_i \) the term containing \( \eta_1 \) will be

\[ m_1 \eta_1 \Sigma \{ (\eta_1 - \eta_2)(\eta_1 - \eta_3) \ldots (\eta_1 - \eta_i) \zeta(\eta_2 \eta_3 \ldots \eta_i) \}^2 \]

\[ = m_1 \eta_1 \times (m_2, m_3 \ldots m_i)^2 \times (\eta_1 - \eta_2)^2 (\eta_1 - \eta_3)^2 \ldots (\eta_1 - \eta_i)^2 \zeta(\eta_2 \eta_3 \ldots \eta_i)^2 \]

\[ = \frac{\mu^2}{m_1} \eta_1 \zeta(\eta_1 \eta_2 \ldots \eta_i) \zeta(\eta_2 \eta_3 \ldots \eta_i). \]

Hence

\[ U_i = \mu^2 \zeta(\eta_1 \eta_2 \ldots \eta_i) \left\{ \frac{\eta_1 \zeta(\eta_2 \eta_3 \ldots \eta_i)}{m_1} + \frac{\eta_2 \zeta(\eta_1 \eta_3 \ldots \eta_i)}{m_2} + \&amp;c. \right\} = T_i. \]

Hence, therefore, \( U_i - T_i \) vanishes whenever the roots of \( f&#x27;x \) contain only \( i \) distinct groups of equal roots, and it has been shown that \( U_i \) and \( T_i \) each contain only \( 2i - 1 \) of the coefficients of \( f&#x27;x \), so that \( U_i - T_i \) is a function only of \( n \) and these \( 2i - 1 \) letters, and consequently by virtue of the Lemma in Art. (a.) \( U_i - T_i \) is universally zero, i.e. \( U_i \) is identical with \( T_i \), as was to be proved. In the same manner as observed in a preceding marginal note, the expression given in the antecedent articles for the numerator of the \( i \)th convergents having been verified for the case of the roots consisting of only \( i \) distinct groups, could have been at once inferred to be generally true by aid of the Lemma above quoted.

Art. (f.) Since the coefficient of \( x \) in \( T_i \) is \( Z_{i-1} \times Z_i \), we deduce the unexpected relation

\[ \Sigma \zeta(h_1 h_2 \ldots h_{i-1}) \times \Sigma \zeta(h_1 h_2 \ldots h_i) = P_1^2 + P_2^2 + \ldots + P_n^2, \]

where

\[ P_e = \Sigma \{ (h_e - h_{e_1})(h_e - h_{e_2}) \ldots (h_e - h_{e_{i-1}}) \zeta(h_{e_1} h_{e_2} \ldots h_{e_{i-1}}) \}. \]

So that every simplified Sturmian quotient to \( \frac{f&#x27;}{f_x} \), when the \( (n) \) roots of \( f&#x27;x \) are real, will be the sum of \( n \) squares. But the equation is otherwise remarkable, in exhibiting the product of the sum of \( \frac{n(n-1) \ldots (n-i+2)}{1 \cdot 2 \ldots (i-1)} \) squares by another sum of \( \frac{n(n-1) \ldots (n-i-1)}{1 \cdot 2 \ldots i} \) squares under the form of the sum of \( n \) squares.
If we call the \(i\)th simplified denominator to the Sturmian convergents to \(\frac{f&#x27;x}{fx}\), \(D_i(x)\), and if we call the \(i\)th simplified quotient \(X_i(x)\), we have

\[
X_ix = \Sigma_n (D_{i-1}h_e)^2(x-h_e).
\]

If we construct the numerators and denominators of the convergents to

\[
\frac{1}{Q_1 - \frac{1}{Q_2 - \frac{1}{Q_3 \cdots Q_i}}}
\]

according to the general rule for continued fractions as functions of \(Q_1, Q_2, Q_3, \&amp;c.\), so that calling the denominators \(\Delta_1, \Delta_2, \Delta_3, \&amp;c., \Delta_i\),

\[
\Delta_1 = Q, \quad \Delta_2 = Q_1Q_2 - 1, \ldots, \Delta_i = Q_i\Delta_{i-1} - \Delta_{i-2},
\]

we have

\[
\Delta_{i-1}x = \frac{Z_{i-1}^2Z_{i-4}^2 \cdots Z_{(i-1)}^2}{Z_i^2Z_{i-2}^2Z_{i-5}^2 \cdots Z_{(i)}^2}D_{i-1}(x),
\]

\(\Delta_{i-1}x\) being in fact the multiplier of \(f&#x27;x\) in the equation which connects \(fx\) and \(f&#x27;x\) with the \(i-1\)th complete residue, and consequently retaining \(Q(x)\) to designate the complete \(i\)th quotient, we have

\[
Q_i(x) = \frac{Z_{i-1}^2Z_{i-3}^2Z_{i-5}^2 \cdots Z_{(i)}^2}{Z_i^2Z_{i-2}^2Z_{i-4}^2 \cdots Z_{(i)+1}^2} \Sigma \{D_{i-1}, h_e\}^2(x-h_e)
\]

\[
= \frac{Z_{i-1}^2Z_{i-3}^2Z_{i-5}^2 \cdots Z_{(i)}^2}{Z_i^2Z_{i-2}^2Z_{i-4}^2 \cdots Z_{(i)+1}^2} \Sigma \{\Delta_{i+1}, h_e\}^2(x-h_e),
\]

which equation gives the connexion between the form of any quotient and that of the immediately preceding convergent denominator of the continued fraction which expresses \(\frac{f&#x27;x}{fx}\).

Art. (g.) I have found that the coefficients of the \(n\) factors of \(fx\) in the expression above given for the quotients possess the property that the sum of their square roots taken with the proper signs is zero for each quotient except the first (the coefficients for the first being all units), i.e. \(D_1h_1 + D_2h_2 + \ldots + D_nh_n = 0\) for all values of \(i\) except \(i = 1\). Moreover I find that the determinant formed by the \(n\) sets of the \(n\) coefficients of the factors of \(fx\) in the complete set of \(n\) quotients is identically zero, i.e. the Determinant represented by the square matrix

\[
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
(D_1, h_1)^2 &amp; (D_1, h_2)^2 &amp; (D_1, h_3)^2 &amp; \ldots (D_1, h_n)^2 \\
(D_2, h_1)^2 &amp; (D_2, h_2)^2 &amp; (D_2, h_3)^2 &amp; \ldots (D_2, h_n)^2 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
(D_{n-1}, h_1)^2 &amp; (D_{n-1}, h_2)^2 &amp; (D_{n-1}, h_3)^2 &amp; \ldots (D_{n-1}, h_n)^2 \\
\end{bmatrix} = 0.
\]

Art. (h.) It should be observed that \(U_i\) is the form of the simplified quotients for all the quotients except the \(n\)th (i.e. the last), for which the simplified form is not \(U_n\), but \(U_n = \zeta(h_1, h_2, \ldots, h_n)\), which arises from the circumstance of the last divisor, which is the final Sturmian residue, not containing \(x\); it being evidently the case that the division
of a rational function of \( x \) by another one degree lower, introduces into the integral part of the quotient the square of the leading coefficient of the divisor, subject to the exception that when the divisor is of the degree zero, the simple power enters in lieu of the square. The general formula gives for the reduced \( n \)th quotient the expression

\[
\Sigma((h_1-h_2)(h_1-h_3)\ldots(h_1-h_n)\zeta(h_2,h_3,\ldots,h_n)^2(x-h_1)),
\]

which equals

\[
\zeta(h_1,h_2,\ldots,h_n)\Sigma\zeta(h_2,h_3,\ldots,h_n)(x-h_1).
\]

Rejecting the first factor, we have

\[
\Sigma\zeta(h_2,h_3,\ldots,h_n)(x-h_1),
\]

which is equal to the penultimate residue, which residue is (as it evidently ought to be) identical with the simplified last quotient.

Art. (i.) We have thus succeeded in giving a perfect representation of \( \frac{f&#x27;_x}{f_x} \), i.e. of

\[
\frac{1}{x-h_1} + \frac{1}{x-h_2} + \cdots + \frac{1}{x-h_n},
\]

under the form of a continued fraction of the form

\[
\frac{1}{m_1(x-e_1)} - \frac{1}{m_2(x-e_2)} - \cdots - \frac{1}{m_n(x-e_n)},
\]

where \( m_1, m_2, \ldots, m_n; e_1, e_2, \ldots, e_n \) are all determinate and known functions of \( h_1, h_2, \ldots, h_n \).

We may by means of this identity, differentiating any number of times with respect to \( x \) both sides of the equation, obtain analogous expressions for the series

\[
\frac{1}{(x-h_1)^t} + \frac{1}{(x-h_2)^t} + \cdots + \frac{1}{(x-h_n)^t}.
\]

But to do this we must be in possession of a rule for the differentiation of continued fractions whose quotients are linear functions of the variable. I subjoin here the first step only toward such investigation.

Let the denominator of

\[
\frac{1}{q_1} - \frac{1}{q_2} - \cdots - \frac{1}{q_n}
\]

where \( q_1, q_2, \ldots, q_n \) are any \( n \) arbitrary quantities, be denoted by \([q_1, q_2, q_3, \ldots, q_n]\), so that the entire fraction will be equal to

\[
\frac{[q_2, q_3, \ldots, q_n]}{[q_1, q_2, q_3, \ldots, q_n]},
\]

any such quantity as \([q_i, q_{i+1}, \ldots, q_n]\) may be termed a Cumulant, of which \( q_i, q_{i+1}, \ldots, q_n \) may be severally termed the elements or Components, and the complete arrangement of the elements may be termed the Type. The cumulant corresponding to any Type remains unaffected by the order of the elements in the Type being reversed, as is evident from any cumulant being in fact representable under the form of a symmetrical determinant,
thus ex gr. the cumulant \([q_1 q_2 q_3 q_4]\) may be represented by the determinant

\[
\begin{array}{cccc}
q_1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; q_2 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; q_3 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; q_4 \\
\end{array}
\]

and \(q_4 q_3 q_2 q_1\) will in like manner be represented by the determinant

\[
\begin{array}{cccc}
q_4 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; q_3 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; q_2 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; q_1 \\
\end{array}
\]

which is equal to the former.

Art. (j.) Let it be proposed in general to find the first differential coefficient in respect to \(x\) of the fraction

\[
\frac{[q_i q_{i+1} \ldots q_n]}{[q_1 q_2 q_3 \ldots q_n]} = F_i,
\]

where each \(q\) is a function of one or more variables.

I find that the variation of \(F_i\) may be expressed as follows:

\[
-\delta F_i = \{\delta[q_1, q_2 \ldots q_{i-2}, q_n] + \delta[q_1, q_2 \ldots q_{i-2}, q_{n-1}] \cdot q_n^2 \\
+ \delta[q_1, q_2, q_3 \ldots q_{i-2}, q_{n-2}] \cdot [q_n, q_{n-1}]^2 + \&amp;c. + \delta[q_1, q_2, q_3 \ldots q_{i-2}, q_{i-1}] \cdot [q_n, q_{n-1}, q_{n-2} \ldots q_i]^2 \\
\div [q_1, q_2, q_3 \ldots q_n]^2.
\]

Art. (k.) Suppose \(i=2\), and \(q_1=a_1x+b_1, q_2=a_2x+b_2, \ldots, q_n=a_nx+b_n\),

we shall have by virtue of the above equation,

\[
\frac{d}{dx} F_2, i.e., \frac{d}{dx} \left\{ \frac{1}{q_1 - q_2 - q_3 \ldots q_n} \right\}
\]

\[
= -\frac{1}{[q_1 q_2 \ldots q_n]^2} \{a_n \cdot 1^2 + a_{n-1} \cdot q_n^2 + a_{n-2} \cdot [q_n, q_{n-1}]^2 + \&amp;c. + a_1 [q_n, q_{n-1}, q_{n-2} \ldots q_2]^2 \}.
\]

If we call \(F_2=\frac{\phi x}{f x}\) every such quantity as \([q_n, q_{n-1} \ldots q_1]\) represents to a constant factor près the \((i-1)\)th simplified residue (\(\phi x\) counting as the first of them) to \(\frac{\phi x}{f x}\), and making certain obvious but somewhat tedious reductions, and rejecting the common factor \(-\frac{1}{(f x)^2}\), we obtain the expression

\[
\frac{C_0 \cdot R_1^2}{C_1} + \frac{R_2^2}{C_1 \cdot C_2} + \frac{R_3^2}{C_2 \cdot C_3} + \ldots + \frac{R_n^2}{C_{n-1} \cdot C_n} = (\phi x, f&#x27;x - \phi&#x27;xfx),
\]

where \(R_1, R_2 \ldots R_n\) represent \(\phi x\) and the successive simplified residues to \(f x, \phi x\), and
$C_i$ means the coefficient of the highest power of $x$ in $R_i$, and $C_0$ the first coefficient in $f(x)$.

Art. (1.) If we take $g(x)$ of the same degree as $f(x)$ and for greater simplicity make the first coefficients in $f(x)$ and $g(x)$, each of them unity, the successive simplified residues to $\frac{gx}{fx}$ will be identical with the simplified residues to $\frac{-fx+gx}{gx}$ (including amongst them the quantity $gx-fx$ itself), and since

$$(fx-g(x))g&#x27;x-(fx-g(x))&#x27;gx=(g&#x27;xfx-f&#x27;x.gx),$$

the right-hand side of the equation above written, when the residues are made to refer to $f$ and $g$, instead of referring to $f$ and $\phi$, are taken of the same degree in $x$, becomes equal to $f&#x27;xgx-f&#x27;xgx&#x27;$; and if we now agree to consider $f$ and $g$ as homogeneous functions each of the $n$th degree in $x$ and 1, the equation becomes

$$\frac{R_1^2}{C_1} + \frac{R_2^2}{C_1.C_2} + \frac{R_3^2}{C_2.C_3} + \cdots + \frac{R_n^2}{C_{n-1}.C_n} = \{f(x, 1)\frac{d}{dx}g(x, 1) - g(x, 1)\frac{d}{dx}f(x, 1)\} = \frac{1}{n}\left(\frac{d}{dx}f + \frac{d}{d1}f&#x27;\right)\left(\frac{d}{dx}g + \frac{d}{d1}g&#x27;\right) = \frac{1}{n}\left(\frac{df}{d1}.\frac{dg}{dx} - \frac{df}{dx}.\frac{dg}{d1}\right) = \frac{1}{n}J(f, g),$$

where $J$ indicates the Jacobian of the given functions $f$ and $g$ in respect to the variables $x$ and 1, meaning thereby the so-called Functional Determinant of Jacobi to $f$ and $g$ in respect of $x$ and 1, which equation also obviously must continue to hold good when we restore to the coefficients of $x^n$ in $f$ and $g$ their general values.

It may happen that for particular relations between the coefficients of $f$ and $g$

* This result may be obtained directly as follows:

Let $fx$, $\phi x$ and the $(m-1)$ complete Sturmian residues be called $\rho_0, \rho_1, \rho_2, \ldots, \rho_n$; let the $n$ complete quotients be called $q_1, q_2, \ldots, q_n$, and let the allotropic factors to the residues $\rho_2, \rho_3, \ldots, \rho_n$ be called $\mu_2, \mu_3, \ldots, \mu_n$; then

$$\rho_0=q_1.\rho_1-\rho_2; \quad \rho_1=q_2.\rho_2-\rho_3; \quad \rho_2=q_3.\rho_3-\rho_4; \quad \text{&amp;c.}$$

hence

$$\rho_1^2\rho_0-\rho_0^2\rho_1=\rho_1^2\rho_1+\rho_1^2\rho_2-\rho_0^2\rho_2$$

$$=\rho_1^2\rho_1+\rho_2^2\rho_2+\rho_3^2\rho_3+\cdots+\rho_n^2\rho_n;$$

but we have in general $\rho_i=\mu_i.R_i$;

hence

$$\delta q_i=\frac{C_{i-1}}{C_i}.\frac{\mu_{i-1}}{\mu_i}\delta x$$

and

$$\rho_i^2\delta q_i=\frac{C_{i-1}}{C_i}.\mu_{i-1}.\mu_i R_i^2\delta x;$$

but it may be easily seen that

$$\mu_{i-1}.\mu_i=\frac{1}{C_{i-1}^2}; \quad \text{except when } i=1, \text{ for which case } \mu_{i-1}.\mu_i=1,$$

hence

$$\rho_i^2\delta q_i=\frac{1}{C_{i-1}.C_i}R_i^2\delta x, \text{ when } i&gt;1, \text{ and } =\frac{C_0}{C_1}R_i^2\delta x \text{ when } i=1,$$

which proves the theorem in the text.
certain of the residues may be wanting, which will be the case when any of the secondary Bezoutics have their first or successive first terms affected with the coefficient zero; the equation connecting the residues with the Jacobian will then change its form (as some of the quantities $C_1, C_2, \ldots C_n$ will become zero); but I do not propose to enter for the present into the theory of these failing, or as they may more properly be termed, Singular cases in the theory of elimination.

Art. (m.) The series last obtained for $J(f, g)$ leads to a result of much interest in the theory, and of which great use is made in the concluding section of this memoir, viz. the identification of the Jacobian (abstraction made of the numerical factor $n$) with what the Bezoutiant becomes when in place of the $n$ variables in it, $u_1 u_2 \ldots u_n$, we write $x^{n-1}, x^{n-2}, \ldots x, 1$. Thus suppose $f$ and $g$ to be each of the third degree, and let

$$Ax^3 + Hx + G$$
$$Hx^3 + Bx + F$$
$$Gx^3 + Fx + C$$

be the three primary Bezoutics; if we make

$$x^3 = u \quad x = v \quad 1 = w,$$

these may be written under the form

$$Au + Hv + Gw = L$$
$$Hu + Bv + Fw = M$$
$$Gu + Fv + Cw = N;$$

and if the Bezoutiant be called $\Phi$, we have

$$L = \frac{d\Phi}{du} \quad M = \frac{d\Phi}{dv} \quad N = \frac{d\Phi}{dw}.$$

The simplified residues to $f$ and $g$ are $L, (L, M), (L, M, N)$, where $(L, M)$ means the result of eliminating $u$ between $L$ and $M$, and $(L, M, N)$ the result of eliminating $u$ and $v$ between $L, M, N$; and by a theorem (virtually implied in the direct method* of reducing a quadratic function to the form of a sum of squares), if we call the leading coefficients of these quantities $C_1, C_2, C_3$, we have

$$\frac{L^2}{C} + \frac{(L, M)^2}{C_1 C_2} + \frac{(L, M, N)^2}{C_2 C_3} = \Phi.$$

Hence when $n = 3 \frac{1}{3} J(f, g) = \Phi$ when in $\Phi, u, v, w$ are turned into $x^3, x, 1$, and so in general for any values of $n$, the Bezoutiant correspondingly modified, becomes $\frac{1}{n} J(f, g)$, as was to be shown†.

* Viz. that of M. Cauchy, adverted to in Section IV. art. 44–45.

† Compare Jacobi, &quot;De Eliminatione,&quot; § 2. The general expression for the allotrious factor, I may here incidentally mention, is given under the head Theorem a, § 16, which comes quite at the end of the same paper.
Art. (n.) The expressions obtained for the quotients to $\frac{f&#x27;x}{fx}$ may be generalized and extended to the quotients to $\frac{\phi x}{fx}$, where $\phi x$ and $fx$ are two functions of $x$ of any degrees $m$ and $n$, whose roots are respectively, $k_1 k_2 ... k_m$, and $h_1 h_2 ... h_n$. If we suppose

$$\frac{\phi x}{fx} = \frac{1}{Q(x)} - \frac{1}{q_2(x)} - \frac{1}{q_3(x)} - \ldots \ldots - \frac{1}{q_{m+1}(x)},$$

where $Q(x)$ is of $n-m$ dimensions, and $q_2(x), q_3(x) ... q_{m+1}(x)$, each of one dimension in $x$, it may be proved that on writing

$$\frac{1}{Q(x)} - \frac{1}{q_2(x)} - \ldots \ldots - \frac{1}{q_i(x)} = \frac{N_i(x)}{D_i(x)},$$

we shall have

$$\sum_{k=0}^{k_0} \left( N_i k_0 + \frac{fk_0}{\phi k_0} (x-k_0) \right) = Cq_{i+1}(x) \quad \ldots \ldots \quad (A.)$$

$$\sum_{h=0}^{h_0} \left( D_i h_0 + \frac{fh_0}{j^h h_0} (x-h_0) \right) = C&#x27;q_{i+1}(x) \quad \ldots \ldots \quad (B.)$$

where

$$C = C&#x27; = 0, \quad \ldots \ldots \quad \quad (E.)$$

$Cq_{i+1}(x)$ being the $(i+1)$th simplified quotient. When $Q(x)$ is a linear function of $x$, in finding $q_ix$ from the formula B, we must take $D_ix = 1$. The proof of this theorem being generally true, may easily be shown to depend upon its being true in the special case*, when $m = \mu + i$, and $n = \nu + i&#x27;$ ($m$ being supposed less than $n$), and $h_1, h_2, ... h_n$ become $l_1 l_2 ... l_\mu, h_1 h_2 ... h_\nu$, and $k_1 k_2 ... k_m$ become $l_1 l_2 ... l_\mu, k_1 k_2 ... k_i$; and the truth of the theorem for this special case (if for instance we wish to prove the formula (B)) depends upon the expression

$$\begin{vmatrix}
h_1 &amp; h_2 &amp; \ldots &amp; h_{i&#x27;-1} \\
k_1 &amp; k_2 &amp; \ldots &amp; k_m
\end{vmatrix}
\div
\begin{vmatrix}
h_1 &amp; h_2 &amp; \ldots &amp; h_{i&#x27;-1} \\
h_{i&#x27;} &amp; h_{i&#x27;+1} &amp; \ldots &amp; h_n
\end{vmatrix}
\times (h_{i&#x27;}-h_1)(h_{i&#x27;}-h_2) \ldots (h_{i&#x27;}-h_{i&#x27;-1})$$

being identical with the expression

$$\left\{
\begin{vmatrix}
h_1 &amp; h_2 &amp; \ldots &amp; h_{i&#x27;-1} \\
k_1 &amp; k_2 &amp; \ldots &amp; k_m
\end{vmatrix}
\div
\begin{vmatrix}
h_1 &amp; h_2 &amp; \ldots &amp; h_{i&#x27;-1} \\
h_{i&#x27;} &amp; h_{i&#x27;+1} &amp; \ldots &amp; h_n
\end{vmatrix}
\times (h_{i&#x27;}-h_1)(h_{i&#x27;}-h_2) \ldots (h_{i&#x27;}-h_{i&#x27;-1})
\right\}$$

$$\times
\begin{vmatrix}
h_{i&#x27;} \\
k_1 &amp; k_2 &amp; \ldots &amp; k_m
\end{vmatrix}
\div
\begin{vmatrix}
h_{i&#x27;} \\
h_1 &amp; h_2 &amp; \ldots &amp; h_{i&#x27;-1} &amp; h_{i&#x27;+1} &amp; \ldots &amp; h_n
\end{vmatrix}$$

* By virtue of the Lemma, that when $\phi x$ and $fx$ are two algebraical functions ($x^n + ax^{n+c} + \ldots$); ($x^{n+e} + ax^{n+(c-e)} + \ldots$) no function of the coefficients vanishing identically when $i$ roots of $fx$ coincide with $i$ roots of $\phi x$ respectively can be formed, in which there are fewer of the coefficients of $f$ and $\phi$ respectively than appear in the leading coefficient of the $(n-i+1)$th residue of $\frac{\phi}{f}$.
as it may readily be shown to be. And the formula (A.) may be verified in precisely the same manner. There is no difficulty in finding the values of $C$ and $C&#x27;$, which are products of powers, some positive and some negative, of the leading coefficients in the simplified residues, and recognising that they satisfy the equation (E.) ; when $\varphi x$ is of one degree below $f&#x27;x$ this equation is of the form $C+C&#x27;=0$.

Art. (o.) When $\varphi x=f&#x27;x$, this expression for the $(i+1)$th simplified quotient becomes $\Sigma(D_i h)^2(x-h)$, as previously found; the correlative expression will be

$$-\Sigma(N_i k)^2 \frac{f_k}{f&#x27;_k}(x-k),$$

$k$ being any root of $f&#x27;x=0$, which is equal to the former expression. The general expressions above given for the simplified quantities are of course integral functions of $h$ and $k$, although given under the form of the sums of fractions, by virtue of the well-known theorem that $\Sigma S(h) \frac{f_h}{f&#x27;_h}$, where $S$ is an integral function of $h$, and the summation comprises all the roots $(h)$ of $f&#x27;h=0$ is always integral.

Art. (p.) It will be found that for all values of $i$ greater than unity

$$\Sigma_m \theta(N_i h) \frac{f_k}{f&#x27;_k}=0,$$

and that

$$\Sigma_n \theta(D_i h) \frac{\varphi h}{f&#x27;_h}=0.$$

The theorem of art (n.) is in effect a theorem of Cumulants of the form

$$[Q_1(x), q_2(x), \ldots q_i(x) \ldots q_n(x)],$$

where the elements are all independent of one another, and where $f&#x27;x$ represents

$$[Q_1(x) q_2(x) q_3(x) \ldots q_n(x)]$$

and $\varphi x$ represents $[q_2x, q_3(x), \ldots q_n(x)]$,

$n$ being any number whatever greater than $i$; this makes the theorem still more remarkable. The urgency of the press precludes my investigating for the present the more general theorem which must be presumed to exist, whereby $q_{i+1}$ can be connected with $[q_1 q_2 q_3 \ldots q_i]$, or $[q_2 q_3 \ldots q_i]$, and with $[q_1 q_2 q_3 \ldots q_{i+e}]$ and $[q_2 q_3 \ldots q_{i+e}]$, when each $(q)$ represents a function of an arbitrary degree in $x$. The theorem so generalized would comprehend the complete theory of the quotients arising from the process of continued division, without exclusion of the singular cases (at present supposed to be excluded) where one or several consecutive principal coefficients in one or more of the residues, vanish.

Art. (q.) The complete statement of two twin theorems suggested by and intimately connected with the biform representation of the quotients $\varphi x$ given in the preceding article, is too remarkable to be omitted.

Suppose $\varphi x=f&#x27;x$, and let the successive convergents to $f&#x27;x$ be called

$$\frac{1}{T_1 x}, \frac{t_1 x}{T_2 x}, \ldots \frac{t_{n-2} x}{T_{n-1} x}, \frac{t_{n-1} x}{T_n x}$$

where the subscript index to $t$ or $T$ indicates the degree in $x$. Then if we call the
roots of \( f(x) \) \( h_1, h_2, \ldots, h_n \) the theorem already cited in a preceding article, concerning the denominators of the convergents, may be expressed as follows:

\[
\begin{align*}
\left( \frac{f&#x27; h_1}{\varphi h_1} \right)^2; &amp; \quad \left( \frac{f&#x27; h_2}{\varphi h_2} \right)^2; \quad \ldots; \quad \left( \frac{f&#x27; h_n}{\varphi h_n} \right)^2 \\
(T_1 h_1)^2; &amp; \quad (T_1 h_2)^2; \quad \ldots; \quad (T_1 h_n)^2 \\
(T_2 h_1)^2; &amp; \quad (T_2 h_2)^2; \quad \ldots; \quad (T_2 h_n)^2 \\
\ldots &amp; \quad \ldots \quad \ldots \quad \ldots \\
(T_{n-1} h_1)^2; &amp; \quad (T_{n-1} h_2)^2; \quad \ldots; \quad (T_{n-1} h_n)^2
\end{align*}
\]

where it will be observed that the first line of terms consists exclusively of units, since \( f&#x27;x = \varphi x \) by hypothesis.

Correlatively I have ascertained that preserving the same assumption that \( \varphi x = f&#x27;x \), so that consequently \( \frac{\varphi k}{f k} \) means \( \frac{f&#x27;k}{fk} \), the following theorem obtains, viz. that if \( k_1, k_2, \ldots, k_{n-1} \) are the \((x-1)\) roots of \( \varphi x \).

\[
\begin{align*}
\left( \frac{\varphi&#x27; k_1}{f k_1} \right)^2; &amp; \quad \left( \frac{\varphi&#x27; k_2}{f k_2} \right)^2; \quad \ldots; \quad \left( \frac{\varphi&#x27; k_{n-1}}{f k_{n-1}} \right)^2 \\
(t_1(k_1))^2; &amp; \quad (t_1(k_2))^2; \quad \ldots; \quad (t_1(k_{n-1}))^2 \\
(t_2(k_1))^2; &amp; \quad (t_2(k_2))^2; \quad \ldots; \quad (t_2(k_{n-1}))^2 \\
\ldots &amp; \quad \ldots \quad \ldots \quad \ldots \\
(t_{n-2}(k_1))^2; &amp; \quad (t_{n-2}(k_2)); \quad \ldots; \quad (t_{n-2}(k_{n-1}))^2
\end{align*}
\]

It may consequently be conjectured, when \( \varphi \) and \( f \) are independent functions of \( x \) and respectively of the degree \( n-1 \) and \( n \), and \( \frac{\varphi x}{f x} \) is expanded under the form of a continued fraction, of which, as before, \( \frac{1}{T_1}; \frac{t_1}{T_2}; \ldots; \frac{t_{n-1}}{T_n} \) are the successive convergents, that we shall have analogous determinants to the twin forms above given, each separately vanishing, these more general determinants differing only from their model forms in respect of the uppermost line of terms in the one of them, being each multiplied by certain functions of \( h_1, h_2, \ldots, h_n \) respectively (all of which become units when \( \varphi x = f&#x27;x \)), and in the other of them by certain functions of \( k_1, k_2, \ldots, k_n \).

The exact form, however, of such functions, and even the possibility of such form being found capable of making the determinants vanish, remains open for further inquiry.

**Section IV.**

On some further Formulae connected with M. Sturm&#x27;s theorem, and on the Theory of Intercalations whereof that theorem may be treated as a corollary.

As preparatory to some remarks about to be made on the formulae connected with M. Sturm&#x27;s theorem, it is necessary to premise two theorems concerning quadratic functions of great importance, one which, notwithstanding its extreme simplicity, is as far as I know very little (if at all) known, and the other was given in part many years ago by M. Cauchy, but is also not generally known. The former of these
two theorems is as follows. If a quadratic homogeneous function of any number of variables be (as it may be in an infinite variety of ways) transformed into a function of a new set of variables, linearly connected by real coefficients with the original set, in such a way that only positive and negative squares of the new variables appear in the transformed expression, the number of such positive and negative squares respectively will be constant for a given function whatever be the linear transformations employed. This evidently amounts to the proposition, that if we have $2n$ positive and negative squares of homogeneous real linear functions of $n$ variables identically equal to zero, the number of positive squares and of negative squares must be equal to one another, so that *ex gr.* we cannot have

$$\pm \{u_1^2 + u_2^2 + &amp;c. \ldots + u_{n+1}^2 - u_{n+2}^2 - u_{n+3}^2 - &amp;c. - u_{2n}^2\}$$

identically zero when $n$ of the variables are linear functions of the remaining $n$; and this is obviously the case, for if the equation could be identically satisfied we might make

$$u_{n+2} = u_1, \quad u_{n+3} = u_2, \ldots, u_{2n} = u_{n-1},$$

and we should then be able to find $u_{n+1}$ as a real numerical multiple of $u_n$, and consequently should have the equation $u_n^2(1+k^2) = 0$, which is obviously impossible; *à fortiori* we may prove that in the identical equation existing between the sum of an even number of positive and of negative squares of real linear functions of half the number of independent variables, there cannot be more than a difference of two (as we have proved that there cannot be that difference) between the number of positive and negative squares. Hence there must be as many of one as of the other; and as a consequence, the number of positive squares or of negative squares in the transform of a given quadratic function of any number of variables effected by any set of real linear substitutions is constant, being in fact some unknown transcendental function of the coefficients of the given function. I quote this law (which I have enunciated before, but of which I for the first time publish the proof) under the name of the law of inertia for quadratic forms.

Art. (45.). The other theorem is the following. If any quadratic function be represented in the umbral notation* under the form of $(a_1 x_1 + a_2 x_2 + \ldots + a_n x_n)^2$, where $a_1, a_2, \ldots, a_n$ are the umbræ of the coefficients, and $x_1, x_2, \ldots, x_n$ the variables, then by writing

$$\begin{vmatrix}
a_1 &amp; a_1 \\
a_1 &amp; a_2 \\
\end{vmatrix} x_1 + \begin{vmatrix}
a_1 &amp; a_2 \\
a_2 &amp; a_3 \\
\end{vmatrix} x_2 + \begin{vmatrix}
a_1 &amp; a_2 \\
a_3 &amp; a_4 \\
\end{vmatrix} x_3 + \ldots + \begin{vmatrix}
a_1 &amp; a_2 \\
a_n &amp; a_{n+1} \\
\end{vmatrix} x_n = y_1,$$

$$\begin{vmatrix}
a_1 &amp; a_2 \\
a_2 &amp; a_3 \\
\end{vmatrix} x_2 + \begin{vmatrix}
a_1 &amp; a_2 \\
a_3 &amp; a_4 \\
\end{vmatrix} x_3 + \ldots + \begin{vmatrix}
a_1 &amp; a_2 \\
a_n &amp; a_{n+1} \\
\end{vmatrix} x_n = y_2,$$

$$\begin{vmatrix}
a_1 &amp; a_2 &amp; a_3 \\
a_2 &amp; a_3 &amp; a_4 \\
\end{vmatrix} x_3 - \begin{vmatrix}
a_1 &amp; a_2 &amp; a_3 \\
a_2 &amp; a_3 &amp; a_4 \\
\end{vmatrix} x_4 + \ldots + \begin{vmatrix}
a_1 &amp; a_2 &amp; a_3 \\
a_n &amp; a_{n+1} &amp; a_{n+2} \\
\end{vmatrix} x_n = y_3,$$

&amp;c. &amp;c. &amp;c.

$$\begin{vmatrix}
a_1 &amp; a_2 &amp; \ldots &amp; a_n \\
a_1 &amp; a_2 &amp; \ldots &amp; a_n \\
\end{vmatrix} x_n = y_n,$$

* For an explanation of the umbral notation, see London and Edinburgh Philosophical Magazine, April 1851, or thereabouts.
\[(a_1 x_1 + a_2 x_2 + \ldots + a_n x_n)^2\] will assume the form

\[
\begin{vmatrix}
a_1 &amp; a_2 \\
a_1 &amp; a_2
\end{vmatrix} y_1^2 +
\begin{vmatrix}
a_1 &amp; a_2 &amp; a_3 \\
a_1 &amp; a_2 &amp; a_3
\end{vmatrix} y_2^2 +
\ldots +
\begin{vmatrix}
a_1 &amp; a_2 &amp; \ldots &amp; a_{n-1} &amp; a_n \\
a_1 &amp; a_2 &amp; \ldots &amp; a_{n-1} &amp; a_n
\end{vmatrix} y_n^2
\]

and consequently the number of positive squares in the reduced form of the given function will always be the number of continuations or permanencies of sign of the series

\[1; \frac{a_1}{a_1}; \frac{a_1 a_2}{a_1 a_2}; \frac{a_1 a_2 a_3}{a_1 a_2 a_3}; \ldots; \frac{a_1 a_2 \ldots a_n}{a_1 a_2 \ldots a_n}\]

the several terms of this progression being in fact the determinants of what the given function becomes when we obliterate successively all the variables but one, then all but that another, then all but these two and a third, until finally, the last term is the determinant of the given function with all the variables retained. This comes to saying that if we call the function (suppose of four variables) \(f\), and we write

\[
\begin{align*}
\frac{d^2 f}{dx_1^2}, &amp; \quad \frac{d^2 f}{dx_1 dx_2}, \quad \frac{d^2 f}{dx_1 dx_3}, \quad \frac{d^2 f}{dx_1 dx_4}, \\
\frac{d^2 f}{dx_2 dx_1}, &amp; \quad \frac{d^2 f}{dx_2 dx_3}, \quad \frac{d^2 f}{dx_2 dx_4}, \\
\frac{d^2 f}{dx_3 dx_1}, &amp; \quad \frac{d^2 f}{dx_3 dx_2}, \quad \frac{d^2 f}{dx_3 dx_4}, \\
\frac{d^2 f}{dx_4 dx_1}, &amp; \quad \frac{d^2 f}{dx_4 dx_2}, \quad \frac{d^2 f}{dx_4 dx_3}, \quad \frac{d^2 f}{dx_4 dx_4},
\end{align*}
\]

(where all the terms are of course coefficients of the given function expressed as above for greater symmetry of notation), the inertia of \(f\) will be measured by the number of continuations of sign in the series formed of the successive principal minor coaxal determinants (in writing which I shall use in general \((r, s)\) to denote \(\frac{d^2 f}{dx_r dx_s}\)),

\[
\begin{bmatrix}
(1, 1) &amp; (1, 2) &amp; (1, 3) &amp; (1, 4) \\
(2, 1) &amp; (2, 2) &amp; (2, 3) &amp; (2, 4) \\
(3, 1) &amp; (3, 2) &amp; (3, 3) &amp; (3, 4) \\
(4, 1) &amp; (4, 2) &amp; (4, 3) &amp; (4, 4)
\end{bmatrix}
\]

and in like manner in general*.

---

* I have given a direct \textit{à posteriori} demonstration in the London and Edinburgh Philosophical Magazine, that the number of continuations of sign in any series formed like the above form a symmetrical matrix, is unaffected by any permutations of the lines and columns thereof, which leaves the symmetry subsisting, that is to say (using the umbral notation), if \(\theta_1, \theta_2, \theta_3, \ldots, \theta_i\) are disjunctively equal, each to each, in any arbitrary order to 1, 2, 3, \ldots, \(i\), the number of continuations of sign in the series

\[
1, \begin{vmatrix} a_{\theta_1} \\ a_{\theta_1} \end{vmatrix}, \begin{vmatrix} a_{\theta_1} a_{\theta_2} \\ a_{\theta_1} a_{\theta_2} \end{vmatrix}, \begin{vmatrix} a_{\theta_1} a_{\theta_2} a_{\theta_3} \\ a_{\theta_1} a_{\theta_2} a_{\theta_3} \end{vmatrix}, \ldots, \begin{vmatrix} a_{\theta_1} a_{\theta_2} \ldots a_{\theta_i} \\ a_{\theta_1} a_{\theta_2} \ldots a_{\theta_i} \end{vmatrix}
\]

is irrespective of the order of the natural numbers 1, 2, 3, \ldots, \(i\) in the arrangement \(\theta_1, \theta_2, \theta_3, \ldots, \theta_i\).
Art. (46.). Reverting now to the simplified Sturmian residues, since by the theory set out in the first Section these differ from the unsimplified complete residues required by the Sturmian method only in the circumstance of their being divested of factors, which are necessarily perfect squares and therefore essentially positive, these simplified Sturmians may of course be substituted for the complete Sturmians for the purposes of M. Sturm&#x27;s theorem. The leading coefficients in these simplified Sturmians, reckoning $f&#x27;(x)$ as one of them, will be

$$m\Sigma \zeta(h_1 h_2), \Sigma \zeta(h_1 h_2 h_3) \ldots \zeta(h_1 h_2 \ldots h_m),$$

which it is easily seen, as remarked long ago by Mr. Cayley, are the successive principal minor coaxal determinants of the matrix

$$\begin{array}{cccc}
\sigma_0, &amp; \sigma_{12}, &amp; \sigma_{23}, &amp; \ldots \sigma_{m-1} \\
\sigma_{13}, &amp; \sigma_{23}, &amp; \sigma_{34}, &amp; \ldots \sigma_m \\
\sigma_{23}, &amp; \sigma_{34}, &amp; \ldots \sigma_{m-1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\sigma_{m-1}, &amp; \sigma_m, &amp; \ldots \sigma_{2m-2},
\end{array}$$

where in general $\sigma_r = h_1^r + h_2^r + \ldots + h_m^r$, and of course $\sigma_0 = m$. M. Hermite has improved upon this remark by observing, which is immediately obvious, that if we use $\sigma_r$ to denote, not the quantity above written, but $\frac{h_1^r}{x-h_1} + \frac{h_2^r}{x-h_2} + \ldots + \frac{h_m^r}{x-h_m}$, the successive coaxal determinants of the above matrix will become respectively

$$\Sigma \frac{1}{x-h_1}; \Sigma \left\{ \frac{\zeta(h_1 h_2)}{(x-h_1)(x-h_2)} \right\}; \Sigma \frac{\zeta(h_1 h_2 h_3)}{(x-h_1)(x-h_2)(x-h_3)}; \ldots \frac{\zeta(h_1 h_2 \ldots h_m)}{(x-h_1)(x-h_2) \ldots (x-h_m)};$$

that is to say, these successive coaxal determinants, when multiplied up by $fx$, will become respectively

$$\Sigma (x-h_2)(x-h_3) \ldots (x-h_m); \Sigma \zeta(h_1 h_2) \{(x-h_3)(x-h_4) \ldots (x-h_m)\}; \ldots; \Sigma \zeta(h_1 h_2 \ldots h_m),$$

that is to say, will represent the simplified Sturmian series given by my general formulæ. M. Hermite further remarks, that the matrix formed after this rule will evidently be that which represents the determinant of the quadratic function (which may be treated as a generating function)

$$\Sigma \frac{1}{x-h_1} \{u_1 + h_1 u_2 + h_1^2 u_3 + \ldots + h_1^{m-1} u_n\}^2,$$

in which, since only the squared differences of the terms in the $(h)$ series finally remain in the successive coaxal determinants, we may write $(x-h_1), (x-h_2) \ldots (x-h_m)$ simultaneously in place of $h_1 h_2 \ldots h_m$ without affecting the result, consequently the generating function above may be replaced by the generating function

$$\Sigma \frac{1}{x-h_1} \{u_1 + (x-h_1) u_2 + (x-h_1)^2 u_3 + \ldots + (x-h_1)^{m-1} u_n\}^2.$$
the corresponding matrix to which becomes

$$\begin{bmatrix}
\Sigma \frac{1}{x-h_1}, &amp; \theta_0, &amp; \theta_1, &amp; \ldots, &amp; \theta_{m-2} \\
\theta_0, &amp; \theta_1, &amp; \theta_2, &amp; \ldots, &amp; \theta_{m-1} \\
\theta_1, &amp; \theta_2, &amp; \ldots, &amp; \ldots, &amp; \theta_m \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\theta_{m-3}, &amp; \theta_{m-1}, &amp; \ldots, &amp; \ldots, &amp; \theta_{2m-3},
\end{bmatrix}$$

where $\theta_i$ denotes $\Sigma (x-a)^i$, and $\Sigma \frac{1}{x-h_i} = f&#x27;x$. Hence every simplified residue is of the form

$$f&#x27;x \times \begin{bmatrix}
\theta_1, &amp; \theta_2, &amp; \ldots, &amp; \theta_r \\
\theta_2, &amp; \theta_3, &amp; \ldots, &amp; \theta_{r+1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\theta_r, &amp; \theta_{r+1}, &amp; \ldots, &amp; \theta_{2r-1}
\end{bmatrix} + f&#x27;x \times \begin{bmatrix}
0, &amp; \theta_0, &amp; \theta_1, &amp; \ldots, &amp; \theta_r \\
\theta_0, &amp; \theta_1, &amp; \ldots, &amp; \theta_{r+1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\theta_r, &amp; \theta_{r+1}, &amp; \ldots, &amp; \theta_{2r-1}
\end{bmatrix}.$$ 

The residue in question will be of the degree $m-r-2$ in $x$, and consequently we have, according to the notation antecedently used for the syzygetic equations

$$t_{r+1} = \begin{bmatrix}
\theta_1, &amp; \theta_2, &amp; \ldots, &amp; \theta_r \\
\theta_2, &amp; \theta_3, &amp; \ldots, &amp; \theta_{r+1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\theta_r, &amp; \theta_{r+1}, &amp; \ldots, &amp; \theta_{2r-1}
\end{bmatrix}$$

$$-\tau_r = \begin{bmatrix}
0, &amp; \theta_0, &amp; \theta_1, &amp; \ldots, &amp; \theta_r \\
\theta_0, &amp; \theta_1, &amp; \ldots, &amp; \theta_{r+1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\theta_r, &amp; \theta_{r+1}, &amp; \ldots, &amp; \theta_{2r-1}
\end{bmatrix}.$$ 

Elegant and valuable for certain purposes as are these formulæ for $t_{r+1}$ and $\tau_r$, they are affected with the disadvantage of being expressed by means of formulæ of a much higher degree in the variable $x$ than really appertains to them, the paradox (if it may be termed such) being explained by the circumstance of the coefficients of all the powers of $x$ above the right degree being made up of terms which mutually destroy one another. Upon the face of the formulæ, $t_{r+1}$ and $\tau_r$ which are in fact only of the degrees $r+1$, and $r$ respectively in $x$ would appear to be of the degree $1+3+5+\ldots+(2r-1)$, i.e. of the degree $r^2$.

Art. (47.). I may add the important remark, which does not appear to have occurred immediately to my friend M. Hermite when he communicated to me the above most interesting results, that in fact, by virtue of the law of inertia for quadratic forms, we may dispense with any identification of the successive coaxal determinants of the matrix to the generating function

$$\Sigma \frac{1}{g-h_1}\{u_1+h_1u_2+h_1^2u_3+\ldots+h_1^{m-1}u_m\}^2$$
with my formulæ for the Sturmian functions, and prove ab initio in the most simple manner, that the successive ascending coaxal determinants (always of course supposed to be taken about the axis of symmetry) of the matrix to the form above written, or to the more general form (which I shall quote as G, viz.)

\[ \Sigma (\varphi - h_i)^q \{ \varphi_1(h_i)u_1 + \varphi_2(h_i)u_2 + \ldots + \varphi_m(h_i)u_m \}^2 \ldots \ldots \quad (G.) \]

(where \( \varphi_1, \varphi_2, \ldots, \varphi_m \) are absolutely arbitrary integral forms of function with real coefficients), will form a rhistoristic series in regard to \( f(x) \) (i.e., a series, the difference between the number of the continuations of sign between the successive terms of which corresponding to two different values of \( \varepsilon \) will determine the number of real roots of \( \varepsilon \) lying between such two assumed values), provided only that \( q \) be an odd positive or negative integer. Nothing can be easier than the demonstration, for whenever \( \varepsilon \) is greater than any one of the real roots as \( (h_i) \)

1st. Any pair of imaginary roots will give rise to two terms of the form

\[(l + m\sqrt{-1})^q(v + w\sqrt{-1})^2 \text{ and } (l - m\sqrt{-1})^q(v - w\sqrt{-1})^2;\]

or more simply,

\[(L + M\sqrt{-1})(v^2 + w^2 + 2vw\sqrt{-1})\]

and \[(L - M\sqrt{-1})(v^2 - w^2 - 2vw\sqrt{-1}),\]

where \( v \) and \( w \) are real linear functions of \( u_1, u_2, \ldots, u_n \). The sum of which couple will be

\[2\{L(u^2 - v^2) - 2Muv\} = \frac{2}{L}\{(Lu - Mv)^2 - (L^2 + M^2)v^2\} = p^2 - q^2;\]

so that each such couple combined will for every value of \( x \) give rise to one positive and one negative square.

2ndly. Any real root of the series \( h_1, h_2, \ldots, h_m \), when \( \varepsilon \) is taken greater than such root, will give rise to a positive square of a real linear function of \( u_1, u_2, \ldots, u_n \).

3rdly. Any real root of the same series, when \( \varepsilon \) is beneath it in value (\( q \) being odd), will give rise to the negative of the square of a real linear function of the same. Hence the number of real roots between \( \varepsilon \) taken equal to one value (\( a \)), and \( \varepsilon \) taken equal to any other value (\( b \)), will be denoted by the loss of an equal number of positive squares in the reduced form of the expression (G.) when \( \varepsilon \) is taken (\( a \)) and when \( \varepsilon \) is taken (\( b \)); i.e. by virtue of art. (45.) will be denoted by the difference of the number of permanencies of sign in the successive minor determinants of the matrix corresponding to the quadratic form (G.)* (which we have taken as our generating function) resulting

* The inertia of the quadratic form \( G \) is the measure of the number of real roots of \( f(x) \) comprised between \( \infty \) and \( \rho \), and may be estimated in any manner that may be found most convenient. If \( \rho \) be made infinity, and \( \varphi_h \) be taken equal to \( h^{k-1} \), and the inertia of the corresponding value of \( G \) be estimated by means of the formulæ in ordinary use by geometers for determining the nature of a surface of the second degree, the criteria of the number of real roots in \( f(x) \) will be, or may be made to be, symmetrical in respect to the two ends of the expression \( f(x) \). This system of criteria, however, is not so good as that given by the Bezoutiant to the two differential coefficients of \( f(x, 1) \) taken with regard to \( x \) and 1 respectively, which will also possess the like character of symmetrical indifference, and be one less in number than the former.
from the substitution respectively of \(a\) and \(b\) in place of \(g\), which gives a theorem equivalent to that of M. Sturm, transformed by my formulæ, when we choose to adopt the particular suppositions

\[ q = -1 \quad \phi_1 h = 1 \quad \phi_2 h = h \quad \phi_3 h = h^2 \ldots \phi_m h = h^{m-1}. \]

This method of constructing a rhizoristic series to \(fx\) by a direct process is deserving of particular attention, because it does not involve the use of the notion of continuous variation, upon which all preceding proofs of Sturm&#x27;s theorem proceed. It completes the cycle of the Sturmian ideas. Happily this cycle was commenced from the other end, for it would have been difficult to have suspected that the root-expressions for the terms in the rhizoristic series could be identified with the residues, had the former been the first to be discovered, and much of the theory of algebraical common measure laid open by means of this identification would probably have remained unknown.

Art. (48.). I proceed now to consider a theorem concerning the relative positions of the real roots of two independent algebraical functions as indicated by the succession of signs presented by their Bezoutian secondaries; this more general theory of intercalations or relative interpositions will be seen to include within it as a corollary the justly celebrated theorem of M. Sturm.

Let the real roots of \(fx\) taken in descending order of magnitudes be \(h_1, h_2, \ldots, h_p\), and the real roots of \(\phi x\) taken in the like order \(n_1, n_2, \ldots, n_q\), so that

\[ fx = (x-h_1)(x-h_2) \ldots (x-h_p)H \]
\[ \phi x = (x-n_1)(x-n_2) \ldots (x-n_q)K, \]

\(H\) and \(K\) being functions of \(x\) incapable of changing their signs. Now, as in M. Sturm&#x27;s method, let us inquire what takes place in respect to the sign of \(\frac{\phi(x)}{f(x)}\), which I shall call the Indicatrix, as \(x\) descends the scale of real magnitude from \(+\infty\) to \(-\infty\). If between \(+\infty\) and \(h_i\), \(i\) real roots of \(\phi x\) are contained, it is obvious that as \(x\) travels from \(+\infty\) to the superior brink of \(h_i\), the Indicatrix will change its sign from \(+\) to \(-\) and from \(-\) to \(+\) altogether \(i\) times, so that at the moment when \(x\) is about to pass through \(h_i\), it will be positive if \(i\) is zero or even, and negative if \(i\) is odd; but the moment after \(x\) has passed through the value \(h_i\), the indicatrix will be negative on the first supposition, and positive on the other supposition. Hence immediately after the passage of \(x\) through \(h_i\) the indicatrix will have been once oftener negative than positive on the one supposition, and as often negative as positive on the other. Again, in like manner as \(x\) traverses the interval between \(h_i\) and the inferior brink of \(h_{i+1}\), if no \(n\) or an even number of \(n\)&#x27;s occupy this interval, the sign which the Indicatrix had at the beginning of this interval will have been reversed once oftener than restored; but if there be an odd number of \(k\)&#x27;s so interposed, the number of reversals and restorations will have been identical; and so for each successive interval, reckoned from a value for \(x\) immediately subsequent to one real root of \(fx\), down to a value immediately subsequent to the next less real root of the
same; and it is evident that the effect upon the sign of the Indicatrix at the end of every such interval depends, not upon the number of \( \eta \)&#x27;s grouped together in such interval, but upon the form of the group as regards its being made up of an odd or even number of terms [the first interval will of course be understood to extend from \( +\infty \) to a value immediately inferior to \( h_1 \), and the last from a value immediately inferior to \( h_p \) to \( -\infty \)]. Hence as regards the relation of the signs of the Indicatrix at the beginning to the sign at the end of every such interval, nothing will be altered by taking away any even number of \( \eta \)&#x27;s that may be found therein. If we suppose this to be done, we shall then have in some of the intervals one \( \eta \) occurring and in the other intervals no \( \eta \); that is to say, some of the \( h \)&#x27;s will be separated by single \( \eta \)&#x27;s, but other \( h \)&#x27;s will come together. Again, by removing any even number of \( h \)&#x27;s not separated by \( \eta \)&#x27;s (and thus removing an even number of intervals), it is clear that as many changes of sign of the Indicatrix will have been done away with from \( + \) to \( - \) as from \( - \) to \( + \), and no effect upon the excess of the one kind of changes of sign over the other kind of changes of sign will have been produced. By removing pairs of \( h \)&#x27;s in this manner, it may happen that \( \eta \)&#x27;s will again be brought together, any even number of which, not separated by \( h \)&#x27;s, may again be removed and then pairs of \( h \)&#x27;s not separated by \( \eta \)&#x27;s in their turn, and so continually toties quoties until at length we must arrive at a reduced system of \( h \)&#x27;s and \( \eta \)&#x27;s, where no two \( h \)&#x27;s and no two \( \eta \)&#x27;s come together, or else all the \( h \)&#x27;s and all the \( \eta \)&#x27;s will have disappeared. Let the scale of \( h \)&#x27;s and \( \eta \)&#x27;s thus simplified and reduced be called the effective scale of intercalations. The number of \( h \)&#x27;s and the number of \( \eta \)&#x27;s in any such scale will be equal, or will at most differ from one another by a unit, since at each part of the scale, except at the end, every \( h \) is followed by an \( \eta \) and every \( \eta \) by an \( h \). If the scale begins and ends with an \( h \), there will of course be one more \( h \) than \( \eta \); if it begin and end with an \( \eta \), there will be one more \( \eta \) than \( h \); if it begin with an \( h \) or an \( \eta \) and end with an \( \eta \) or \( h \), there will be as many of the one as of the other.

1st. Suppose the effective intercalation scale to commence with an \( h \); then in passing from \( +\infty \) to just beyond the first \( h \) the sign of the indicatrix \( \frac{\phi x}{f x} \) changes from \( + \) to \( - \); it changes again from \( - \) to \( + \) as it passes the first \( \eta \), then again from \( + \) to \( - \) as it passes the second \( h \), and so on; that is to say, there will be a change always in the same direction from \( + \) to \( - \) as \( x \) passes, from being just greater than to being just less than any \( h \) appearing in the effective scale. 2nd. If the effective scale begin with \( \eta \), the indicatrix will conversely be negative after passing the first and every subsequent \( \eta \), and change from \( - \) to \( + \) in the act of passing through the first and every subsequent \( h \). So that on either supposition the changes of sign for the effective scale always take place in the same direction, and the number of \( h \)&#x27;s in the effective scale will be measured by the number of such changes, and consequently will be measured by the difference between the number of times that the indicatrix \( \frac{\phi x}{f x} \) changes its sign from \( + \) to \( - \) as \( x \) passes through each in turn of the real roots of \( f x \), and the number of times that in passing through any such root it changes its sign from \( - \) to \( + \); if the former number be MDCCCLIII.
greater than the latter, the effective scale of interpositions will begin with a root of $fx$; if it be less, the scale will begin with a root of $\varphi x$. If instead of beginning with $+\infty$ and ending with $-\infty$ we begin and end with any two limits, $a$ and $b$ respectively (making abstraction of all roots of $fx$ or of $\varphi x$ lying outside these limits, and forming the effective intercalation scale with the roots comprised within these limits exclusively), we shall obviously obtain a similar result, but with the condition that the changes from $+$ to $-$ will be in excess if an even number of $h$&#x27;s and $\eta$&#x27;s combined be cut off by the superior limit, and the effective scale begin with an $h$, or if an odd number of $h$&#x27;s and $\eta$&#x27;s combined be so cut off and the scale begin with an $\eta$; and in defect if an odd number of $h$&#x27;s and $\eta$&#x27;s combined be so cut off and the scale begin with an $h$, or an even number be so cut off and the scale begin with an $\eta$. If, now, supposing $fx$ to be of $n$, and $\varphi x$ of not more than $n$, say $(m)$ dimensions, we form the signaletic series $fx$, $\varphi x$, $B_1$, $B_2$, ... $B_m$ (where the $B_1$, $B_2$, ... $B_m$ are the Bezoutian secondaries or simplified successive residues corresponding to $\frac{\varphi x}{fx}$ expanded under the form of an improper continued fraction), it may be shown, in the same way as for Sturm&#x27;s theorem, that whenever $\frac{\varphi x}{fx}$ changes from $+$ to $-$ a change of sign will be gained in the series, and when from $-$ to $+$ a change will be lost; and that no change can be gained or lost except as $x$ passes through the successive real roots of $fx$. Hence the difference between the number of changes of sign in the above signaletic series when $x$ is taken $(a)$, and the number of the same when $x$ is taken $(b)$, will indicate the number of roots of $fx$ remaining in the effective scale of interpositions formed between such of the roots of $fx$ and of $\varphi x$ as lie between $(a)$ and $(b)$; calling the one number $I(a)$ and the other $I(b)$, the sign of $I(b) - I(a)$ depends not on the relative magnitudes of $(a)$ and $(b)$, but upon the manner in which the effective scale commences; if $I(a) - I(b)$ is positive, the effective scale formed between the $(a)$ and $(b)$ will commence with a root of $fx$; if negative, it will commence with a root of $\varphi(x)$.

Art. (49.). In forming the scale of effective interpositions, it is evidently not necessary to go on reducing the $(h)$ series and the $\eta$ series separately and alternately; the same result will be effected more expeditiously by eliding simultaneously any even number of $h$&#x27;s that come together without being separated by an $\eta$, and any even number of $\eta$&#x27;s that come together without being separated by an $(h)$, and, repeating this process of simultaneous elision, as often as may be required, until no two $h$&#x27;s or $\eta$&#x27;s come together. Thus, for instance, denoting the magnitudes of the series of real roots of $f$ and of $\varphi$ by the distances of $h$ and $\eta$ points taken along a right line from a fixed point therein, and supposing such series of roots between the limits $a$ and $b$ to be

$$hh\eta\eta h\eta h\eta h\eta h\eta h\eta h\eta h\eta h\eta h,$$

our first reduction brings this scale to the form

$$h\eta h\eta h\eta h\eta h;$$

the next reduction brings it to the form

$$h\eta\eta h\eta;$$
and a third and final reduction brings it to the form

\[ h \eta h \eta; \]

and accordingly we shall find for such an arrangement of the \( h \) and \( \eta \) system

\[ I(b) - I(a) = \pm 2. \]

Art. (50.). If we suppose \( \phi x = \frac{dfx}{dx} \), by a well-known theorem of algebra, any two consecutive roots of \( fx \) will contain between them an odd number of roots of \( \phi x \), and the number of real roots of \( f&#x27;x \) greater than the greatest root of \( fx \), and the number of real roots of \( f&#x27;x \) less than the least root of \( fx \) will each be even. Hence the effective intercalation scale between any two limits \( (a) \) and \( (b) \) will be formed by merely reducing the \( \eta \) groups to single units, and the number of \( h \)&#x27;s in the scale so formed will be the total number of \( h \)&#x27;s between the limits \( (a) \) and \( (b) \). Moreover, since such scale commences always with a root of \( fx \), or with an even number of roots of \( f&#x27;x \) followed by a root of \( fx \), if the number of \( h \)&#x27;s and \( \eta \)&#x27;s cut off be even, and with a root of \( f&#x27;x \) or an even number of roots of \( fx \) followed by a root of \( fx \), if the number so cut off be odd, it follows that for this case \( I(a) - I(b) \), \( (a) \) being the superior limit, will be always positive, and will measure the total number of real roots of \( f(x) \) lying between \( (a) \) and \( (b) \); this, then, is Sturm&#x27;s theorem, treated as a corollary to the Theory of Intercalations.

Art. (51.). If we write down the last syzygetic equation between \( fx \) of \( m \) and \( \phi(x) \) of \( n \) dimensions, viz.

\[ r_{n-1}(x)f(x) - t_{m-1}(x)\phi x + S_0 = 0, \]

it has been shown that the succession of signs in the series formed with \( fx \), \( \phi x \) and their successive Bezoutian secondaries will contain the same number of continuations and variations as the series formed with \( f(x) \), \( t_{m-1}(x) \), and their successive Bezoutian secondaries. This indicates that the effective scale of interpositions for \( fx \) and \( \phi x \) will contain an equal number of roots of \( fx \) with the effective scale for \( fx \) and \( t_{m-1}(x) \); the two scales however will not necessarily be identical, because the roots of \( \phi x \) will not necessarily be in the same order relative to the \( h \)&#x27;s in the one scale as those of \( t_{m-1},x \) relative to the \( h \)&#x27;s in the other scale. This equality is perfectly well explained \( a posteriori \) by the form of \( t_{m-i},x \), which by the formula in Section II. will be represented by

\[ \Sigma(x-h_{q_1})(x-h_{q_2})...(x-h_{q_{m-1}}) \cdot \frac{\phi h_{q_1},\phi h_{q_2}...\phi h_{q_{m-1}}}{(h_{q_m}-h_{q_1})(h_{q_m}-h_{q_2})...(h_{q_m}-h_{q_{m-1}})}. \]

Now, whenever \( x \) is indefinitely near to any one of the roots of \( fx \), as \( h_{q_m} \), this sum reduces to the simple expression

\[ \phi h_{q_1},\phi h_{q_2}...\phi h_{q_{m-1}} = \{ \phi h_1,\phi h_2...\phi h_m \} \cdot \frac{1}{\phi h_{q_m}}, \]

and consequently in the immediate neighbourhood of every real root of \( fx \), \( \phi(x) \) and \( t_{m-1},x \) will have always the same or always a contrary sign, according as \( \phi h_{q_1},\phi h_{q_2}...\phi h_{q_m} \) is positive or negative, which will depend upon the relative disposition of the real roots in \( f \) and \( \phi \); in either case the effective scale of interpositions for \( fx \) with \( \phi x \) and
for \( fx \) with \( t_{m-1} \cdot x \) must contain the same number of \( h&#x27;s \); but the difference will be, 
that if \( ph_1.p h_2 \ldots p h_m \) is positive an \( h \) will occupy the first place in each scale, or the 
second place in each scale; but if negative, then in one scale an \( (h) \) will occupy the 
first place, and in the other scale the second place.

Art. (52.). The same process of common measure or residues which serves to furnish 
a rhizoristic series for \( f(x) \) or a synrhizoristic series for \( fx \) and \( px \), will serve also to 
furnish superior and inferior limits to the real roots of any proposed equation. Thus 
suppose \( fx \) to be any rational integral function of \((x)\) of the degree \((n)\) and \( p(x) \) any 
other function of \( x \), which I shall begin with supposing to be of the degree \((n-1)\), 
and let the successive quotients resulting from the process of finding the greatest 
common measure of \( fx \), \( px \) continued until the last remainder is not a constant but zero, 
be supposed to be (as they may generally be taken, but subject to cases of exception, 
which will hereafter be alluded to) \( n \) linear functions \( q_1 q_2 \ldots q_n \), then we shall have

\[
\frac{px}{fx} = \frac{1}{q_1 + \frac{1}{q_2 + \cdots + \frac{1}{q_{n-1} + \frac{1}{q_n}}} 
\]

and therefore

\[
px = K.N \\
fx = K.D,
\]

where \( N \) is the numerator and \( D \) the denominator of the fraction

\[
\frac{1}{q_1 + \frac{1}{q_2 + \cdots + \frac{1}{q_n}}},
\]

and \( K \) is a constant (the value of which is immaterial to be considered, but in fact equals

\[\pm L_0 L_1^3 L_2^4 \ldots &amp;c.,\]

\( L_0, L_1, L_2, L_3, &amp;c. \) being the leading coefficients of the last, the last but one, the last 
but two, &amp;c. of the Bezoutian secondaries to \( fx \) and \( px \). Accordingly,

if \( n = 1 \), let \( D = q_1 = \mu_1 \);

if \( n = 2 \), let \( D = q_2 q_1 + 1 = \mu_1 \left[ q_2 + \frac{1}{\mu_1} \right] = \mu_1 \mu_2 \);

if \( n = 3 \), let \( D = q_3 \{ q_2 q_1 + 1 \} + q_1 = \mu_1 \mu_2 \left[ q_3 + \frac{1}{\mu_2} \right] = \mu_3 \);

\[
\begin{align*}
&amp;\mu_1 = q_1 \\
&amp;\mu_2 = q_2 + \frac{1}{\mu_1} \\
&amp;\mu_3 = q_3 + \frac{1}{\mu_2} \\
&amp;\vdots \\
&amp;\mu_n = q_n + \frac{1}{\mu_{n-1}}
\end{align*}
\]

Now suppose \( x \) to be so taken that

\[
\begin{align*}
q_1 &amp;\text{ does not lie between } +1 \text{ and } -1 \\
q_2 &amp;\text{ . . . . . . . . }+2 \text{ and } -2 \\
q_3 &amp;\text{ . . . . . . . . }+2 \text{ and } -2 \\
q_4 &amp;\text{ . . . . . . . . }+2 \text{ and } -2 \\
&amp;\vdots \\
q_{n-1} &amp;\text{ . . . . . . . . }2 \text{ and } -2 \\
q_{n} &amp;\text{ . . . . . . . . }1 \text{ and } -1
\end{align*}
\]

\[(*\cdot)\]
where it will be observed that the excluded region lies between \(+2\) and \(-2\) for all the intermediate quotients, but between only \(+1\) and \(-1\) for the first and last quotient. Then \(\mu_1\) is positively or negatively greater than 1, therefore \(\frac{1}{\mu_1}\) is a positive or negative fraction, but \(q_2\) is positively or negatively greater than 2; therefore \(\mu_2\) will be of the same sign in \(q_3\), and also \(\mu_2\) will be positively or negatively greater than 1; therefore \(\frac{1}{\mu_2}\) will be a positive or negative fraction, but \(q_3\) is positively or negatively greater than 2; therefore \(\mu_3\) will be of the same sign as \(q_3\), and also \(\mu_3\) will be positively or negatively greater than 1; and proceeding in this way, we find that all values of \(\mu_i\), from \(i=1\) to \(i=n-1\), will be of the same sign as \(q_i\), and positively or negatively greater than 1. Finally, \(\frac{1}{\mu_{n-1}}\) will be a fraction, and therefore, since \(q_n\) is positively or negatively greater than 1, \(\mu_n=q_n+\frac{1}{\mu_{n-1}}\) will have the same sign as \((q_n)\) (but of course is not necessarily greater than 1, nor would that condition serve any purpose were it satisfied). We infer consequently, that when the conditions \((\omega)\) are satisfied, \(\mu_1, \mu_2, \mu_3, \ldots, \mu_n\) will respectively have the same signs as \(q_1, q_2, \ldots, q_n\); and therefore \(D=\mu_1, \mu_2, \mu_3, \ldots, \mu_n\) has the same sign as \(q_1, q_2, q_3, \ldots, q_n\). Now suppose

\[ q_1=a_1x+b_1 \quad q_2=a_2x+b_2 \ldots q_n=a_nx+b_n, \]

and solve the \(2n\) equations

\[ a_1x+b_1=+c_1 \quad a_2x+b_2=+c_2 \ldots a_{n-1}x+b_{n-1}=c_{n-1} \quad a_nx+b_n=c_n \]
\[ a_1x+b_1=-c_1 \quad a_2x+b_2=-c_2 \ldots a_{n-1}x+b_{n-1}=-c_{n-1} \quad a_nx+b_n=-c_n, \]

where \(c_1=1 \quad c_2=2 \quad c_3=2 \ldots \ldots c_{n-1}=2 \quad c_n=1.\)

Whenever in any one of the \(n\) pairs of equations above written the coefficient of \(x\) is positive, the upper equation of the pair will bring out the greater value of \(x\); but when the coefficient is negative the lower equation will give the greater value.

Take the pair

\[ a_ix+b_i=c_i \]
\[ a_ix+b_i=-c_i. \]

If \(a_i\) is positive \(a_ix+b_i\) will always be positive, and greater than \(c_i\) between \(x=\infty\) and \(x=\) the greater of the two values of \(x\); if \(a_i\) is negative \(a_ix+b_i\) will always be negative, and less (i.e. nearer to \(-\infty\)) than \(-c_i\) for all values of \(x\) between the same limits as before. So again it will be seen in like manner, that whether \(a_i\) be positive or negative between \(x=-\infty\) and \(x=\) the lesser of the two values of \(x\) corresponding to the above pair of equations, \(a_ix+b_i\) will always retain the same sign, and will be greater than \(+c_i\), or less than \(-c_i\), according as \(a_i\) is negative or positive. If, then, we take the greatest of the greater of the \(n\) pairs of values of \(x\), i.e. the absolute greatest of the \(2n\) values, and the least of the lesser, i.e. the absolute least of the same, say \(L\) and \(\Lambda\) between \(L\) and \(\Lambda\), \(q_1, q_2, \ldots, q_n\) will each always retain an invariable sign, and will then fall without the limits \(\pm c_1, \ldots, \pm c_{n-1}, \pm c_n\), so that between \(+\infty\) and \(L\) and between \(\Lambda\) and \(-\infty\), \(\mu_1, \mu_2, \ldots, \mu_n\), i.e. a constant multiple of \(f(x)\), will retain the
same sign as \( q_1, q_2, \ldots, q_n \), i.e. will never change its sign from the beginning to the end of one interval, nor from the beginning to the end of the other; and consequently \( L \) and \( A \) will be a superior and inferior limit respectively to the real roots of \( f(x) \). It will of course be observed that it is indifferent for the purposes of the foregoing theorem, whether \( \frac{f(x)}{\varphi x} \) be expanded under the form of a proper or an improper fraction, i.e. whether we employ the ordinary or the Sturmian process of successive division, for changing the signs of the residues will only have the effect of changing \( q_i \) into \( (\pm)q_i \), and the pair of equations \( (\pm)q_i = \pm c_i \) remains the same whether the \( + \) or the \( - \) sign be prefixed to \( q_i \). The result is, that if we form the \( 2n \) quantities

\[
\frac{\pm 1-b_1}{a_1}, \frac{\pm 2-b_2}{a_2}, \frac{\pm 3-b_3}{a_3}, \ldots \frac{\pm 2-b_{n-1}}{a_{n-1}}, \ldots \frac{\pm 1-b_n}{a_n},
\]

the greatest of them will be a superior, and the least of them an inferior limit to the roots of \( f(x) \).

It may be remarked, that if the successive dividends in the course of the process be multiplied respectively by \( k_1, k_2, \ldots, k_n \), \( \frac{f(x)}{\varphi x} \) will take the form

\[
\frac{k_1}{q_1} + \frac{k_2}{q_2} + \frac{k_3}{q_3} + \ldots + \frac{k_n}{q_n};
\]

and if we write \( a_ix + b_i = \pm c_i \), \( a_ix + b_i = \pm c_i \), \( \ldots \), \( a_ix + b_i = \pm c_i \)

and make \( c_1 = 1 \), \( c_2 = 1 + k_2 \), \( c_3 = 1 + k_3 \), \( \ldots \), \( c_n = 1 + k_n \),

the same reasoning as above will show the greatest and least of the \( 2n \) quantities

\[
\frac{\pm 1-b_1}{a_1}, \frac{\pm (1+k_2)-b_2}{a_2}, \ldots \frac{\pm (1+k_n)-b_{n-1}}{a_{n-1}}, \frac{\pm 1-b_n}{a_n}
\]

will be a superior and inferior limit to the roots of \( f(x) \).

For greater simplicity, again, consider \( k_1, k_2, \ldots, k_n \) to be all equal to unity; we may make this addition to the theorem as above stated, viz. calling \( L_1 \), \( A_1 \); \( L_2 \), \( A_2 \); \( \ldots \), \( L_n \), \( A_n \) the greatest and least values of the terms contained respectively in the series marked below 1, 2, 3...\( n \), viz.

\[
(1.) \quad \frac{\pm 1-b_1}{a_1}, \frac{\pm 2-b_2}{a_2}, \frac{\pm 2-b_3}{a_3}, \ldots \frac{\pm 2-b_{n-1}}{a_{n-1}}, \frac{\pm 1-b_n}{a_n}
\]

\[
(2.) \quad \ldots \quad \frac{\pm 1-b_2}{a_2}, \frac{\pm 2-b_3}{a_3}, \ldots \frac{\pm 2-b_{n-1}}{a_{n-1}}, \frac{\pm 1-b_n}{a_n}
\]

\[
(3.) \quad \ldots \quad \ldots \quad \frac{\pm 1-b_3}{a_3}, \ldots \frac{\pm 2-b_{n-1}}{a_{n-1}}, \frac{\pm 1-b_n}{a_n}
\]

\[
(n-1) \quad \ldots \quad \ldots \quad \ldots \quad \frac{\pm 1-b_{n-1}}{a_{n-1}}, \frac{\pm 1-b_n}{a_n}
\]

\[
(n.) \quad \ldots \quad \ldots \quad \ldots \quad \ldots \quad \frac{\pm 1-b_n}{a_n},
\]

* For a generalization and improved form of statement of this theorem see Supplement to the present Section.
L_1 \Lambda_2; L_2 \Lambda_3; ... L_n \Lambda_n will be respectively superior and inferior limits to \( f_x, \varphi x \) and their successive residues. As a corollary, we see, of course, that \( L \) and \( \Lambda \), the superior and inferior limit to the roots of the given function \( f_x \), must always lie between \( +\infty \) and the greatest root, and between \( -\infty \) and the least root, of the arbitrarily assumed function \( \varphi x \).

Art. (53.). Let us now assume somewhat more generally that \( \varphi x \) is any number of degrees \( \theta_1 \) in \( x \) lower than \( f_x \), which will cause the first quotient \( q_{\theta_1} \) to be of the degree \( \theta_1 \) in \( x \); and let us further suppose that \( \varphi x \) stands in such a relation to \( f_x \) that the following quotients, \( q_{\theta_2}, q_{\theta_3}, ... q_{\theta_p} \), are of the degrees \( \theta_2, \theta_3, ... \theta_p \) in \( x (\theta_2, \theta_3, ... \theta_p \) being supposed not necessarily units, as they would generally be, but any positive integers whatever, as may happen in consequence of one or more of the leading coefficients in any residue vanishing), then

\[
\frac{\varphi x}{f_x} = \frac{1}{q_{\theta_1}} + \frac{1}{q_{\theta_2}} + \frac{1}{q_{\theta_3}} + ... + \frac{1}{q_{\theta_p}},
\]

where \( \theta_1 + \theta_2 + \theta_3 + ... \theta_p = n \), and consequently \( f_x \) will be equal to the denominator of the last convergent above written, multiplied by a constant, so that we have now \( c \cdot f_x = m_1 \cdot m_2 \cdot ... \cdot m_p \), where

\[
m_1 = q_{\theta_1}, \quad m_2 = q_{\theta_2} + \frac{1}{m_1}, \quad ... \quad m_p = q_{\theta_p-1} + \frac{1}{m_{p-1}}.
\]

And as in the case previously considered, so long as

\[
\begin{align*}
q_{\theta_1} &amp; &gt; 1 \\
q_{\theta_2} &amp; &gt; 2 \\
q_{\theta_3} &amp; &gt; 2 \\
&amp; \vdots \\
q_{\theta_p} &amp; &gt; 1 \\
q_{\theta_1} &amp; &lt; -1 \\
q_{\theta_2} &amp; &lt; -2 \\
q_{\theta_3} &amp; &lt; -2 \\
&amp; \vdots \\
q_{\theta_p} &amp; &lt; -1
\end{align*}
\]

\( f_x \) will have the same sign as \( q_{\theta_1} \cdot q_{\theta_2} \cdot ... \cdot q_{\theta_p} \).

Let now

\[
q_{\theta_i} = \pm c_1, \quad q_{\theta_2} = \pm c_2, \quad ... \quad q_{\theta_p} = \pm c_p,
\]

where

\[
c_1 = 1, \quad c_2 = 2, \quad ... \quad c_{p-1} = 2, \quad c_p = 1.
\]

Consider any pair of the above equations as \( q_{\theta_i}^2 - c_i^2 = 0 \).

1st. Suppose all the roots of this equation are impossible, \( q_{\theta_i}^2 - c_i^2 \) must be positive for all values of \( x \), and \( q_{\theta_i} \) can never lie between \( +c_i \) and \( -c_i \); moreover, since upon the hypothesis made, \( q_{\theta_i} + c_i \) and \( q_{\theta_i} - c_i \) always retain the same sign, viz. that of the coefficient of the highest power of \( q_{\theta_i} \), it follows that \( q_{\theta_i} \) must also always retain the same sign; for if we construct the two curves \( y = q_{\theta_i} + c_i \) and \( y = q_{\theta_i} - c_i \), these will both lie on the same side of the axis of \( x \), and never cut the axis, consequently the curve \( y = q_{\theta_i} \), which lies between them, must also lie on the same side as either of them, and never cut the axis.

Hence, then, if the roots of the equation are all impossible, \( q_{\theta_i} \) will always retain the same sign, and will never fall within the region bounded on its two sides by \( +c_i \) and \( -c_i \).

2nd. Suppose the equation to have one or more possible roots, and \( l_i \) to the greatest, and \( \lambda_i \) the least (which of course, if there is but one possible root, will be identical). If
the leading coefficient of \( q_i \) is positive, the greatest root (\( l \)) of the equation \( q_i - c = 0 \) will exceed the greatest root of (\( l&#x27; \)) of the equation \( q_i + c = 0 \); for between \( x = \infty \) and \( x = l&#x27; \), \( q_i \) must go through all values intermediate between \( \infty \) and \(-c_i\); hence there must be a quality \( l \) intermediate between \( l&#x27; \) and \( +\infty \), which will make \( q_i = c_i \). In like manner, if the leading coefficient of \( q_i \) is negative, it will be seen that the greatest root of \( q_i + c = 0 \) will exceed that of \( q_i - c = 0 \). Moreover, in the one case \( q_i \) will be always positive and greater than \( c_i \), and in the other always negative, and less than \( c_i \). In every case, therefore, between \( +\infty \) and \( l_i \), \( q_i \) retains the same sign, and does not fall within the region bounded by \( +c_i \) and \(-c_i\); the same thing may be shown to be true for all values of \( x \) between \(-\infty \) and \( \lambda_i \). Hence, then, by the same reasoning as that employed in the preceding article, we are enabled to affirm, that if we form the equation

\[
(q_{i_1}^2 - 1)(q_{i_2}^2 - 4)(q_{i_3}^2 - 4)\ldots(q_{i_p}^2 - 4)(q_{i_q}^2 - 1) = 0, \ldots \ldots \ldots \quad (\psi)
\]

its greatest root will be a superior limit, and its least root an inferior limit to the roots of the equation \( f(x) = 0 \), whatever be the value of the assumed function \( \varphi x \); and if the above equation (\( \psi \)) has no real root, all the roots of \( f(x) \) will be imaginary.

Art. (54.). In the preceding two articles it has been supposed that all the quotients are taken integral functions of \( x \); but the process of successive division may be so conducted as to give rise to quotients of the form

\[
ax^i + bx^{i-1} + \ldots + c + \frac{d}{x} + \ldots + \frac{l}{x^i}.
\]

Suppose then that we have in general

\[
\frac{\varphi x}{f(x)} = \frac{1}{q_1} + \frac{1}{q_2} + \ldots + \frac{1}{q_w},
\]

where \( q_1, q_2, \ldots, q_w \) are each of the general form above written (but of course \( i \) and \( i&#x27; \) being not necessarily the same for any two of the quotients), and suppose that the sum of the degrees in \( x \) of \( q_1, q_2, \ldots, q_w \) is \( n + t \), where \( t \) is essentially (as it must be) positive. Then we shall find, as in the last article, that \( L \) and \( \Lambda \) being called the greatest and least roots of \((q_1^2 - 1)(q_2^2 - 4)\ldots(q_{n-1}^2 - 4)(q_n^2 - 1)\), \( D \) the denominator of the last convergent to the continued fraction above written, will never change its sign between \( +\infty \) and \( L \), nor between \( \Lambda \) and \(-\infty \); but here we shall have

\[
f(x) = Kx^t \times D.
\]

Hence \( x^t \cdot D \) will be invariable in sign within each of these two intervals.

1st. Let \( t \) be even; then \( f(x) \) will be invariable in sign, whatever \( L \) and \( \Lambda \) may be for each such interval.

2nd. Let \( t \) be odd; then if \( L &gt; 0 \) and \( \Lambda &lt; 0 \), \( f(x) \) cannot change its sign in either interval; but if \( L &lt; 0 \) or \( \Lambda &gt; 0 \), \( f(x) \) will change its sign as \( x \) passes through zero, but will be invariable for each of the three regions contained between \( +\infty \) and \( L \), \( L \) and 0, or 0 and \( \Lambda \) (as the case may be), and \( \Lambda \) and \(-\infty \); so that universally \( L \) and \( \Lambda \) will be a superior and inferior limit to the roots of \( f(x) \), making abstraction of the roots (if any such there be in \( f(x) \)) whose value is zero.

Art. (55.). I shall close this section with offering (for what it is worth) a bare
suggestion as to the mode in which the theory of Intercalations may hereafter be found to admit of being extended from a system of two general functions of \( x \), to a system of three general functions of \( x, y \), four general functions of \( x, y, z \), and in general to a system of \( s \) general functions of \( s-1 \) variables, or which is the same thing, of \( s \) homogeneous functions of \( s \) variables. In the case of two functions of \( x, f(x) \) and \( \varphi x, f(x)=0 \) and \( \varphi x=0 \) may be considered to represent two systems of points in a right line; and the theory relates in this case to the relative positions of these two &quot;Kenothemes&quot; or point systems; and of course using \( x \) and \( y \) to denote the distances of any point in a line from two fixed points therein respectively, instead of \( fx \) and \( \varphi x \), we may employ two homogeneous functions of \( x \) and \( y \), as \( f(x, y) \) and \( \varphi (x, y) \), to denote these two systems of points. So, similarly, if we have three functions of two variables, \( f(x, y), g(x, y), h(x, y) \), which I shall suppose to be of the same degree, we may consider the mutual relations of the Monothemes, that is to say, the three plane curves, denoted by the equations \( f(x, y)=0, g(x, y)=0, h(x, y)=0 \). Now every two of these will intersect one another in a system of points, which we may call \((f,g)\) for the intersections of \( f \) and \( g \), \((g,h)\) for those of \((g\) and \(h)\), and \((h,f)\) for those of \( h \) and \( f \). If we take any two of these systems of intersections, as \((f,g)\) and \((g,h)\), they will both lie upon one of the given curves \((g)\). And by reading off the two systems of points \((f,g)\) and \((g,h)\), arranged according to the order upon which they are disposed upon the curve \( g \), we may, by following the course of such curve, form a scale of effective intercalations for these two systems, and in like manner for the two systems \((g,h)\) and \((h,f)\); \((h,f)\) and \((f,g)\). Now I believe that it will be found that when \( f, g, h \) represent any algebraical curves consisting of a single continuous line, either extending to infinity in both directions, or returning to itself (and I have fully satisfied myself of the truth of this for the case of ellipses), each effective scale of intercalation will contain the same number of pairs of points; if, however, the curves consist of more than one branch, as if hyperbolæ be considered, such is no longer necessarily the case; from these facts, conjoined with the light thrown upon the subject by its relation to the theory of combinants explained in the succeeding section, I am induced to infer the probability of the truth of the following law (which, for avoidance of further uncertainty, I confine to the case of functions of the same degree), viz. that if \( f, g, h \) be three homogeneous functions of \( x, y, \) and \( z \) of the same degree, and if \( U, V, W \) be any three linear functions of \( f, g, h \), and if \( U=0, V=0, W=0 \) be treated as the equations to three cones, and if we form an effective scale of the intercalations of the lines of intersection of \( U \) and \( W \), and \( V \) and \( W \), according to the order in which they are disposed upon \( W \) (which seems to require that the lines shall be continuous, in order to admit of a fixed order of reading off the intersections of any two of them upon the third); then whatever value may have been given to the coefficients in the linear functions the number of elements remaining in any such scale will (as I conjecture) be constant, and some theory (to be discovered) for three functions analogous to that of Bezoutian residues for two functions will serve to determine the

MDCCCLIII.

3 T
number of the elements so remaining. And so, in like manner, but with a difficulty increasing at each step (as at the next step we should have to pass into quasi-space of four dimensions), a theory of intercalations may be conjectured to exist for any \((n)\) general functions of any \((n-1)\) variables.

**Development of the method of assigning a superior and inferior limit to the roots of any algebraical equation.**

Art. (a.). Since the articles in the preceding part of this section on the method of discovering limits to the roots of an algebraical equation were written, the method of which the germ is therein contained has presented itself in a much more fully developed form, which I proceed to exhibit: for greater simplicity I shall suppose \(f x\) to be of \(n-1\), and \(f x\) to be of \(n\) dimensions in \(x\), and that by means of the ordinary process for common measure (except that as in Sturm’s theorem the sign of all the remainders are changed) \(\frac{f x}{f x}\) has been thrown under the form of the improper continued fraction

\[
\frac{1}{q_1 - \frac{1}{q_2 - \frac{1}{q_3 - \cdots q_n}}},
\]

where \(q_1, q_2, \ldots q_n\) are all restricted to signify simple linear functions of \(x\).

Suppose the series \(q_1, q_2, q_3, \ldots q_n\) to be resolved into the distinct sequences

\[q_1 q_2 \ldots q_i; \quad q_{i+1} q_{i+2} \ldots q_v; \quad q_{v+1} \ldots q_{v+1} \ldots \ldots q_n,\]

in such a manner that in each sequence as \(q_{i+1} q_{i+2} \ldots q_v\) the coefficients of \(x\) have all the same sign, but that in any two adjoining sequences the coefficients of \(x\) have opposite signs, so that for instance in \(q_i\) and \(q_{i+1}\) the coefficients of \(x\) are unlike, as also in \(q_v\) and \(q_{v+1}\); there will of course be nothing to preclude any of these sequences becoming reduced to a single term.

The first theorem is, that the greatest and least roots of the product of the cumulants

\[\left[q_1 q_2 \ldots q_i\right] \times \left[q_{i+1} q_{i+2} \ldots q_v\right] \ldots \times \left[q_{(i)+1} q_{(i)+2} \ldots q_n\right]\]

are superior and inferior limits to the roots of \(f x\). To prove this theorem I begin with premising the two following lemmas, one virtually and the other expressly contained in the Philosophical Magazine for the months of September and October of the present year*.

* Each of these two lemmata flows readily from the faculty previously adverted to engaged by every cumulant of being representable under the form of a determinant. As to the second lemma, it becomes apparent immediately when the cumulant is so represented, by separating the matrix into two rectangles and expressing the entire determinant according to a well-known rule for the decomposition of determinants as a function of the determinants belonging to these two rectangles taken separately. As to the first lemma, by reason of the cumulant \([\omega_1 \omega_2 \ldots \omega_{i-1} \omega_i \omega_{i+1}]\) being so representable, we know that when \([\omega_1 \omega_2 \ldots \omega_{i-1} \omega_i]=0, [\omega_1 \omega_2 \ldots \omega_{i-1}]\) and \([\omega_1 \omega_2 \ldots \omega_{i+1}]\) must have opposite signs. Suppose, now, that the theorem is true when the number of elements in the type does not exceed \(i\); then the roots of \([\omega_1 \omega_2 \ldots \omega_{i-1}]\), say of \(\psi_{i-1}\), being called \(h_1, h_2, \ldots h_{i-1}\), and of \([\omega_1 \omega_2 \ldots \omega_{i-1} \omega_i]\), say of \(\psi_i\), being called \(k_1, k_2, \ldots k_i\), these may be arranged in the following order of
Lemma A. The roots of the cumulant \([q_1, q_2, \ldots, q_i]\), in which each element is a linear function of \(x\), and wherein the coefficient of \(x\) for each element has the like sign, are all real, and between every two of such roots is contained a root of the cumulant \([q_1, q_2, \ldots, q_{i-1}]\), and ex converso a root of the cumulant \([q_1, q_2, \ldots, q_i]\), and (as an evident corollary) for all values of \(g\) and \(g&#x27;\) intermediate between 1 and \(i\) the greatest root of \([q_1, q_2, \ldots, q_{i-1}, q_i]\) will be greater, and the least root of the same will be less than the greatest and least roots respectively of \([q_1, q_2, \ldots, q_{i-1}, q_i]\).

Lemma B. For all values of the elements \(q_1, q_2, \ldots, q_n\), the cumulant

\[
[q_1, q_2, \ldots, q_{n-1}, q_n, q_{n+1}, q_{n+2}, \ldots, q_n] = [q_1, q_2, \ldots, q_{n-1}, q_n] \times [q_{n+1}, q_{n+2}, \ldots, q_n]
\]

Thus ex gr. the cumulant \([abcd]\), i.e. \(abcd - ab - cd - ad + 1\),

\[
= [ab] \times [cd] - [a] \times [d] = (ab - 1)(cd - 1) - ad,
\]

and \([abcde]\), i.e. \(abcde - abc - ade - ade - cde + a + c + e = [abc][ae] - [ab][e]\),

\[
i.e. = (abc - a - c)(de - 1) - (ab - 1)e.
\]

Art. (3.). Now suppose that \(q_1, q_2, \ldots, q_{n-1}, q_n\) are all linear functions of \(x\), and that the coefficients of \(x\) have all one (say the positive) sign in \(q_1, q_2, \ldots, q_n\), and all the contrary signs in \(q_{n+1}, \ldots, q_n\), and let \(L\) be not less than the greatest root of \([q_1, q_2, \ldots, q_n]\) or of \([q_{n+1}, \ldots, q_n]\), and also let \(\Lambda\) be not greater than the least root of each of these same two cumulants; then by lemma A, \(L\) and \(\Lambda\) will also be respectively greater than the greatest, and less than the least roots of \([q_1, q_2, \ldots, q_{n-1}]\) and of \([q_{n+1}, \ldots, q_n]\). Now the coefficient of the highest power of \(x\) in both \([q_1, q_2, \ldots, q_n]\) and in \([q_1, q_2, \ldots, q_{n-1}]\) is positive, but as to \([q_{n+1}, \ldots, q_n]\) and \([q_{n+2}, \ldots, q_n]\) is of contrary signs in the two, viz. negative in that one of those cumulants which contains an odd, and positive in that one of the two which contains an even number of elements. Hence by virtue of Lemma B, \(L\) and any quantity greater than \(L\) substituted for \(x\) will make \([q_1, q_2, \ldots, q_n]\) to have always the same sign, and in like manner it may be shown that \(\Lambda\) and any quantity less than \(\Lambda\) substituted for \(x\) will also cause \([q_1, q_2, \ldots, q_n]\) to retain always the same sign. Hence \(L\) and \(\Lambda\) are superior and inferior limits to \([q_1, q_2, \ldots, q_n]\); and the same reasoning would magnitude \(k_1 h_1 k_2 h_3 k_4 \ldots k_{i-1} h_{i-1} k_i\); and if the roots of \([\omega_1, \omega_2, \ldots, \omega_{i-1}, \omega_i, \omega_{i+1}]\), say of \(\psi_{i+1}\), be called \(l_1, l_2, \ldots, l_{i+1}\), from the fact of the leading coefficients in \(\psi_{i-1}\) and \(\psi_{i+1}\) expanded according to the powers of \(x\) having the same sign, it follows that when \(x = \infty\), \(\psi_{i-1}\) and \(\psi_{i+1}\) have the same sign, but they have contrary signs when \(x = k\); but \(\psi_{i-1}\) does not change its sign between \(x = \infty\) and \(x = k\), hence \(\psi_{i+1}\) does change its sign between \(x = \infty\) and \(x = k\), and therefore a root of \(\psi_{i+1}\) lies between \(\infty\) and \(k\); in like manner precisely it may be shown that a root of \(\psi_{i+1}\) lies between \(-\infty\) and \(k\); and since \(\psi_{i-1}\) changes its sign between \(k_1\) and \(k_2\), between \(k_2\) and \(k_3\), \ldots, \(k_i\), and between \(k_{i-1}\) and \(k_i\), \(\psi_{i+1}\) must likewise change its sign between one and the other extremity of each of these intervals, and hence the roots \(l_1, l_2, \ldots, l_{i+1}\) are intercalated between \(\infty, k_1, k_2, \ldots, k_i, -\infty\), or which is the same thing, \(k_1, k_2, \ldots, k_i\) are respectively intercalated between \(l_1, l_2, \ldots, l_{i+1}\); consequently, if the theorem is true up to \(i\), it is true for \(i+1\), and therefore true universally; but is manifestly true when \(i = 2\), for then \(x = \pm \infty\) makes \([\omega_1, \omega_2]\), i.e. \(\omega_1 \omega_2 - 1\) positive; but \(\omega_1 = 0\) makes it negative, which proves the theorem contained in Lemma A.

3 T 2
evidently apply if we had supposed the signs of the coefficients of \( x \) in the first partial series of elements to have been negative, and in the other series of elements to have been positive.

The greatest and least roots of \([q_1 q_2 \ldots q_n] \times [q_{n+1} \ldots q_n]\) evidently satisfy the condition to which \( L \) and \( \Lambda \) are subject, and may be taken in place of \( L \) and \( \Lambda \) respectively. They will accordingly be superior and inferior limits to the cumulant

\[
[q_1 q_2 \ldots q_n q_{n+1} \ldots q_n].
\]

Again, by virtue of theorem (B.) it may readily be shown that

\[
[q_1 q_2 \ldots q_{n-1} q_{n+1} q_{n+2} \ldots q_n] = [q_1 q_2 \ldots q_{n-1}] \times [q_{n+1} q_{n+2} \ldots q_n] \times [q_{n+1} \ldots q_n]
\]

\[
-[q_1 q_2 \ldots q_{n-1}] \times [q_{n+1} \ldots q_n] \times [q_{n+1} \ldots q_n]
\]

\[
-[q_1 q_2 \ldots q_{n-1}] \times [q_{n+1} \ldots q_n] \times [q_{n+1} \ldots q_n]
\]

\[
+[q_1 q_2 \ldots q_{n-1}] \times [q_{n+1} \ldots q_n] \times [q_{n+1} \ldots q_n];
\]

and hence if \( q_1 q_2 \ldots q_n \) are all linear functions of \( x \) in which the coefficients of \( x \) have all the same algebraical sign in any one (taken per se) of the three series

\( q_1 q_2 \ldots q_{n-1}; \quad q_{n+1} \ldots q_n; \quad q_{n+1} \ldots q_n; \)

but so that this sign changes in passing from one series to another, it is easily seen, by the same reasoning as in the preceding case, that the two positive and two negative products on the right-hand side of the equation all give the same sign to the coefficient of the highest power of \( x \), and consequently that if \( L \) and \( \Lambda \) be superior and inferior limits to

\[
[q_1 \ldots q_{n-1}], \quad [q_{n+1} \ldots q_n], \quad [q_{n+1} \ldots q_n],
\]

and consequently by Lemma A, to

\[
[q_1 q_2 \ldots q_{n-1}], \quad [q_{n+1} \ldots q_n], \quad [q_{n+1} \ldots q_n], \quad [q_{n+1} \ldots q_n], \quad \text{and to } [q_{n+2} \ldots q_n],
\]

\( L \) or \( \Lambda \) substituted for \( x \) will cause \([q_1 q_2 \ldots q_n]\) to retain always the same sign, and will consequently be superior and inferior limits thereto; and so in general; whence it follows, returning to the theorem to be demonstrated, that the greatest and least roots of

\[
[q_1 q_2 \ldots q_i] \times [q_{i+1} q_{i+2} \ldots q_n] \times \ldots \times [q_{n+1} \ldots q_n],
\]

will be superior and inferior limits to the cumulant \([q_1 q_2 \ldots q_n]\), i.e. to \( C.fx^* \), and therefore to \( fx \), as was to be proved.

* If \( \frac{\phi x}{fx} \) expanded as a continued fraction by means of the common measure process gives rise to the quotients \( q_1, q_2, \ldots, q_n \), and if \( L_1, L_2, \ldots, L_{n-1}, L_n \) be the leading coefficients of the successive simplified residues, \((L_n\) being, in fact, the final simplified residue, i.e. the resultant to \( \phi x, fx \)), we must have \( \phi x = C[q_1, q_2, \ldots, q_n] \)

\[
fx = C[q_1, q_2, \ldots, q_n],
\]

where (supposing \( \phi x \) to be of \( n-1 \), and \( fx \) of \( n \) dimensions in \( x \)),

\[
C = \frac{1}{L_n} \left\{ \begin{array}{c}
L_n^2 \cdot L_{n-2}^2 \cdot L_{n-4}^2 &amp; \text{etc.} \\
L_{n-1}^2 \cdot L_{n-3}^2 \cdot L_{n-5}^2 &amp; \text{etc.}
\end{array} \right\}.
\]
Art. (γ.). The second theorem is the following: if \( q_1, q_2, \ldots, q_n \) be linear functions of \( x \), say \( a_1x + b_1, a_2x + b_2, \ldots, a_nx + b_n \), in which the coefficients of \( x \) have all the same sign, and if we take the quantities \( \mu_1, \mu_2, \ldots, \mu_{n-1} \), all having the same sign as \( a_1, a_2, \ldots, a_n \), but otherwise arbitrary, and make

\[
k_1 = \mu_1, \quad k_2 = \frac{\mu_2}{\mu_1}, \quad k_3 = \frac{\mu_3}{\mu_2}, \ldots, k_{n-1} = \frac{\mu_{n-1}}{\mu_{n-2}}, \quad k_n = \frac{1}{\mu_n},
\]

then the greatest of the quantities

\[
\frac{k_1 - b_1}{a_1}, \quad \frac{k_2 - b_2}{a_2}, \ldots, \frac{k_n - b_n}{a_n},
\]

say \( L \), is a superior limit, and the least of the quantities

\[
\frac{-k_1 - b_1}{a_1}, \quad \frac{-k_2 - b_2}{a_2}, \ldots, \frac{-k_n - b_n}{a_n},
\]

say \( \Lambda \), is an inferior limit to the roots of \( f(x) \).

\( L \) and any value greater than \( L \) substituted for \( x \) will evidently make \( q_1 - k_1; q_2 - k_2; \ldots; q_n - k_n \), all of them positive.

Hence when \( x = \) or \( &gt; L \) \( q_1 \) is positive and \( &gt; \mu_1 \), and

\[
q_2 - \frac{1}{q_1} &gt; k_2 - \frac{1}{\mu_1} &gt; \mu_2 + \frac{1}{\mu_1} - \frac{1}{\mu_1}, \text{i.e. is positive, and } &gt; \mu_2,
\]

\[
q_3 - \frac{1}{q_2} &gt; k_3 - \frac{1}{\mu_2} &gt; \mu_3 + \frac{1}{\mu_2} - \frac{1}{\mu_2}, \text{i.e. is positive, and } &gt; \mu_3,
\]

and consequently the cumulant \([q_1, q_2, q_3, \ldots, q_n]\), which

\[
= q_1 \times \left( q_2 - \frac{1}{q_1} \right) \times \left( q_3 - \frac{1}{q_2} - \frac{1}{q_1} \right) \times \&amp;c.,
\]

remains of a constant sign when \( L \) and any quantity greater than \( L \) is substituted for \( x \). Hence \( L \) is a superior limit. In like manner \( \Lambda \) and any quantity less than \( \Lambda \) will evidently make \( q_1 + k_1, q_2 + k_2; \ldots; q_n + k_n \) all of them negative, so that when \( x = \) or \( &lt; \Lambda \) \( q_1 \) is negative, and \( &lt; -\mu_1 \)

\[
q_2 - \frac{1}{q_1} &lt; k_2 - \frac{1}{\mu_1} \text{ is negative, and } &lt; -\mu_2,
\]

\[
q_3 - \frac{1}{q_2} &lt; k_3 - \frac{1}{\mu_2} \text{ is negative, and } &lt; -\mu_3,
\]

and \( q_n - \frac{1}{q_{n-1}} - \frac{1}{q_{n-2}} \ldots \frac{1}{q_1} &lt; \frac{1}{\mu_{n-1}} - \frac{1}{\mu_{n-1}} \text{ is negative.} \)
So that \([q_1 q_2 \ldots q_n]\) for all values of \(x\) less than \(\Lambda\) will preserve an invariable sign, and consequently \(\Lambda\) is an inferior limit to \(fx\).

Art. (δ.). It may be remarked that the quantities

\[
\mu_1; \frac{\mu_1}{\mu_1}; \frac{\mu_2}{\mu_2}; \ldots \frac{\mu_{n-2}}{\mu_{n-3}}; \frac{\mu_{n-1}}{\mu_{n-2}}; \frac{1}{\mu_{n-1}}
\]

may be derived successively from one another, according to the same law, from whichever end of the series we begin.

If we take any two consecutive terms as

\[
\mu_i + \frac{1}{\mu_{i-1}}; \mu_{i+1} + \frac{1}{\mu_i},
\]

the effect of diminishing \(\mu_i\) is to decrease the first of these two terms, and pro tanto, to tend to deduce the limit; but on the other hand, \(\frac{1}{\mu_i}\) being increased, there is brought into play an opposite tendency, which operates pro tanto to increase the value of the limit.

Art. (ε.). It is of importance to remark, that by a right selection of the system of quantities \(\mu_1, \mu_2, \ldots \mu_{n-1}\), which enter into the composition of \(k_1 k_2 \ldots k_n\), \(L\) may be made to coincide with the greatest root of \([q_1 q_2 \ldots q_n]\); and so in like manner by a right selection of another system of these quantities, whereby to form \(k_1 k_2 \ldots k_n\), \(\Lambda\) may be made to coincide with the least root of the same. Thus let \(\mu_1, \mu_2, \ldots \mu_{n-1}\) be so chosen, that

\[
q_1 - k_1 = 0 \quad q_2 - k_2 = 0 \ldots q_n - k_n = 0
\]

are all satisfied by the same value of \(x\).

Then

\[
q_1 = \mu_1 \quad q_2 = \mu_2 + \frac{1}{\mu_1} \quad q_3 = \mu_3 + \frac{1}{\mu_2} \ldots q_n = \frac{1}{\mu_{n-1}}
\]

exist simultaneously.

Hence

\[
\mu_2 = q_2 - \frac{1}{q_1} \quad \mu_3 = q_3 - \frac{1}{\mu_2} = q_3 - \frac{1}{q_2} - \frac{1}{q_1}
\]

\[
\mu_{n-1} = q_{n-1} - \frac{1}{q_{n-2}} - \frac{1}{q_{n-3}} \ldots \frac{1}{q_1}
\]

\[
q_n = \frac{1}{q_{n-1}} - \frac{1}{q_{n-2}} - \ldots \frac{1}{q_1},
\]

which is satisfied by making \([q_n q_{n-1} q_{n-2} \ldots q_1] = 0\).

It remains then only to show that the greatest root of \(x\) in this equation substituted for \(x\) in \(q_1, q_2, \ldots q_n\) will make \(\mu_1, \mu_2, \ldots \mu_{n-1}\) all of one sign, and that the least root of \(x\) similarly substituted, will also make them all of one, but a contrary sign, which may be proved as follows.

We have

\[
\mu_1 = q_1 \quad \mu_2 = [q_1 q_2] \div q_1 \quad \mu_3 = [q_1 q_2 q_3] \div [q_1 q_2] \text{ &amp;c. } \mu_{n-1} = [q_1 q_2 \ldots q_{n-1}] \div [q_1 q_2 \ldots q_{n-2}];
\]

and by Lemma B the superior limit to \([q_1 q_2 \ldots q_n]\) will be a superior limit also to \(q_1, q_2, q_3, \ldots, q_{n-2}\), and to \([q_1 q_2], [q_1 q_2 q_3], \ldots, [q_1 q_2 \ldots q_{n-1}]\).
Consequently this superior limit will make \( \mu_1, \mu_2, \ldots, \mu_{n-1} \) have all the same sign as that of the coefficients of \( x \) in \( q_1, q_2, \ldots, q_n \). And in like manner, the inferior limit to \([q_1, q_2, \ldots, q_n]\) will cause \( \mu_1, \mu_2, \ldots, \mu_{n-1} \) to have all the contrary sign to that of these coefficients.

Thus then we see that when the coefficients of \( x \) in the partial quotients to \( \frac{\varphi x}{f x} \) expressed as an improper continued fraction form a single series of continuations of signs, by a right choice of the arbitrary constants \( \mu_1, \mu_2, \ldots, \mu_{n-1} \), the superior or inferior limit given by this new method may severally and separately be made to coincide with the greatest and least real root, or each in turn with the sole real root of \( f x \), if there be but one.

Art. (\(\zeta\)). The general method of enclosing the roots of \( f x \) within limits is founded upon the combination of the two theorems above demonstrated. An arbitrary function \( \varphi x \) one degree in \( x \) below, \( f x \) being assumed, and by aid of the auxiliary function \( \varphi x, f x \) being thrown under the form

\[ C[q_1, q_2, \ldots, q_i, q_1&#x27;, q_2&#x27;, \ldots, q_i&#x27;, \ldots, (q)_1, (q)_2, \ldots, (q)_i], \]

in which the coefficient of \( x \) is supposed to change sign in the passage from \( q_i \) to \( q_i&#x27; \), from \( q_i&#x27; \) to \( q_i&#x27;&#x27; \), &amp;c., a superior limit is found to each of the cumulants

\[ [q_1, q_2, \ldots, q_i], \quad [q_1&#x27;, q_2&#x27;, \ldots, q_i&#x27;], \quad \ldots \quad [(q)_1, (q)_2, \ldots, (q)_i], \]

taken separately, by means of the second theorem, and then by virtue of the first theorem the greatest of these superior limits is a superior limit to the cumulant

\[ [q_1, q_2, \ldots, q_i, \ldots, (q)_1, \ldots, (q)_i], \]

and consequently to \( f x \), and so mutatis mutandis the least of the inferior limits of the same partial cumulants is an inferior limit to the total cumulant

\[ [q_1, q_2, \ldots, q_i, \ldots, (q)_1, (q)_2, \ldots, (q)_i]. \]

Art. (\(\eta\)). When all the roots of \( f x \) are real, if \( \varphi x \) be so assumed that all its roots are intercalated between those of \( f x \), the partial quotients to \( \frac{\varphi x}{f x} \) will form but one single series. In order that \( \varphi x \) may fulfill this condition, it is necessary that the coefficients of \( \varphi x \) shall be subject to certain conditions of inequality, not necessary here to be investigated; but no conditions of equality, i.e. no equations between the coefficients of \( \varphi x \), are introduced by this condition; or in other words, the coefficients* of \( \varphi x \), the auxiliary function, are independent and arbitrary within limits; and we have shown that in this case the auxiliary constants \( \mu_1, \mu_2, \ldots, \mu_{n-1} \) may be so determined that the limits may be made to come separately and respectively into contact with the two extreme roots. When all the roots of \( f x \) are not real, the quotients (however \( \varphi x \) is chosen) can no longer be made to form a single series. It still however remains true, that, by a due choice of the auxiliary function followed by a due choice of the

* It need scarcely be stated that \( f&#x27;x \) is the simplest form of \( \varphi x \), which satisfies the condition in question.
auxiliary constants, this coincidence may be brought about, so long as there is a single real root in \( f(x) \).

It is rather important to demonstrate this universal possibility of effecting a coincidence of the limits to the roots with the extreme roots themselves, because it is the most striking feature which distinguishes the method of limitation here developed from all others previously brought to light.

Art. (b.). Before entering upon this demonstration I may make the passing remark, that every method of root-limitation is implicitly a method of root-approximation.

For instance, let \( e \) be any given quantity between which and \( +\infty \) it is known that a root of \( f(x) \) lies. Then if we write \( x = e + \frac{1}{y} \), and form the equation \( y^n f(e + \frac{1}{y}) = 0 \), and find \( L \) a superior limit to \( y \), it is clear that \( e + \frac{1}{L} \) will lie between \( e \) and the root of \( f(x) \) say \( E \), next superior to \( e \). Again, making \( x = e + \frac{1}{L} + \frac{1}{L&#x27;} \), and finding a superior limit \( L&#x27; \) to \( y&#x27; \), we shall have \( e + \frac{1}{L} + \frac{1}{L&#x27;} \) still nearer to \( E \) than \( e + \frac{1}{L} \) was; and so we may proceed advancing nearer and nearer, and always from the same side towards \( E \) at each step, and finally obtain \( E \) under the form \( e + \frac{1}{L} + \frac{1}{L&#x27;} + \frac{1}{L&#x27;&#x27;} + \ldots \) &amp;c. And in like manner calling \( E_i \) the root next below \( e \), we may find \( E_i = e - \frac{1}{\Lambda} - \frac{1}{\Lambda&#x27;} - \frac{1}{\Lambda&#x27;&#x27;} + \ldots \) &amp;c.

Art. (i.). In establishing the theorem of coincidence above adverted to, the following notation will be found very advantageous. Let \( \Omega \) denote a Type of any number of Elements, as \( q_1, q_2, \ldots, q_{i-1}, q_i \), and let \( \Omega&#x27; \) denote this same type when the last element, and \( &#x27; \Omega \) the same type when the first element is cut off, and \( &#x27; \Omega&#x27; \) the same type when both extremes are cut off, so that the apocopated type \( \Omega&#x27; \) will mean \([q_1, q_2, \ldots, q_{i-1}]\); the apocopated type \( &#x27; \Omega \) will mean \([q_2, q_3, \ldots, q_i]\), and the doubly apocopated type \( &#x27; \Omega&#x27; \) will mean \([q_2, q_3, \ldots, q_{i-1}]\).

If now a type \( \Omega \) be made up of the types \( \Omega_1, \Omega_2, \ldots, \Omega_i \) put in apposition, and if we use in general \([\Omega]\) to denote the cumulant corresponding to the type \( \Omega \), there will be a very simple law* connecting \([\Omega]\) with

\[
[\Omega_1][\Omega_2][\Omega_3] \ldots [\Omega_{i-2}][\Omega_{i-1}][\Omega_i]
\]

\[
[\Omega&#x27;_1][\Omega&#x27;_2][\Omega&#x27;_3] \ldots [\Omega&#x27;_{i-2}][\Omega&#x27;_{i-1}]
\]

\[
[&#x27;\Omega_2][&#x27;\Omega_3] \ldots [&#x27;\Omega_{i-2}][&#x27;\Omega_{i-1}][&#x27;\Omega_i]
\]

\[
[&#x27;\Omega&#x27;_2][&#x27;\Omega&#x27;_3] \ldots [&#x27;\Omega&#x27;_{i-2}][&#x27;\Omega&#x27;_{i-1}].
\]

This law will be seen to be obviously deducible by successive steps of expansion

* The cumulant corresponding to any portion or fragment of a type may be said to be a partial cumulant to the entire type, and a type whose elements are constituted out of the elements of two or more types placed in juxtaposition may be said to be the aggregate of these types; the law given in the text above may then be said to have for its object the expansion of the complete cumulant to any type in terms of complete and partial cumulants to the types of which the given type is the aggregate.
from the fundamental theorem given in Lemma (B.) art. (i.), for the case of \( \Omega = \Omega_1 \Omega_2 \), and will be best understood by showing its operation in a few simple cases.

Thus let \( \Omega = \Omega_1 \Omega_2 \ast \).

Then

\[
[\Omega] = [\Omega_1] \times [\Omega_2] - [\Omega&#x27;_1] \times [\Omega&#x27;_2].
\]

Let \( \Omega = \Omega_1 \Omega_2 \Omega_3 \).

Then

\[
[\Omega] = [\Omega_1] \times [\Omega_2] \times [\Omega_3]
- [\Omega&#x27;_1] \times [\Omega&#x27;_2] \times [\Omega&#x27;_3] - [\Omega_1] \times [\Omega&#x27;_2] \times [\Omega&#x27;_3]
+ [\Omega&#x27;_1] \times [\Omega&#x27;_2] \times [\Omega&#x27;_3].
\]

Let \( \Omega = \Omega_1 \Omega_2 \Omega_3 \Omega_4 \).

Then

\[
[\Omega] = [\Omega_1] \times [\Omega_2] \times [\Omega_3] \times [\Omega_4]
- [\Omega&#x27;_1] \times [\Omega&#x27;_2] \times [\Omega&#x27;_3] \times [\Omega&#x27;_4] - [\Omega_1] \times [\Omega&#x27;_2] \times [\Omega&#x27;_3] \times [\Omega&#x27;_4]
+ [\Omega&#x27;_1] \times [\Omega&#x27;_2] \times [\Omega&#x27;_3] \times [\Omega&#x27;_4].
\]

and so in general if \( \Omega = \Omega_1 \Omega_2 \ldots \Omega_i \), \( [\Omega] \) may be expanded under the form of the sum of \( 2^{i-1} \) products separable into \( i \) alternately positive and negative groups containing respectively 1, \( (i-1) \frac{i-2}{2}, \ldots (i-1), 1 \) products.

Art. (z.). In every one of the above groups forming a product the accents enter in pairs and between contiguous factors, it being a condition that if any \( \Omega \) have an accent on the right the next \( \Omega \) must have one on the left, and if it have one on the left the preceding \( \Omega \) must have an accent on the right, and the number of pairs of accents goes on increasing in each group from 0 to \( i-1 \). This rule serves completely to define the development in question.

* The sign of equality is employed here to denote the relation between a concrete whole and the aggregate of its parts.

† The number of distinct factors entering into these products, taken collectively, is evidently \( i + 2(i-1) + (i-2) \), i.e. \( 4(i-1) \).

‡ When each partial type \( \Omega \) consists of a single element, every doubly accented \( \Omega \) will vanish, and every singly accented \( \Omega \) will become unity; hence we may derive the rule for the expansion of the cumulant \( [a_1 a_2 a_3 \ldots a_i] \) in terms of \( a_1 a_2 \ldots a_i \), which will accordingly consist of

\[
a_1 \cdot a_2 \cdot a_3 \ldots a_i - \sum \frac{1}{a_e \cdot a_{e+1}} (a_1 \cdot a_2 \ldots a_i) + \sum \frac{1}{a_e \cdot a_{e+1} \times a_f \cdot a_{f+1}} (a_1 \cdot a_2 \ldots a_i) \text{ &amp;c.},
\]

the indices \( e \) and \( f \), \( e+1 \) and \( f \), &amp;c. being understood to be all distinct integers (which agrees with the known rule for the expression of the denominator of a continued fraction in terms of the quotients). The number of terms in this expansion, in consequence of the vanishing of the quantities affected with a double accent, reduces from \( 2^{i-1} \) down to the \( i \)th term in the series commencing with 1, 2, 3, &amp;c. defined by the equation \( u_{i+1} = u_i + u_{i-1} \),

i.e. \( \frac{1}{\sqrt{5}} \left( \frac{1+\sqrt{5}}{2} \right)^{i+1} - \frac{1}{\sqrt{5}} \left( \frac{1-\sqrt{5}}{2} \right)^{i+1} \);

the number, therefore, of products in which double accents occur in the general expansion of \( [\omega_1 \omega_2 \ldots \omega_i] \) is

\[
2^{i-1} - \frac{1}{\sqrt{5}} \left( \frac{1+\sqrt{5}}{2} \right)^{i+1} + \frac{1}{\sqrt{5}} \left( \frac{1-\sqrt{5}}{2} \right)^{i+1}.
\]
For greater brevity let \([\Omega_e][\Omega_e][\Omega_e][\Omega_e]\) be denoted respectively by \(\omega_e, \omega&#x27;_e, \omega&#x27;&#x27;_e, \omega&#x27;&#x27;&#x27;_e\), then when the type \(\Omega_e\) consists of a single element,

\[
\omega&#x27;_e = 1 \quad \omega&#x27;&#x27;_e = 1 \quad \omega&#x27;&#x27;&#x27;_e = 0.
\]

It should be observed that the two equations \(\omega_e = 0 \quad \omega&#x27;_e = 0\) cannot exist simultaneously, for if \(\Omega_e\) represent \(q_1 q_2 \ldots q_i\),

\[
\omega_e = q_i \omega&#x27;_e - \omega&#x27;&#x27;_e \quad \omega&#x27;_e = q_{i-1} \omega&#x27;&#x27;_e - \omega&#x27;&#x27;&#x27;_e, \text{ &amp;c.,}
\]

so that if \(\omega_e = 0\) and \(\omega&#x27;_e = 0\), we have \(\omega&#x27;&#x27;_e = 0, \omega&#x27;&#x27;&#x27;_e = 0, \text{ &amp;c.,}\) and thus, finally, \(-1 = 0,\) which is absurd.

Now, if we suppose \(\Omega_1 \Omega_2 \ldots \Omega_e\) to be types every element in each of which is a linear function of \(x\), the coefficients of \(x\) in these elements being positive in \(\Omega_1\), negative in \(\Omega_2\), and so on alternately, and \(\Omega\) is the aggregate of \(\Omega_1 \Omega_2 \ldots \Omega_e\), it may easily be made out that each term in the development of \(\omega\) in terms of \(\omega_1, \omega&#x27;_1, \omega&#x27;&#x27;_1; \omega_2, \omega&#x27;_2, \omega&#x27;&#x27;_2; \omega_3, \omega&#x27;_3, \omega&#x27;&#x27;_3; \text{ &amp;c.}\) will have the same sign when we give to \(x\) a value which is a superior limit, or an inferior limit to the roots of each of the cumulants \(\omega_1, \omega_2, \ldots \omega_e\), and consequently to those of the cumulants \(\omega&#x27;_1, \omega&#x27;&#x27;_1, \omega&#x27;&#x27;&#x27;_1; \omega&#x27;_2, \omega&#x27;&#x27;_2, \omega&#x27;&#x27;&#x27;_2; \omega&#x27;_3, \omega&#x27;&#x27;_3, \omega&#x27;&#x27;&#x27;_3; \text{ &amp;c.}\); the products affected with positive signs being all positive or negative in themselves, and those affected with negative signs being reversely all negative, or all positive.

Thus, ex. gr. if

\[
\Omega = \Omega_1 \Omega_2
\]

\[
\omega = \omega_1 \cdot \omega_2 - \omega&#x27;_1 \cdot \omega&#x27;_2,
\]

and the sign of the leading coefficient in \(\omega_2\) will be the contrary of that in \(\omega_3\), but \(\omega_1\) and \(\omega&#x27;_1\) have both the same positive sign; so again if \(\Omega = \Omega_1 \Omega_2 \Omega_3\),

\[
\omega = \omega_1 \cdot \omega_2 \cdot \omega_3 - \omega&#x27;_1 \cdot \omega&#x27;_2 \cdot \omega&#x27;_3 + \omega&#x27;&#x27;_1 \cdot \omega&#x27;&#x27;_2 \cdot \omega&#x27;&#x27;_3,
\]

where the leading coefficients in \(\omega_2\) and \(\omega&#x27;_2\) have contrary signs, as have also those in \(\omega_2\) and \(\omega&#x27;_2\) between \(\omega_2\) and \(\omega&#x27;_2\) have the same sign; and of course the leading coefficients in \(\omega_1, \omega_3, \omega&#x27;_1, \omega&#x27;_3\) have all the same sign, they being all positive, and so in general. But the superior limit to the roots of any integral algebraical function of \(x\) substituted in place of \(x\) causes the signs of the resulting values of the functions to coincide with the signs of the leading coefficients, so that in the example last above given, \(L\) a superior limit to all the factors in the several products in the equation substituted for \(x\) will make \(\omega_1 \cdot \omega_2 \cdot \omega_3, -\omega&#x27;_1 \cdot \omega&#x27;_2 \cdot \omega&#x27;_3, -\omega&#x27;&#x27;_1 \cdot \omega&#x27;&#x27;_2 \cdot \omega&#x27;&#x27;_3, \omega_1 \cdot \omega&#x27;_2 \cdot \omega&#x27;_3\) to have all the same sign. The like will be true of \(\Lambda\) the inferior limit; for if \(\Omega_1, \Omega_2, \Omega_3\) contain respectively \(n_1, n_2, n_3\) elements, the values of the four products last above written, when \(x = -\infty\), will be to the values of the same when \(x = +\infty\) in the respective ratios of

\[
(-)^{m_1 + m_2 + m_3 - 1}; \quad (-)^{m_1 + m_2 + m_3 - 2}; \quad (-)^{m_1 + m_2 + m_3 - 3}; \quad (-)^{m_1 + m_2 + m_3 - 4};
\]

and so in general. Hence we deduce the theorem, that if the total type \(\Omega\) represent the aggregate in apposition of the partial orders \(\Omega_1 \Omega_2 \ldots \Omega_e\) (the elements being understood to be linear functions of \(x\), which are subject to the law of alternation in the signs of the coefficients of \(x\) in passing from one partial type to another), no superior
limit to \( \omega_1, \omega_2, \ldots \omega_e \) can make \( \omega \) vanish unless each separate product in the expansion of \( \omega \) in terms of \( \omega_1, \omega_2, \ldots \omega_e \) and the appurtenant apocopated cumulants vanish separately.

Art. (λ.). From the above theorem we may deduce the following law, viz. that if the roots of \( \omega_1, \omega_2, \ldots \omega_e \) be supposed to be arranged in order of magnitude, and \( \lambda \) to be that one of them which is nearest to \( +\infty \) or to \( -\infty \), then if \( e \) is even it is impossible for \( \lambda \) to be a root of \( \omega \). Thus suppose \( e=2 \), and consequently \( \omega=\omega_1.\omega_2-\omega_1.\omega_2; \) if \( \lambda \) be a root of \( \omega \), and one of the two extremes of the roots of \( \omega_1, \omega_2 \) put in order of magnitude, \( \lambda \) cannot be a root of \( \omega_2 \), for the roots of \( \omega_2 \) are confined between the roots of \( \omega_1 \); but if \( \lambda \) make \( \omega \) and \( \omega_1 \) each vanish, we must have \( \omega_1.\omega_2=0 \), hence \( \omega_1=0 \) as well as \( \omega_2=0 \), which is impossible. In like manner if a root of \( \omega_3 \) were the extreme root, the same impossibility could be in like manner established.

Again, suppose \( e=4 \), so that

\[
\omega=\omega_1.\omega_2.\omega_3.\omega_4\left\{1-\frac{\omega_1.\omega_2}{\omega_1.\omega_2}-\frac{\omega_2.\omega_3}{\omega_2.\omega_3}-\frac{\omega_3.\omega_4}{\omega_3.\omega_4}+\frac{\omega_1.\omega_2.\omega_3}{\omega_1.\omega_2.\omega_3}+\frac{\omega_1.\omega_2.\omega_3.\omega_4}{\omega_1.\omega_2.\omega_3.\omega_4}+\frac{\omega_1.\omega_2.\omega_3.\omega_4}{\omega_1.\omega_2.\omega_3.\omega_4}\right\}.
\]

Let \( \lambda \) continue to denote one or the other extreme of the roots of \( \omega_1, \omega_2, \omega_3, \omega_4 \). We must in each case, if \( \lambda \) makes \( \omega=0 \), have

\[
\begin{align*}
\omega_1.\omega_2.\omega_3.\omega_4&amp;=0; \\
\omega_1&#x27;.\omega_2.\omega_3.\omega_4&amp;=0; \\
\omega_1.\omega_2&#x27;.\omega_3.\omega_4&amp;=0; \\
\omega_1.\omega_2.\omega_3&#x27;.\omega_4&amp;=0; \\
\omega_1.\omega_2.\omega_3.\omega_4&amp;=0; \\
\omega_1&#x27;.\omega_2&#x27;.\omega_3.\omega_4&amp;=0; \\
\omega_1&#x27;.\omega_2.\omega_3&#x27;.\omega_4&amp;=0; \\
\omega_1.\omega_2&#x27;.\omega_3&#x27;.\omega_4&amp;=0; \\
\omega_1.\omega_2.\omega_3&#x27;.\omega_4&amp;=0; \\
\omega_1&#x27;.\omega_2&#x27;.\omega_3&#x27;.\omega_4&amp;=0.
\end{align*}
\]

Now suppose that \( \lambda \) is a root of \( \omega_1 \), then the equations remaining to be satisfied are

\[
\begin{align*}
\omega_1&#x27;.\omega_2.\omega_3.\omega_4&amp;=0; \\
\omega_1&#x27;.\omega_2&#x27;.\omega_3&amp;=0; \\
\omega_1&#x27;.\omega_2.\omega_3&#x27;.\omega_4&amp;=0; \\
\omega_1&#x27;.\omega_2&#x27;.\omega_3&#x27;.\omega_4&amp;=0.
\end{align*}
\]

Since \( \omega_1 \) and \( \omega_1&#x27; \) cannot both be zero together, \( \lambda \) cannot make \( \omega_1 \) or \( \omega_1&#x27; \) zero; and because \( \lambda \) is an extreme to the roots of \( \omega_2, \omega_3, \omega_4 \), \( \lambda \) cannot make \( \omega_2 \) or \( \omega_2&#x27; \) or \( \omega_3 \) or \( \omega_3&#x27; \) or \( \omega_4 \) or \( \omega_4&#x27; \) zero, so that in fact when \( x=\lambda \) none of the singly accented quantities \( \omega \) can be zero. As regards the doubly accented quantities \( \omega \), the same thing cannot be affirmed, because if any \( \Omega \) contains only one element the corresponding value of \( \omega \) with a double accent vanishes spontaneously. Again, any of the unaccented quantities \( \omega \) may vanish, because we may suppose any of these to have an extreme root \( \lambda \). Consequently the first, second and fourth of the equations remaining to be satisfied, might be satisfied on making the necessary suppositions as to the form of the quantities \( \omega \) and the values of the extreme roots; but the third remaining equation \( \omega_1.\omega_2.\omega_3.\omega_4=0 \), in which only singly accented quantities \( \omega \) occur, remains incapable of being satisfied on any supposition whatever. And the same thing would be true if we suppose \( \lambda \) to be a root of any other \( \omega \) instead of \( \omega_1 \). Hence \( \lambda \) cannot make \( \omega=0 \) when \( e=4 \).

In like manner, if \( e \) be any even number \( 2s \), there will be an equation

\[
\omega_1&#x27;.\omega_2.\omega_3.\omega_4.\omega_5&#x27;.\omega_6.\ldots.\omega_{2s-1}&#x27;.\omega_{2s}=0
\]

to be satisfied by that value (if it exist) of \( x \) which, besides being an extreme (on either side) of the roots of \( \omega_1, \omega_2, \ldots \omega_{2s} \) arranged in order of magnitude, also makes \( \omega=0 \). But as such equation cannot be satisfied, neither extreme root of the roots of
\( \omega_1, \omega_2, \ldots, \omega_{3t} \) can be a root of \( \omega \), as was to be proved. Consequently, unless \( \varphi x \) is so assumed that the number of changes of sign in the coefficients of \( x \) in the quotients resulting from \( \frac{\varphi x}{f x} \) expanded as an improper continued fraction is even (for if the changes from sequence to sequence are odd the number of sequences themselves is even), the method of limitation in the text cannot give the means of drawing either limit indefinitely near to one or the other extreme roots of \( f x \).

Art. (\(\mu\)). It now remains to prove the converse, and to show, 1st, that when the number of changes is even, i.e. the number of sequences odd, this coincidence can always be effected; and 2ndly, that it is always possible when \( f x \) has one or more real roots, so to assume \( \varphi x \) that the number of sequences shall be odd.

The first part of the proposition is easily proved. Thus suppose \( e = 3 \), so that

\[
\omega = \omega_1 \cdot \omega_2 \cdot \omega_3 - \omega_1&#x27; \cdot \omega_2 \cdot \omega_3 - \omega_1 \cdot \omega_2&#x27; \cdot \omega_3 + \omega_1&#x27; \cdot \omega_2&#x27; \cdot \omega_3.
\]

If we suppose \( \lambda \) either extreme of the scale formed by writing in order of magnitude, the roots of \( \omega_1, \omega_2, \omega_3 \) to be a root common to \( \omega_1 \) and to \( \omega_3 \) and if \( \omega_4 = 0 \), which last equation may be satisfied by supposing the type \( \Omega_2 \) to consist of a single element, the separate equations

\[
\omega_1 \cdot \omega_2 \cdot \omega_3 = 0 \quad \omega_1&#x27; \cdot \omega_2 \cdot \omega_3 = 0 \quad \omega_1 \cdot \omega_2&#x27; \cdot \omega_3 = 0 \quad \omega_1&#x27; \cdot \omega_2&#x27; \cdot \omega_3 = 0
\]

will all be satisfied; and so in general it may be shown without difficulty that if \( e = 2s + 1 \), and if \( \lambda \) be a root common to \( \omega_1 = 0 \), \( \omega_3 = 0 \), \( \omega_5 = 0 \), ..., \( \omega_{2s+1} = 0 \), and if \( \omega_2, \omega_4, \ldots, \omega_{2s} \) be all simple linear functions of \( x \), so that consequently \( \omega_2 = 0 \), \( \omega_4 = 0 \), ..., \( \omega_{2s} = 0 \), each separate term in the development of \( \omega \) will vanish singly and separately, and consequently \( \lambda \) will be a root of \( \omega \): for since \( \lambda \) makes \( \omega_1 = 0 \), \( \omega_3 = 0 \), ..., \( \omega_{2s+1} = 0 \), every product in the developed form \( \omega \), in which \( \omega_1, \omega_3, \ldots, \omega_{2s+1} \) do not each bear at least one accent, will vanish; and if we consider any product in which \( \omega_1, \omega_3, \ldots, \omega_{2s+1} \) are all accented, if in any two of these immediately following one after the other as \( \omega_{2k-1}, \omega_{2k+1} \), an accent falls to the right of the first, and to the left of the second, the intervening term \( \omega_{2k} \) will bear a double accent, and will therefore vanish, since \( \Omega_{2k} \) is supposed to be a linear function of \( x \); but it is impossible when every \( \omega \) is accented to prevent two accents of contiguous odd terms in any such product, from falling to the right of the left, and to the left of the right, term of the two, since the contrary would imply that all the accents would fall to the right, or all to the left, which, as above remarked, is impossible, on account of the two extreme terms being only simply accentable, i.e. \( \omega_1 \) only to the right, and \( \omega_{2s+1} \) only to the left. Hence, when \( x \) substituted for \( \lambda \) makes \( \omega_1, \omega_3, \ldots, \omega_{2s+1} \) all vanish, and when \( \omega_2, \omega_4, \ldots, \omega_{2s} \) are all linear functions of \( x \), \( x = \lambda \) will be a root of \( \omega \).

Art. (\(\nu\)). I believe that the remaining part of the proposition may be rigorously demonstrated, viz. that when any of the roots of \( f x \) are real, and the number of odd integers not exceeding the index of the degree of \( f x \) is \( m \), and the number of imaginary pairs of roots in \( f x \) is \( \mu \), \( \varphi x \) may be so assumed that the quotients to \( \frac{\varphi x}{f x} \) expanded
under the form of an improper continued fraction, may be made to take the form \( \Omega_1; \Omega_2; \Omega_3; \Omega_4; \ldots; \Omega_{2i+1} \), where \( \Omega_2; \Omega_i; \ldots; \Omega_{2i} \) are linear functions of \( x \), and \( i \) is any number assumed at will, not less than \( p \), and of course not greater than \( m \); and where \( \omega_1; \omega_3; \ldots; \omega_{2i+1} \) will have in common a root \( \lambda \), which may be made at will the greatest or the least root of \( \omega_1.\omega_2.\omega_3.\omega_{2i+1} \); the investigation, however, according to the present light which I possess on the subject, appears complicated and tedious, and therefore, in order that the press, which is waiting for the completion of these supplemental articles, may not be kept standing, must be adjourned to some future occasion. For the present I content myself with showing the truth of the law for the simple case where \( f(x) \) is a cubic function of \( x \).

1st. If \( \frac{\varphi x}{f(x)} \) gives rise to a single sequence of quotients \( \Omega \), we know, from the theory of intercalations, that it is necessary that all the roots of \( f(x) \) shall be real, and in order that when this is the case the quotients may form a single sequence \( \Omega \), it is only necessary so to assume \( \varphi x \), that its roots may be intermediate between those of \( f(x) \).

2nd. If the roots of \( f(x) \) are not all real, or if they are all real, but do not compose the roots of \( f(x) \) intercalated between them, and if for greater brevity of ratiocination we stipulate that \( \varphi x \) shall have its leading coefficients of the same sign as that of the leading coefficient of \( f(x) \), the leading coefficients of the three quotients will either bear the respective signs \( +++, -+- \), or the respective signs \( ++- \), or the respective signs \( +-- \); in the first and last of these cases there would be two sequences, and therefore, by what has been shown above, the method of limitation of the text could not give a limit coincident with a root. Let us then look to the remaining case, and inquire whether, and how, \( \varphi x \) may be assumed so that \( f(x) \) shall become representable to a constant factor \( \text{près} \) by the cumulant \( [p(x-a), -q(x-\beta), r(x-a)] \), where \( p, q, r \) are all positive, and \( a \) is a root of \( f(x) \).

Let this cumulant be called \( hfx \).

Nothing in point of generality will be lost if we suppose the leading coefficient of \( hfx \) to be \(-1\). We then have

\[
hfx = [p(x-a), -q(x-\beta); r(x-a)]
= -pqr(x-a)^2(x-b)-(p+r)(x-a)
\]

and writing \( \frac{hfx}{x-a} = x^2+Bx+C \) and making \( x=a \), we find from the above identity that

\[
p+r=a^2+Ba+C, \quad \text{i.e. } p=a^2+Ba+C-r,
\]

and

\[
pq(x-\beta)=x+a+B,
\]

hence

\[
\beta+a+B=0, \quad \text{i.e. } \beta=-B-a,
\]

and

\[
pq=1, \quad \text{and } \therefore qr=\frac{1}{p}=\frac{1}{a^2+Ba+C-r}.
\]

Hence if \( \varphi x \) be so assumed that the quotients to \( \frac{\varphi x}{f(x)} \) are \( p(x-a); -q(x-\beta); r(x-a), \)
we have

\[ h\varphi x = [-q(x-\beta), r(x-a)] = -qr(x+B+a)(x-a) - 1 \]

\[ = -qr(x^2+Bx-a^2-aB) - 1 = -\frac{1}{p}(x^2+Bx-a^2-aB+p). \]

Hence \( \varphi(x) \) is of the form

\[ m(x^2+Bx-a^2-aB+(a^2+aB+C-r)) = m(x^2+Bx+C-r). \]

If we call the three roots of \( fx \), \( a \), \( b \), \( c \) respectively, we have

\[ q = \frac{1}{r(a^2+Ba+C-r)} = \frac{1}{r((a-b)(a-c)+r)}; \]

and since \( q \) and \( r \) are both to be positive, we see that \( (a) \) must be taken the greatest or least of the three roots if they are all real, so that \( a^2+Ba+C \) may be positive, which it will of course necessarily be if \( b \) and \( c \) are imaginary; we must also have \( a^2+Ba+C-r \) positive, so that the form of \( \varphi x \) is \( m((x^2-a^2)+B(x-a)-t) \), \( t \) being necessarily positive, but otherwise arbitrary, a form containing two arbitrary constants, one of which is subject to satisfy a certain condition of inequality; whereas when \( fx \) is of such a form as to admit, and \( \varphi(x) \) is supposed to be so assumed as to cause it to come to pass that the quotients to \( \frac{\varphi x}{fx} \) form a single sequence, then the three coefficients in \( \varphi x \) remain exempt from all conditions of equality but are subject to two conditions of inequality. And so in general when the degree of \( fx \) is \( x \) and the number of sequences \( 2i+1 \), it is to be inferred that the \( n \) coefficients of \( \varphi x \) will be subject to satisfy \( n-i-1 \) conditions of inequality and \( i \) conditions of equality.

Art. (\(\xi\)). The theory of the determination of the minimum interval between either limit determinable by this method and the nearest root, or between the two limits so determinable when \( \varphi x \) is so assumed that \( \frac{\varphi x}{fx} \) gives rise to a defined even number of sequences (which will include the theory of the case where all the roots of \( fx \) are imaginary), must be deferred to an opportunity more favourable for leisurely contemplation. As regards the application of the theory to the very interesting case of all the roots being imaginary, the principal point remaining to be cleared up is the determination of the least value that can be assigned to the greatest, and the greatest value that can be assigned to the least root of the algebraical product \( X_1.X_2.X_3...X_{2n} \), where \( X_1, X_2, ... X_{2n} \) are all of them real linear functions of \( x \), subject to the condition that the cumulant \([X_1, X_2, X_3...X_{2n}]\) shall (to a numerical factor près) be equal to a given function of the degree \( 2n \) in \( x \) incapable of changing its sign, which condition implies, as a necessary consequence, that the coefficients of \( x \) in each of the terms \( X_1, X_2, ... X_{2n} \) must be affected with the same algebraical sign.

Art. (\(\sigma\)). It should be observed that in the application of the above method, the division of the series of quotients into distinct sequences governed by the signs of the coefficients of \( x \) is introduced for the purpose of drawing the limits closer to the roots, but is not necessary for the mere object of assigning limits.
Thus, for instance, if there be two sequences so that

\[ q_1 q_2 \ldots q_i; \quad q_{i+1} q_{i+2} \ldots q_{i+r} \]

\[ q_1^2 = \mu_1^2; \quad q_2^2 = \left( \frac{\mu_2}{\mu_1} + 1 \right)^2; \quad q_3^2 = \left( \frac{\mu_3}{\mu_2} + 1 \right)^2; \ldots; \quad q_r^2 = \left( \frac{1}{\mu_{r-1}} \right)^2 \]

and

\[ q_{i+1}^2 = v_1^2; \quad q_{i+2}^2 = \left( \frac{v_2}{v_1} + 1 \right)^2; \ldots; \quad q_{i+r}^2 = \left( \frac{1}{v_{r-1}} \right)^2 \]

the greatest and least roots of \( x \) deduced from these equations will be superior and inferior limits respectively to the roots of \( f(x) \); from which it is clear that if leaving all the other equations unaltered, except those which contain respectively \( q_i^2 \) and \( q_{i+1}^2 \), we write in place of these

\[ q_i^2 = \left( \frac{1}{\mu_i - 1} \right)^2 \]

\[ q_{i+1}^2 = \left( \frac{1}{v_i - 1} \right)^2 \]

the roots of the system of \( i + r \) equations thus modified will à fortiori be limits to the roots of \( f(x) \), but then the quantities

\[ \mu_1, \mu_2 + \frac{1}{\mu_1}, \ldots, \mu_{r-1} + \frac{1}{\mu_{r-2}}, \frac{1}{\mu_{r-1}}, v_1 + \frac{1}{v_1}, v_2 + \frac{1}{v_2}, \ldots, \frac{1}{v_{r-1}} \]

form the same single series as would correspond to the two sequences

\[ q_1 q_2 \ldots q_i q_{i+1} \ldots q_{i+r}, \]

treated as a single sequence, and the same is obviously the case for any number of sequences*.

Art. (π.). If we consider a single sequence as \( q_1 q_2 \ldots q_n \), and write

\[ q_1 = a_1(x - c_1); \quad q_2 = a_2(x - c_2); \ldots; \quad q_n = a_n(x - c_n) \]

where \( a_1, a_2, \ldots, a_n \) are supposed to have all the same sign, and write

\[ a_1^2(x - c_1)^2 = \mu_1^2; \quad a_2^2(x - c_2)^2 = \left( \frac{\mu_2}{\mu_1} + 1 \right)^2; \ldots; \quad a_n^2(x - c_n)^2 = \left( \frac{1}{\mu_{n-1}} \right)^2 \]

no root of \( Q \) can lie between the extreme roots of the function \( K \), used to denote the cumulant

\[ [\sqrt{q_1}, -\sqrt{q_2}, \sqrt{q_3}, \ldots, \pm \sqrt{q_n}], \]

the square roots being understood to be taken so as to make the sign of the coefficients of \( x \) all of them positive; and from a preceding article we know that either extreme root of \( Q \) can be made to coincide with a corresponding extreme root of \( K \). Hence we have an à priori solution of the following question, viz. &quot;To determine the \((n-1)\) positive quantities \( \mu_1, \mu_2, \ldots, \mu_{n-1} \), so as to make the greatest root of \( Q \) a minimum and its least root a maximum;&quot; for the greatest root of \( K \) will be the minimum greatest root of \( Q \), and the least root of \( K \) the maximum least root of \( Q \). Calling these respectively \( l \) and \( \lambda \), the two systems of values of \( \mu_1, \mu_2, \ldots, \mu_{n-1} \) required will be obtained by substituting respectively \( l \) and \( \lambda \) for \( x \) in the equations

\[ \mu_1 = \sqrt{q_1}; \quad \mu_2 = -\sqrt{q_2} - \frac{1}{\mu_1}; \quad \mu_3 = +\sqrt{q_3} - \frac{1}{\mu_2}; \ldots; \quad \mu_{n-1} = \pm \sqrt{q_{n-1}} - \frac{1}{\mu_{n-2}}. \]
it seems not unlikely that the interval between the greatest and least of the roots of the above equations will be a minimum when the intervals between any pair is the same for each pair, i.e. when

\[
\frac{\mu_1}{a_1} = \frac{\mu_2 + 1}{a_1} = \frac{\mu_3 + 1}{a_2} = \ldots = \frac{1}{a_n}.
\]

If we assume these equations, and write \( \mu_1 = a_1 \xi \), the equation for determining \( \xi \) will be

\[
[a_1 \xi, a_2 \xi, a_3 \xi, \ldots, a_n \xi] = 0.
\]

If \( n = 2 \) this equation becomes \( a_1 a_2 \xi^2 - 1 = 0 \).

If \( n = 3 \), rejecting the factor \( \xi \), it becomes

\[
a_1 a_2 a_3 \xi^3 - (a_1 + a_2 + a_3) \xi^2 + 1 = 0.
\]

If \( n = 4 \) it becomes

\[
a_1 a_2 a_3 a_4 \xi^4 - (a_1 a_2 + a_3 a_4 + a_1 a_4 + a_2 a_3) \xi^3 + 1 = 0.
\]

If \( n = 5 \), rejecting the factor \( \xi \), it becomes

\[
a_1 a_2 a_3 a_4 a_5 \xi^5 - (a_1 a_2 a_3 + a_1 a_2 a_4 + a_1 a_3 a_4 + a_2 a_3 a_4 + a_1 a_2 a_3 a_4 a_5) \xi^4 + (a_1 + a_2 + a_3 + a_4 + a_5) = 0,
\]

and so in general the equation in \( \xi^2 \) being always of a degree measured by the integer nearest to and not exceeding \( \frac{n}{2} \); and it is easy to be seen that for all values of \( n \), the second coefficient divided by the first will be an inferior limit to \( \xi^2 \) (of course actually coinciding with it for the cases of \( n = 2 \) and \( n = 3 \)). Hence we have the following valuable practical rule for finding a superior and inferior limit to the cumulant

\[
[a_1(x - c_1), a_2(x - c_2), \ldots, a_n(x - c_n)],
\]

where \( a_1, a_2, \ldots, a_n \) have the same sign, viz. if \( C \) be the greatest, and \( K \) be the least of the quantities \( c_1, c_2, \ldots, c_n \), \( C + \Delta \) will be a superior, and \( K - \Delta \) an inferior limit, \( \Delta \) being taken equal to the positive value of

\[
\sqrt{\frac{1}{a_1 a_2} + \frac{1}{a_2 a_3} + \frac{1}{a_3 a_4} + \ldots + \frac{1}{a_{n-1} a_n}};
\]

and it may be noticed that \( C \) and \( K \) are the quantities which would themselves be the superior and inferior limits to the given cumulant if the series of terms \( a_1, a_2, \ldots, a_n \), instead of presenting only a sequence of continuations or permanencies, presented only a sequence of changes or variations of sign.

**Section V.**

*On the Theory of Intercalations as applicable to two functions of the same degree, and on the formal properties of the Bezoutiant with reference to the method of Invariants.*

Art. (56.). If \( f x \) and \( \varphi x \) be any two given functions of \( x \) of the same degree \( m \), we may form a system of \( m \) Bezoutics to \( f \) and \( \varphi \) (as shown in the first section), the coefficients of the powers of \( x^{m-1}, x^{m-2}, \ldots, x^1, x^0 \) in which will compose a square matrix of \( m \) lines of \( m \) terms each, which will be symmetrical in respect to the diagonal
which passes through the first coefficient of the first Bezoutic and the last coefficient of the last Bezoutic; and we may construct a quadratic homogeneous function of $m$ new variables, such that its determinative matrix shall coincide with the Bezoutic square so formed. This quadratic form may be considered in the light of a generating function. All its coefficients will be formed of quantities obtained by taking any two coefficients in one of the given functions, and two corresponding coefficients in the other given function, multiplying them in cross order, and taking the difference: each coefficient of the generating function in question will consist of one or more such differences, and will thus be of two dimensions altogether, being linear in respect to the coefficients of $f$, and also linear in respect to the coefficients of $\varphi$. This generating function I term the *Bezoutiant*, and it may be denoted by the symbol $B(f, \varphi)$: the determinant of $B$ is of course the resultant to $f, \varphi$, and the matrix to $B$ is the Bezoutic square to $f, \varphi$. Now we have seen that the decrease in the number of continuations of sign in the series $1, B_1(x), B_2(x) \ldots B_m(x)$ (where $B_1(x), B_2(x) \ldots B_m(x)$ are the $(n)$ Bezoutics to $f, \varphi$), as $x$ changes from $a$ to $b$, measures the number of roots of $fx$ retained in the effective scale of intercalations taken between the limits $(a)$ and $(b)$. If we take the entire scale between $+\infty$ and $-\infty$ the total number of effective intercalations will be the same, whether reckoned by the number of roots of $f$ or of $\varphi$ remaining; for these two numbers can never differ except by a unit, since no two of either can ever come together; but the number of each remaining in the effective scale will be $m-2i$ and $m-2i&#x27;$ respectively, $i$ being the number of pairs of imaginary roots and pairs of unseparated real roots of $f$ and $i&#x27;$ being the similar number for $\varphi$; so that we must have $i=i&#x27;$.

Now obviously this number becomes measured by the number of continuations of sign in the *signaletic* series $1, (B_1), (B_2), \ldots (B_m)$, where in general $(B_i)$ denotes the principal coefficient in $B_i(x)$.

But $(B_1), (B_2), \ldots (B_m)$ are the successive ascending coaxal minor determinants about the axis of symmetry to the Bezoutic square; and accordingly the number of continuations just spoken of, measures the number of positive terms in the Bezoutiant when linearly transformed, so as to contain only positive and negative squares, or in other words, measures the *inertia* of the Bezoutiant, the constant integer which adheres to it under all its real linear transformations.

Art. (57.). This inertia is the same number as in the case of a homogeneous quadratic function of three variables, used to express a curve referred to trilinear coordinates, serves to determine whether such conic belongs to the impossible class or to the possible class of conics, being 3 or 0 in the former case, and 1 or 2 in the latter; or as in the case of a homogeneous quadratic function of four variables used to denote a surface referred to quadriplanar or tetrahedral coordinates, serves to determine whether such surface belongs to the impossible class or to the class consisting of the ellipsoid and the hyperboloid of two sheets (which are descriptively indistinguishable), or to the hyperboloid of one sheet, being 0 or 4 in the first case,
1 or 3 in the second, and 2 in the third. The most symmetrical (but least expeditious) method of finding the inertia of any quadratic form is that which corresponds to the method of orthogonal transformations, and is, in fact, the usual method employed in geometrical treatises on lines and surfaces of the second degree. If we apply this method to the Bezoutian B considered as a homogeneous quadratic function of the \((m)\) arbitrarily named variables \(u_1, u_2, u_3, \ldots u_m\) in order to measure its inertia, that is to say, the number of effective interpositions between the two systems of roots, we must construct the determinant

\[
D(\lambda) = \begin{vmatrix}
\frac{d^2B}{du_1^2} + \lambda; &amp; \frac{d^2B}{du_1 \cdot du_2}; &amp; \frac{d^2B}{du_1 \cdot du_3}; &amp; \cdots &amp; \frac{d^2B}{du_1 \cdot du_m} \\
\frac{d^2B}{du_2 \cdot du_1}; &amp; \frac{d^2B}{du_2^2} + \lambda; &amp; \frac{d^2B}{du_2 \cdot du_3}; &amp; \cdots &amp; \frac{d^2B}{du_2 \cdot du_m} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{d^2B}{du_m \cdot du_1}; &amp; \frac{d^2B}{du_m \cdot du_2}; &amp; \frac{d^2B}{du_m \cdot du_3}; &amp; \cdots &amp; \frac{d^2B}{du_m^2} + \lambda
\end{vmatrix}
\]

All the roots of \(D(\lambda) = 0\), as is well known, are real; the inertia of B, being measured by the number of positive roots of \(D(-\lambda)\), will be equal to the number of continuations of sign in \(D(\lambda)\) expressed as a function of \(\lambda\) of the \(m\)th degree.

If in \(fx\) and \(\varphi x\) we reverse the order of the coefficients, and \(f&#x27;x\) and \(\varphi_1 x\) so transformed become \(f_1(x)\) and \(\varphi_1(x)\), it is obvious that the roots of \(f_1\) and \(\varphi_1\) being the reciprocals of the roots of \(f\) and \(\varphi\) respectively, the number of effective intercalations to \(f_1\) and \(\varphi_1\) must be the same as for \(f\) and \(\varphi\). Accordingly we find that the form of the Bezoutian to \(f\) and \(\varphi\) is the same as that of the Bezoutian to \(f_1\) and \(\varphi_1\), the sole difference (one only of names) being that \(B(u_1, u_2, \ldots u_{m-1}, u_m)\) for the one becomes \(B(u_m, u_{m-1}, \ldots u_2, u_1)\) for the other. The equation \(D(\lambda)\), which determines the inertia of B, remains precisely the same as it ought to do for either of the two systems \(f\) and \(\varphi\) or \(f_1\) and \(\varphi_1\).

Art. (58.). The theory in the preceding articles of this section may be made to embrace the case involved in Sturm&#x27;s theorem; for if

\[
fx = a_0 x^n + a_1 x^{n-1} + \cdots + a_{m-1} x^{m-1} + a_m x^m
\]

and

\[
f&#x27;x = ma_0 x^{n-1} + (n-1)a_1 x^{n-2} + \cdots + a_{m-1},
\]

the Bezoutian secondaries, or which is the same thing, the simplified Sturmian residues to \(fx\) and \(f&#x27;x\), will evidently be the same as those to \(f_1x\) and \(f&#x27;_1x\). Accordingly, if we form the signaletic series

\[
fx, f&#x27;x, B_1, B_2, \ldots B_{m-1},
\]
where $B_1, B_2 \ldots B_{m-1}$ are the Bezoutian secondaries to $f(x)$ and $f&#x27;(x)$, the number of variations of sign between consecutive terms in this series, when $x$ is made $+\infty$, will measure the number of pairs of imaginary roots in $f(x)$; and $f(x)$ and $f&#x27;(x)$ forming always a continuation, and the coefficient of $f&#x27;(x)$ being supposed positive, we see that the terms of the rhizoristic series will be $1, (B_1), (B_2) \ldots (B_{m-1})$ consisting of positive unity, and the successive ascending coaxal determinants of the Bezoutian matrix to $f&#x27;$ and $f(x)$. Hence then the form of the Bezoutiant to $f&#x27;(x)$ and $f(x)$ will serve to determine the number of pairs of imaginary, and consequently also the number of real roots to $f(x)$.

It should be remarked that the form of the Bezoutiant to $f&#x27;(x)$ and $f(x)$, considered as a quadratic function of $u_1, u_2 \ldots u_{m-1}$ and of the coefficients in $f(x)$, will remain unaltered when for $f(x)$ we write $f&#x27;(x)$, for this will change the signs throughout of $f(x)$ and $f&#x27;(x)$, and consequently the coefficients in the Bezoutiant, which contain in every term one coefficient from $f&#x27;(x)$, and one from $f(x)$, will remain unaltered in sign.

Art. (59.). It appears then from the preceding article, that for every function of $x$ of the degree $m$, there exists a homogeneous quadratic function of $(m-1)$ variables, the inertia of which augmented by unity will represent the number of real roots in the given function. Now this inertia itself may be measured by the number of positive roots of a certain equation in $\lambda$ formed from the quadratic function (in fact the well-known equation for the secular inequalities of the planets), all whose roots will be real. Hence then we are led to the following remarkable statement. &quot;An algebraical equation of any degree being given, an equation whose degree is one unit lower may be formed, all the roots of which shall be real, and of which the number of positive roots shall be one less than the total number of real roots of the given equation.&quot;

Let us suppose $f(x)$ written in its most general form, the first and last as well as all the intermediate coefficients being anything whatever: by reversing the order of the coefficients $f&#x27;(x)$ will become $f(x)$ and $f(x)$ will become $f&#x27;(x)$; the Bezoutiant to $f(x)$ and $f&#x27;(x)$ (which we may term the Bezoutoid to $f(x)$) will remain unaltered except in sign, and the equation of the $(m-1)$th degree in $\lambda$ formed from the Bezoutoid remain unchanged, consequently the equation in $\lambda$ enables us to substitute, for the purpose of calculating the total number of real roots in $f(x)$ in lieu of Sturm&#x27;s auxiliary functions to $f(x)$, another set of functions which remain unaltered when the order of the coefficients is completely reversed, i.e. in effect, when we consider the number of real roots of $f\left(\frac{1}{x}\right)$ in lieu of those of $f(x)$. And of course more generally the equation of the $m$th degree in $\lambda$ formed from the Bezoutiant to any two functions $f(x)$ and $\phi(x)$ of the $m$th degree each in $x$, supplies a set of functions for determining the total number of effective intercalations between the roots of $f(x)$ and $\phi(x)$, which do not alter when we consider in lieu of these, the roots of $f&#x27;\left(\frac{1}{x}\right)$ and $\phi\left(\frac{1}{x}\right)$. This substitution of functions symmetrically formed in respect to the two ends of an equation for the purpose of assigning the total number of real roots in lieu of the unsymmetrical ones furnished
by the ordinary method of M. Sturm, had been long felt by me to be a desideratum, and as an object the accomplishment of which was indispensable to the ulterior development of the theory, and it is certain that I did not in anticipation exaggerate the importance of the result to be attained.

Art. (60.). It may happen that the Bezoutiant to $f$ and $\phi$ (each of the $m$th degree) may become a quadratic function of less than $m$ independent variables, or the Bezoutoid to $f$ (a function in $x$ of the $m$th degree) of less than $(m-1)$ independent variables. This will take place whenever $f$ and $\phi$ have roots in common, or whenever $F$ has equal roots. The number of independent relations of equality between the roots of $f$ and $\phi$, and the amount of multiplicity, however distributed, among the roots of $F$, will be indicated by the number of orders thus disappearing out of the general form of the Bezoutiant and Bezoutoid in the respective cases*. In what particular mode the form of each would be affected according to the manner of the distribution of the equalities and the multiplicity requires a specific discussion, which I must reserve for some future occasion.

Art. (61.). I shall devote the remainder of this memoir to a consideration of the properties and affinities of Bezoutiants or Bezoutoids, regarded from the point of view of the Calculus of Invariants. For this purpose it will be more convenient hereafter to convert all the functions which we are concerned with into homogeneous forms, and I shall accordingly for the future use $f$ and $\phi$ to denote functions each of $x$ and $y$, which I shall write under the form

$$f = a_0 \cdot x^m + ma_1 \cdot x^{m-1} \cdot y + m \cdot \frac{m-1}{2} a_2 \cdot x^{m-2} \cdot y^2 + \ldots + a_m \cdot x^m$$

$$\phi = b_0 \cdot x^m + b_1 \cdot x^{m-1} \cdot y + m \cdot \frac{m-1}{2} b_2 \cdot x^{m-2} \cdot y^2 + \ldots + b_m \cdot x^m.$$  

In what follows a knowledge of the general principles of the Method of Invariants is presupposed, but a perusal of my two papers on the Calculus of Forms in the Cambridge and Dublin Mathematical Journal, February and May 1852, will furnish nearly all the information that is strictly necessary for the present purpose. The first point to be established is, that $B$, the Bezoutian of $fx$ and $\phi x$, is a Covariant to the system $f$, $\phi$; the variables in $B$ being in compound relation of cogredience with the combinations of powers of $x$ and $y$,

$$x^{m-1}; x^{m-2} \cdot y; x^{m-3} \ldots y^{m-1}.$$  

That is to say, I propose to show that if $f$, $g$, $h$, $k$ be any four quantities, taken for greater simplicity subject to the relation $fk - gh = 1$, and if on substituting $fx + gy$ for $x$ and $hx + ky$ for $y$, $f(x, y)$ becomes

$$A_0 \cdot x^m + mA_1 \cdot x^{m-1} \cdot y + m \cdot \frac{m-1}{2} A_2 \cdot x^{m-2} \cdot y^2 + A_m \cdot y^m,$$  

say $G(x, y)$;

* I have elsewhere defined how this word order, as here employed, is to be understood. If $F$, a homogeneous function of $x_1, x_2, \ldots, x_n$, can be expressed as a function of $u_1, u_2, \ldots, u_{n-i}$ (all linear functions of $x_1, x_2, \ldots, x_n$), $F$ is said to be a function of $n-i$ orders, or to have lost $i$ of the orders belonging to the complete form.
and $\phi(x, y)$ becomes

$$B_0x^m + B_1x^{m-1}y + m\frac{m-1}{2}B_2x^{m-2}y^2 + B_m y^m,$$

say $T(x, y)$,

and if $B&#x27;(u_1&#x27;, u_2&#x27;...u_m&#x27;)$ be the Bezoutiant to $G$ and $T$; $B(u_1, u_2...u_m)$ being that to $f$ and $\phi$, then, on making $u_1, u_2...u_m$, the same linear functions of $u_1&#x27;, u_2&#x27;...u_m&#x27;$ as $(fx+gy)^m; (fx+gy)^{m-1}(hx+ky); ......(fx+gy)(hx+ky)^{m-1}; (hx+ky)^{m-1}$ are respectively of

$$x^m, x^{m-1}y...x^my^{m-1}; y^m,$$

$B$ will become identical with $B&#x27;$. I was led to suspect the high probability of the truth of this proposition concerning the invariance of the Bezoutiant from the following considerations: 1st. That for the particular case where $f$ and $\phi$ are the differential derivatives in respect to $x$ and $y$ respectively of the same function $F(x, y)$, the Bezoutiant of $f$ and $\phi$, which then becomes the Bezoutoid of $F$, determines the number of real factors in $F$, which obviously remains the same for all linear transformations of $F$. 2ndly. That taking $f$ and $\phi$ in their most general form, the invariant to their Bezoutiant, i.e. the determinant of their Bezoutiant is an invariant of $f$ and $\phi$, being in fact the resultant of these two functions; now as every concomitant (an invariantive form of the most general kind) to a concomitant is itself a concomitant to the primitive, so it appeared to me, and is I believe true (although awaiting strict proof), that any form satisfying certain necessary and tolerably obvious conditions of homogeneity and isobarism, a concomitant to which is also a concomitant to a given form, will be itself a concomitant to such form; this principle, if admitted, would be of course at once conclusive as to the Bezoutiant being an invariantive concomitant to the functions from which it is derived.

Art. (61*). Since the publication of the two papers above referred to on the Calculus of Forms, I have made the important observation that every species of concomitant, however complex, to a given system of functions, may be treated as a simple invariant of a system including the given system together with an appropriate superadded system of absolute functions; thus an ordinary covariant involving only one system of variables, as $u, v, w ...$ cogredient with $x, y, z ...$ the variables of a system $S$, is in fact an invariant of the system $S$ combined with the system $ux - vy, vz - wy, wx - uz, &amp;c., u, v, w ...$ being treated as constants; so again a simple contravariant of $S$ is an invariant of $S$ combined with the equation $ux + vy + wz + &amp;c.$; so again, to meet the case before us, a covariant to the binary system $f$ and $\phi$ expressed as a function of $u_1, u_2...u_m$, where $u_1, u_2...u_m$ are cogredient with $x^{m-1}, x^{m-2}y...y^{m-1}$, may be regarded as an invariant of the ternary system $f, \phi, \Omega$, where

$$\Omega = u_1y^{m-1} - mu_2y^{m-2}x + m\frac{m-1}{2}u_3y^{m-3}x^2... + (-)^{m-1}u_{m-1}x^{m-1},$$

($u_1, u_2, ... u_{m-1}$ being here to be treated as constants), and accordingly the differential equations which serve to define in the most general and absolute manner such cova-
variant of $f$, $\phi$, or invariant to $f$, $\phi$, $\Omega$, say I, will take the form

$$\left\{ \begin{array}{c}
\left( a_0 \frac{d}{da_1} + b_0 \frac{d}{db_1} \right) + 2 \left( a_1 \frac{d}{da_2} + b_1 \frac{d}{db_2} \right) + 3 \left( a_2 \frac{d}{da_3} + b_2 \frac{d}{db_3} \right) + \ldots + m \left( a_{m-1} \frac{d}{da_m} + b_{m-1} \frac{d}{db_m} \right) \\
- \left( u_1 \frac{d}{du_2} + 2u_2 \frac{d}{du_3} + 3u_3 \frac{d}{du_4} + \ldots + (m-1)u_{m-1} \frac{d}{du_m} \right)
\end{array} \right\} I = 0$$

$$\left\{ \begin{array}{c}
\left( a_m \frac{d}{da_{m-1}} + b_m \frac{d}{db_{m-1}} \right) + 2 \left( a_{m-1} \frac{d}{da_{m-2}} + b_{m-1} \frac{d}{db_{m-2}} \right) \\
+ 3 \left( a_{m-2} \frac{d}{da_{m-3}} + b_{m-2} \frac{d}{db_{m-3}} \right) + \ldots + m \left( a_1 \frac{d}{da_0} + b_1 \frac{d}{db_0} \right) \\
- \left( u_{m-1} \frac{d}{du_{m-2}} + 2u_{m-2} \frac{d}{du_{m-3}} + 3u_{m-3} \frac{d}{du_{m-4}} \ldots + (m-1)a_2 \frac{d}{du_1} \right)
\end{array} \right\} I = 0.$$

These equations may be proved to be satisfied when I is taken = B, the Bezoutiant to $f$, $\phi$, and thus B may be proved to be a covariant to $f$, $\phi$, but the demonstration is long and tedious. An admirable suggestion, well worthy of its keen-witted author, for which I am indebted to Mr. Cayley, will enable us to prove the invariantive character of B by a much more expeditious method.

Art. (62.). For greater simplicity begin with considering functions of a single variable $x$; and in order to fix the ideas, suppose $(m)$ to be taken 5, and write

$$fx = ax^5 + bx^4 + cx^3 + dx^2 + ex + l$$

$$\phi x = ax^5 + \beta x^4 + \gamma x^3 + \delta x^2 + \epsilon x + \lambda,$$

and let $\mathfrak{D} = \frac{fx\phi x&#x27; - f\phi x \cdot \phi x}{x - x&#x27;}$; this is of course an integral function of $x$ and $x&#x27;$, since the numerator vanishes when $x = x&#x27;$; and we have by performing the actual operations,

$$\mathfrak{D} = \left\{ \begin{array}{c}
(a\beta - b\alpha)x^4 \cdot x&#x27;^4 + (a\gamma + c\alpha)x^3 \cdot x&#x27;^3(x + x&#x27;) + (a\delta - d\alpha)x^2 \cdot x&#x27;^2(x^2 + xx&#x27; + x&#x27;^2) + (a\epsilon - e\alpha) \\
xx&#x27;(x^2 + x^2x&#x27; + xx&#x27;^2 + x&#x27;^3) + (a\lambda - l\alpha)(x^4 + x^3x&#x27; + x^2x&#x27;^2 + xx&#x27;^3 + x&#x27;^4)
\end{array} \right\}$$

$$+ \left\{ \begin{array}{c}
(b\gamma - c\beta)x^3 \cdot x&#x27;^3 + (b\delta - d\beta)x^2 \cdot x&#x27;^2(x + x&#x27;) + (b\epsilon - e\beta)xx&#x27;(x^2 + xx&#x27; + x&#x27;^2) \\
+ (b\lambda - l\beta)(x^3 + x^2x&#x27; + xx&#x27;^2 + x&#x27;^3)
\end{array} \right\}$$

$$+ ((c\delta - d\gamma)x^2 \cdot x&#x27;^2 + (c\epsilon - e\gamma)xx&#x27;(x + x&#x27;) + (c\lambda - l\gamma)(x^2 + xx&#x27; + x&#x27;^2))$$

$$+ ((d\epsilon - e\delta)xx&#x27; + (d\lambda - l\delta)(x + x&#x27;))$$

$$+ (e\lambda - l\epsilon);$$

and if we arrange $\mathfrak{D}$ under the form

$$A_{4,4} x^4 \cdot x&#x27;^4 + A_{4,3} x^4 \cdot x&#x27;^3 + A_{4,2} x^4 \cdot x&#x27;^2 + A_{4,1} x^4 \cdot x&#x27; + A_{4,0} \cdot x^4$$

$$+ A_{3,4} x^3 \cdot x&#x27;^4 + A_{3,3} x^3 \cdot x&#x27;^3 + A_{3,2} x^3 \cdot x&#x27;^2 + A_{3,1} x^3 \cdot x&#x27; + A_{3,0} \cdot x^3$$

$$+ A_{2,4} x^2 \cdot x&#x27;^4 + A_{2,3} x^2 \cdot x&#x27;^3 + A_{2,2} x^2 \cdot x&#x27;^2 + A_{2,1} x^2 \cdot x&#x27; + A_{2,0} \cdot x^2$$

$$+ A_{1,4} xx&#x27;^4 + A_{1,3} xx&#x27;^3 + A_{1,2} xx&#x27;^2 + A_{1,1} xx&#x27; + A_{1,0} \cdot xx&#x27;$$

$$+ A_{0,4} x&#x27;^4 + A_{0,3} x&#x27;^3 + A_{0,2} x&#x27;^2 + A_{0,1} x&#x27; + A_{0,0};$$
it will readily be perceived that the matrix formed by the twenty-five coefficients, viz.—

\[
\begin{array}{cccccc}
A_{4,4} &amp; A_{4,3} &amp; A_{4,2} &amp; A_{4,1} &amp; A_{4,0} \\
A_{3,4} &amp; A_{3,3} &amp; A_{3,2} &amp; A_{3,1} &amp; A_{3,0} \\
A_{2,4} &amp; A_{2,3} &amp; A_{2,2} &amp; A_{2,1} &amp; A_{2,0} \\
A_{1,4} &amp; A_{1,3} &amp; A_{1,2} &amp; A_{1,1} &amp; A_{1,0} \\
A_{0,4} &amp; A_{0,3} &amp; A_{0,2} &amp; A_{0,1} &amp; A_{0,0}
\end{array}
\]

will be symmetrical about its dexter diagonal (that one, namely, which passes through \(A_{4,4}\) and \(A_{0,0}\)), and will be identical with the Bezoutian square corresponding to the system \(f, \varphi\); in fact, using the notation previously employed in the first section, it becomes

\[
\begin{array}{cccccc}
(0, 1) &amp; (0, 2) &amp; (0, 3) &amp; (0, 4) &amp; (0, 5) \\
(0, 2) &amp; \{(0, 3)\} &amp; \{(0, 4)\} &amp; \{(0, 5)\} &amp; (1, 5) \\
(1, 2) &amp; \{(1, 3)\} &amp; \{(1, 4)\} &amp; \{(1, 5)\} &amp; (2, 5) \\
(0, 3) &amp; \{(0, 4)\} &amp; \{(0, 5)\} &amp; \{(1, 5)\} &amp; (3, 5) \\
(1, 3) &amp; \{(1, 4)\} &amp; \{(1, 5)\} &amp; \{(2, 3)\} &amp; (3, 5) \\
(0, 4) &amp; \{(0, 5)\} &amp; \{(1, 5)\} &amp; \{(2, 3)\} &amp; (3, 5) \\
(1, 4) &amp; \{(1, 5)\} &amp; \{(2, 3)\} &amp; \{(3, 5)\} &amp; (4, 5)
\end{array}
\]

\((r, s)\) being used in general to denote the difference between the cross products of the coefficients of \(x^{5-r}\) and \(x^{5-s}\) in \(f\) and \(\varphi\). Restoring now to \(m\) its general value, and taking \(f\) and \(\varphi\) homogeneous functions of \(x\) and \(y\), and making

\[
\Omega = \frac{f(x, y)\varphi(x&#x27;, y&#x27;) - f(x&#x27;, y&#x27;)\varphi(x, y)}{xy&#x27; - x&#x27;y},
\]

we see without difficulty that

\[
\Omega = \sum A_{r,s}\{x^ry^{m-1-r}x&#x27;^sy^{m-1-s}\},
\]

where \(A_{r,s}\) is the term in the \(r\)th line and \(s\)th column of the Bezoutiant matrix to \(f\) and \(\varphi\). This is the identification, the idea of which, as before observed, is due to Mr. Cayley.

Art. (63.). If, now, we consider the system of functions

\[
f(x, y) = a_0x^m + ma_1x^{m-1}y + \ldots + a_my^m,
\]
\[
\varphi(x, y) = b_0x^m + mb_1x^{m-1}y + \ldots + b_my^m,
\]
\[
\Omega(x, y) = u_{m-1}y^{m-1} - (m-1)u_{m-2}y^{m-2} \pm \ldots + (-)^{m-1}u_1x^{m-1};
\]
evidently \( f(x, y)\varphi(x&#x27;, y&#x27;) - f(x&#x27;, y&#x27;)\varphi(x, y) \) is a covariant with \( f \) and \( \varphi \), and therefore (which is a mere truism) with the entire system \( f, \varphi, \Omega \). So also is \( xy&#x27; - x&#x27;y \), and therefore \( S \), the quotient of these two, is a covariant to the system. Hence, therefore, by virtue of a general theorem given in my Calculus of Forms,

\[
\Omega \left( \frac{d}{dy&#x27;} - \frac{d}{dx} \right) S
\]

is a covariant to the system; and again, therefore,

\[
\Omega \left( \frac{d}{dy&#x27;} - \frac{d}{dx} \right) \cdot \Omega \left( \frac{d}{dy} - \frac{d}{dx} \right) S
\]

is a covariant thereto. Now \( S \) is of \((m-1)\) dimensions in \( x, y \) and also of the same in \( x&#x27;, y&#x27; \). Consequently this latter form will contain only the quantities \( u_1, u_2, \ldots u_{m-1} \), and the coefficients of \( f \) and \( \varphi \), so that the powers of \( x, y; x&#x27;, y&#x27; \) will not appear in it.

Now

\[
S = \sum_{m=1}^{m-1} \sum_{r,s} A_{r,s} \{ x^r \cdot y^{m-1-r} \cdot x&#x27;^s \cdot y^{m-1-s} \}
\]

\[
(-)^{m-1} \Omega \left( \frac{d}{dy&#x27;} - \frac{d}{dx} \right) = u_{m-1} \left( \frac{d}{dx} \right)^{m-1} + (m-1)u_{m-2} \left( \frac{d}{dx} \right)^{m-2} \frac{d}{dy} + \ldots + u_1 \left( \frac{d}{dy} \right)^{m-1}
\]

\[
(-)^{m-1} \Omega \left( \frac{d}{dy&#x27;} - \frac{d}{dx} \right) = u_{m-1} \left( \frac{d}{dx&#x27;} \right)^{m-1} + (m-1)u_{m-2} \left( \frac{d}{dx&#x27;} \right)^{m-2} \frac{d}{dy&#x27;} + \ldots + u_1 \left( \frac{d}{dy&#x27;} \right)^{m-1},
\]

\[
\vdots \quad \frac{1}{1 \cdot 2 \cdot 3 \cdots (m-1)^2} \cdot \Omega \left( \frac{d}{dy&#x27;} - \frac{d}{dx} \right) \cdot \Omega \left( \frac{d}{dy} - \frac{d}{dx} \right) S
\]

\[
= \sum_{m=1}^{m-1} (A_{r,r} \cdot u_r^2) + 2 \sum_{m=1}^{m-1} \sum_{r,s} (A_{r,s} \cdot u_r \cdot u_s),
\]

\( r \) and \( s \) being excluded in the latter sum from being made equal; but this latter expression is the Bezoutiant to \( f, \varphi \). Hence the Bezoutiant of \( f, \varphi \) is an invariant to \( f, \varphi, \Omega \), i.e. a covariant to the system \( f, \varphi, \Omega \), as was to be proved. The mode of obtaining the covariant \( S \), used in this and the preceding article, is very remarkable. I believe that the true suggestive view of the process for finding it, is to consider

\[
f(x, y) \cdot \varphi(x&#x27;, y&#x27;) - f(x&#x27;, y&#x27;) \cdot \varphi(x, y)
\]

as a concomitant capable of being expressed under the form of a function of \( S \) and \( \omega \), \( \omega \) standing for the universal covariant \( xy&#x27; - x&#x27;y \); \( S \) is then to be considered, not properly as a quotient, but rather as an invariant of the form \( S \cdot \omega \), a function of \( \omega \) of the first degree, where \( S \) is treated as constant.

Art. (64.). B is not an ordinary covariant of \( f \) and \( \varphi \), it belongs to that special and most important family of invariants to a system to which I have given the name of Combinants*, viz. Invariants, which, besides the ordinary character of invariance, when linear substitutions are impressed upon the variables, possess the same character of invariance when linear substitutions are impressed upon the functions themselves containing the variables; combinants being, as it were, invariants to a system of

* For some remarks on the Classification of Combinants, see Cambridge and Dublin Mathematical Journal, November, 1853.
functions in their corporate combined capacity qud system. That the Bezoutiant possesses this property is evident; for if instead of \( f \) and \( \varphi \) we write \( k&#x27;f + i&#x27;\varphi \) and \( k&#x27;&#x27;f + i&#x27;&#x27;\varphi \), any such quantity as \( a_r b_s - a_s b_r \) (\( a_r, b_r \) being coefficients in \( f \), and \( a_s, b_s \) the corresponding ones in \( \varphi \)) becomes

\[
(k a_r + i b_r)(k&#x27; a_s + i&#x27; b_s) - (k a_s + i b_s)(k&#x27; a_r + i&#x27; b_r), \quad \text{i.e.} \quad (k i&#x27; - k&#x27; i)(a_r b_s - a_s b_r),
\]

so that \( B \), the Bezoutiant, becomes increased in the ratio of \( (k i&#x27; - k&#x27; i)^m \), i.e. remains always unaltered in point of form and absolutely immutable, provided that \( k i&#x27; - k&#x27; i \) be taken, as we may always suppose to be the case, equal to 1.

We derive immediately from this observation, the somewhat remarkable geometrical proposition, that the intersections with the axis of \( x \) made by any two curves of the family of curves \( u = \lambda f(x) + \mu \varphi(x) \), (\( f \) and \( \varphi \) being functions of \( x \) of the same degree) give rise to a constant number of effective intercalations, whatever values be given to \( \lambda \) or \( \mu \) for the two curves so selected.

Art. (65.). \( B(u_1, u_2, \ldots u_m) \) being a covariant of the system \( f \) and \( \varphi \), and \( u_1, u_2, \ldots u_m \) cogredient with \( x^{m-1}, x^{m-2}, y_0 \ldots y^{m-1} \), it follows from a general principle in the theory of invariants, that on making \( u_1, u_2, \ldots u_m \) respectively equal to the quantities with which they are cogredient, \( B \) will become an ordinary covariant to \( f \) and \( \varphi \). By this transformation \( B \) becomes a function of \( x \) and \( y \) of the degree \( 2(m-1) \) in \( x \) and \( y \) conjointly, and linear in respect to the coefficients of \( f \), and also in respect to those of \( \varphi \). The only covariant capable of answering this description is what I am in the habit of calling the Jacobian (after the name of the late but ever-illustrious Jacobi), a term capable of application to any number of homogeneous functions of as many variables. In the case before us, where we have two functions of two variables, the Jacobian

\[
J(f, \varphi) = \begin{vmatrix}
\frac{df}{dx}; &amp; \frac{d\varphi}{dx} \\
\frac{df}{dy}; &amp; \frac{d\varphi}{dy}
\end{vmatrix} = \frac{df}{dx} \cdot \frac{d\varphi}{dy} - \frac{df}{dy} \cdot \frac{d\varphi}{dx}.
\]

We have then the interesting proposition*, that the Bezoutiant to two functions, when the variables in the former are replaced by the combinations of the variables in the latter, with which they are cogredient, becomes the Jacobian†. So in the case of a single function \( F \) of the degree \( m \), the Bezoutiant, i.e. the Bezoutoid to \( \frac{dF}{dx}, \frac{dF}{dy} \), on making the \((m-1)\) variables which it contains identical with \( x^{m-2}, x^{m-3}y; \ldots y^{m-2} \) respectively, becomes identical with the Jacobian to \( \frac{d^2F}{dx^2}, \frac{d^2F}{dxdy}, \frac{d^2F}{dy^2} \).

* I have subsequently found that this proposition is contained under another mode of statement, at the end of Section 2 of the Memoir of Jacobi, &quot;De Eliminatione,&quot; above referred to.

† For a strict proof of this proposition see Supplement to Third Section of this memoir.
As an example of this property of the Bezoutiant, suppose

\[ f = ax^3 + bx^2 y + cxy^2 + dy^3 \]
\[ \phi = \alpha x^3 + \beta x^2 y + \gamma xy^2 + \delta y^3. \]

The Bezoutiant matrix becomes

\[
\begin{array}{ccc}
a\beta - b\alpha &amp; a\gamma - c\alpha &amp; a\delta - d\alpha \\
a\delta - d\alpha &amp; b\gamma - c\beta &amp; b\gamma - c\beta \\
a\delta - d\alpha &amp; b\gamma - c\beta &amp; c\delta - d\gamma .
\end{array}
\]

The Bezoutiant accordingly will be the quadratic function

\[
(a\beta - b\alpha)u_1^2 + (a\delta - d\alpha + b\gamma - c\beta)u_2 u_3 + c\delta - d\gamma u_3^2
\]
\[ + 2(a\gamma - c\alpha)u_1 u_2 + 2(a\delta - d\alpha)u_3 u_1 + 2(b\gamma - c\beta)u_3 u_1,
\]

which on making

\[ u_1 = x^2 \quad u_2 = xy \quad u_3 = y^2, \]

becomes

\[ Lx^4 + Mx^3y + Nx^2y^2 + Px^2y + Qy^4, . . . . . . . . . . . . (3.) \]

where \( L, M, N, P, Q \) respectively will be the sum of the terms lying in the successive bands drawn parallel to the sinister diagonal of the Bezoutiant matrix, i.e.

\[ L = a\beta - b\alpha \]
\[ M = 2(a\gamma - c\alpha) \]
\[ N = 3(a\delta - d\alpha) + (b\gamma - c\beta) \]
\[ P = 2(b\gamma - c\beta) \]
\[ Q = c\delta - d\gamma. \]

The biquadratic function in \( x \) and \( y \) (3.) above written will be found on computation to be identical in point of form with the Jacobian to \( f, \phi \), viz.

\[ (3ax^2 + 2bxy + cy^2)(\beta x^2 + 2\gamma xy + 3\delta y^2) - (3ax^2 + 2\beta xy + \gamma y^2)(bx^2 + 2cxy + dy^2), \]

this latter being in fact

\[ 3Lx^4 + 3Mx^3y + 3Nx^2y^2 + 3Px^2y + 3Qy^4. \]

The remark is not without some interest, that in fact the Bezoutiant, which is capable (as has been shown already) of being mechanically constructed, gives the best and readiest means of calculating the Jacobian; for in summing the sinister bands transverse to the axis of symmetry the only numerical operation to be performed is that of addition of positive integers, whereas the direct method involves the necessity of numerical subtractions as well as additions, inasmuch as the same terms will be repeated with different signs. Thus if

\[ f = ax^5 + bx^4 y + cx^3 y^2 + dx^2 y^3 + exy^4 + fy^5 \]
\[ \phi = \alpha x^5 + \beta x^4 y + \gamma x^3 y^2 + \delta x^2 y^3 + \epsilon xy^4 + \lambda y^5, \]

using \((r, s)\) in the ordinary sense that has been considered throughout, we obtain by
taking the sum of the sinister bands in (α.)* for the value of B when we write \(x^4, x^3y, x^2y^2, xy^3, y^4\) in place of \(u_1, u_2, u_3, u_4, u_5\),

\[
(0, 1)x^8 + 2(0, 2)x^7y + (3(0, 3) + (1, 2))x^6y^2 + (4(0, 4) + 2(1, 3))x^5y^3 \\
+ (5(0, 5) + 3(1, 4) + (2, 3))x^4y^4 + (4(1, 5) + 2(2, 4))x^3y^5 + (3(2, 5) + (3, 4))x^2y^6 \\
+ 2(3, 5)xy^7 + (4, 5)y^8.
\]

The direct process requires the calculation of

\[
(5ax^4 + 4bx^3y + 3cx^2y^2 + 2dxy^3 + ey^4)(3x^4 + 2\gamma x^3y + 3\delta x^2y^2 + 4\epsilon xy^3 + 5\lambda y^4) \\
-(5ax^4 + 4\beta x^3y + 3\gamma x^2y^2 + 2\delta xy^3 + \varepsilon y^4)(bx^4 + 2cx^3y + 3dx^2y^2 + 4exy^3 + 5ly^4),
\]

each coefficient of which will contain the numerical factor 5; so that to reduce the Jacobian to its simplest form each coefficient will necessitate the employment of additions, subtractions, and a division, instead of additions merely, as when the Bezoutic square is employed. For instance, to find the coefficient of \(x^4.y\) from the above expression (α.), we have to calculate

\[
\frac{1}{5}(25(0, 5) + 16(1, 4) + 9(2, 3) + 4(3, 2) + (4, 1)),
\]

i.e. \(\frac{1}{5}(25(0, 5) + (16 - 1)(1, 4) + (9 - 4)(2, 3))\),

which is \(5(0, 5) + 3(1, 4) + (2, 3)\), agreeing with what has been found above for the value of such coefficient, by a simple process of counting. The same remark will, of course, also apply to the computation of the Hessian of \(F\) by means of its Bezoutoid.

(Art. 66.). This relation between the Bezoutiant and the Jacobian led me to inquire whether, as would at first sight appear probable, the Bezoutiant were the only lineo-linear quadratic function of \((m)\) variables covariantive to \(f\) and \(φ\) (the word lineo-linear being used to denote the form of coefficients, such as those in the Bezoutiant, linear in respect of the coefficients in \(f\) and the coefficients of \(φ\)). If so, then there would have existed a method of performing the inverse process of recovering the Bezoutiant from the Jacobian, almost as simple as that of deriving the Jacobian from the Bezoutiant. On investigating the matter, however, I found that such is by no means the case†, but that there exists a whole family of independent lineo-

* Vide art. 62.

† This might have been concluded immediately from the following observation. Let \(J\), the Jacobian of \(f\) and \(φ\), be expressed under the form

\[
A_0x^{2m-2} + (2m-2)A_1x^{2m-1}.y + (2m-2)\frac{2m-3}{2}A_2x^{2m-2}.y^2 + \ldots + A_{2m-2}.y^{2m-2},
\]

then we know from the Calculus of Forms, that, \(D\) being taken to represent the persymmetrical Determinant

\[
\begin{array}{cccc}
A_0 &amp; A_1 &amp; \ldots &amp; A_{m-1} \\
A_1 &amp; A_2 &amp; \ldots &amp; A_m \\
A_2 &amp; A_3 &amp; \ldots &amp; A_{m+1} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
A_{m-1} &amp; A_m &amp; \ldots &amp; A_{2m-2},
\end{array}
\]
linear quadratic covariants of \( m \) variables to every two homogeneous functions of \( x \) and \( y \) of the \( m \)th degree. I have, moreover, I believe, succeeded in determining the number of such lineo-linear quadratic forms for any value of \( (m) \), of which all the rest, in whatever manner obtained, may be expressed as linear functions, the coefficients of the linear relations moreover being abstract numbers; in other words, I have succeeded in forming the fundamental or constituent scale of lineo-linear quadratic forms of \( m \) variables covariantive to \( f \) and \( \phi \); a result of too great interest, as exhibiting the affinities of the Bezoutiant to its cognate forms, to be altogether passed over in silence. Supposing the number of linearly independent forms of the kind to be \( v \), then speaking \( a \) priori any of the forms taken at random might seem to be equally eligible to form one of the \( v \) included in the fundamental scale, combined with any \( (v - 1) \) others independent inter se, and of which the selected one is also independent. In fact, however, this is not so; for it will always be more satisfactory to contemplate the fundamental scale of forms as generated successively or simultaneously by a uniform process; and in the case before us, the process which I have hit upon, and which I believe is the simplest that can be employed for generating the fundamental scale, will be found not to include directly the Bezoutiant among the number. There will thus arise two subjects of inquiry; 1st, the mode of forming the fundamental scale, and proving its fundamental

\( D = 0 \) is the condition to be satisfied in order that \( J \) may be representable under the form of the sum of the squares of \( (m - 1) \) linear functions of \( x \) and \( y \), and \( D \) itself is an invariant to \( J \), and consequently an invariant and (as is obvious from its form) a combinantive invariant to \( f \) and \( \phi \). Moreover, which is more immediately to the point, we know that the quadratic form \( Q \)

\[
(A_0 u_1^2 + 2A_1(u_1 \cdot (m-1)u_2) + A_2 \left( (m-1)(m-2) \right) u_2^2 + \text{etc.} + A_{2m-2} u_m^2)
\]

will be an invariant to \( f \), \( \phi \) and \( \Omega \) (this last quantity \( \Omega \) being defined as in p. 524), and a combinantive covariant to \( f \) and \( \phi \) in the same sense precisely as the Bezoutiant is a covariant to the same, and like the Bezoutiant is lineo-linear in respect of the coefficients of \( f \) and \( \phi \). If we operate with the symbol \( E \), where \( E \) represents

\[
\frac{d}{dA_0} u_1^2 + 2 \frac{d}{dA_1} u_1 u_2 + \frac{d}{dA_2} (u_2^2 + 2u_1 \cdot u_3) + \text{etc.} + \frac{d}{dA_{2m-2}} u_m^2,
\]

upon \( K \) any invariant of \( f \) and \( \phi \), we shall obtain \( E.K \), a quadratic function of \( u_1 u_2 \ldots u_m \), which by the rules of the Calculus of Forms we know will be a contravariant to \( f \) and \( \phi \), and the matrix corresponding to which must evidently be persymmetrical. It is an interesting subject of inquiry, which I reserve for some future occasion, to determine the Co-bezoutiant, the Discriminant of which must be employed for \( K \), so that when this discriminant is operated upon by \( E \), the matrix corresponding to \( E.K \) may become identical (term for term) with the matrix which is the inverse to the Bezoutiant matrix, which inverse, as Jacobi has so simply and beautifully demonstrated, possesses this persymmetrical character. Vide the &quot;De Eliminatione,&quot; section 5. The investigation of the arithmetical connexion between the \( Q \) of this note and the fundamental Co-bezoutiants must be also similarly reserved. I believe it to be generally true, and have verified the fact for the case of two cubic functions, that \( E.Q \) gives a quadratic form such that the corresponding matrix is the inverse to the matrix of \( Q \). The calculations necessary for extending the verification of this remarkable proposition for functions of \( x, y \) exceeding the third degree (notwithstanding that they are much abbreviated by the application of the rules of the calculus) still remain excessively laborious. The abbreviation alluded to consists in confining the verification in question to the comparison of either one of the two unreiterated terms at opposite corners of the matrix to \( E.Q \) with the corresponding term in the inverse matrix of \( Q \); if these coincide, it is easy to prove that every other pair of corresponding terms in the two matrices must also coincide respectively with one another.
character; 2ndly, determining the numerical relations which connect that very important form, perhaps of all of its kind, the most important with the forms comprised in the fundamental or constituent scale. These questions I propose to consider more fully at a future period. For the present I shall content myself with giving a method of forming the constituent scale (without, however, seeking the proof of all the forms extra to such assumed scale being linear functions of these comprised within it), and with determining the numerical relations between the forms in this scale and the Bezoutiant for a limited number of values of \( m \). All the forms which we are seeking, besides being lineo-linear quadratics, must also be combinantive invariants to \( f \) and \( \varphi \), remaining (as forms) unaltered for any linear substitutions impressed either upon the variables or upon the functions containing the variables.

Art. (67.). I must here premise that if there be any two forms of the same degree (and that degree odd) in \( x \) and \( y \), a combinant may be formed from them, which will be linear in respect to each set of coefficients*. Thus calling the two functions

\[
a_0x^{2n+1} + (2n+1)a_1x^{2n}y + (2n+1)\frac{2n}{2}a_2x^{2n-1}y^2 + \ldots + a_{2n+1}y^{2n+1}
\]

\[
a_0x^{2n+1} + (2n+1)a_1x^{2n}y + (2n+1)\frac{2n}{2}a_2x^{2n-1}y^2 + \ldots + a_{2n+1}y^{2n+1},
\]

the lineo-linear combinant in question will be

\[
T = \left\{ a_0a_{2n+1} - (2n+1)a_1a_{2n} + (2n+1)\frac{2n}{2}a_2a_{2n-1} + \frac{(2n+1)(2n)(2n-1)}{1.2.3}a_3a_{2n-2} &amp;c. - a_{2n+1}a_0 &amp;c. \right\}
\]

which, using our customary notation, will be of the form

\[
(0, 2n+1) - (2n+1)(1, 2n) + \frac{(2n+1)2n}{1.2}(2, 2n-1) \pm &amp;c. + (-)^n \frac{(2n+1)(2n)(2n-1)...(n+2)}{1.2.3...n}(n, n+1).
\]

As a corollary to this proposition (which, as well as the proposition itself, will be needed for the purposes of the ensuing determination), taking any function of an even degree in \( x, y \), \( F(x, y) \), there will exist a combinant to \( \frac{dF}{dx} \) and \( \frac{dF}{dy} \), by virtue of what has been stated above, which will be Mr. Cayley&#x27;s well-known quadrivariant to \( F \); viz. if \( F = a_0x^{2n} + a_1x^{2n-1} + \ldots + a_{2n}x^{2n} \), this will be

\[
a_0a_{2n} - 2na_1a_{2n} + \frac{2n(2n-1)}{2}a_2a_{2n-2} + \ldots + \frac{1}{2}(-)^n \frac{2n(2n-1)...(n+1)}{1.2...n}a_n^2.
\]

The proposition itself is easily proved; first, the expression \( T \) being expressed entirely in terms of quantities of the form \((r, s)\) remains unaltered for linear substitutions impressed upon the forms \( f \) and \( \varphi \); it remains then only to show that \( T \) satisfies the differential equations to \( T \) treated as a mere invariant, viz.—

* I may add here incidentally (although not wanted for our present purposes) that as a combinant in which each set of coefficients enters linearly can always be formed to a system of functions 2 in number of as many variables and of any odd degree, so reciprocally can a combinant in which each set of coefficients enters linearly be always formed to a system of functions each of the degree 2, of which and of the variables contained in them, the number is any odd integer.
\[ \left\{ a_0 \cdot \frac{d}{da_1} + 2a_1 \cdot \frac{d}{da_2} + 3a_2 \cdot \frac{d}{da_3} + \ldots + (2n+1)a_{2n} \cdot \frac{d}{da_{2n+1}} \right\} T = 0, \]

and

\[ \left\{ a_{2n+1} \cdot \frac{d}{da_{2n+1}} + 2a_{2n} \cdot \frac{d}{da_{2n-1}} + \ldots + (2n+1)a_1 \cdot \frac{d}{da_0} \right\} T = 0. \]

From the hemihedral symmetry of \( T \), which only changes its sign when the order of the coefficients in \( f \) and \( \phi \) is simultaneously reversed, it is obvious that one of these equations cannot be satisfied without the other being so too. Looking then exclusively at the first of them, we see that this is satisfied by virtue of the equations

\[ \left\{ a_0 \cdot \frac{d}{da_1} + (2n+1)a_{2n} \cdot \frac{d}{da_{2n+1}} \right\} T = 0 \]

\[ \left\{ 2a_1 \cdot \frac{d}{da_2} + 2n \cdot a_{2n-1} \cdot \frac{d}{da_{2n}} \right\} T = 0 \]

\[ \vdots \]

\[ \left\{ (2n+1)a_{2n} \cdot \frac{d}{da_{2n+1}} + a_0 \cdot \frac{d}{da_1} \right\} T = 0. \]

Hence then the differential equations to \( T \) being satisfied proves that it is an invariant, and, as above observed, its form shows upon its face that it is a combinant.

Precisely in the same way it may be demonstrated, that to two functions each of the same even degree \((2m)\) as

\[ a_0 x^{2m} + 2ma_1 x^{2m-1} y + \frac{2m(2m-1)}{2} a_2 x^{2m-2} y^2 + \ldots + a_{2m} y^{2m} \]

and

\[ a_0 x^{2m} + 2ma_1 x^{2m-1} y + \frac{(2m-1)}{2} a_2 x^{2m-2} y^2 + \ldots + a_{2m} y^{2m} \]

there will be a quantity

\[ G = a_0 \cdot a_{2m} - 2ma_1 \cdot a_{2m-1} + \frac{2m(2m-1)}{2} a_2 \cdot a_{2m-2} \pm &amp;c. - 2ma_1 a_{2m-1} + a_0 \cdot a_{2m}, \]

which, although not a combinant, will satisfy the differential equations necessary to prove it to be an ordinary invariant to the two given functions.

Art. (68.). Now let us consider the three forms \( f, \phi \) and the subsidiary form

\[ f = a_0 x^m + ma_1 x^{m-1} y + \ldots + a_m y^m \]

\[ \phi = b_0 x^m + mb_1 x^{m-1} y + \ldots + b_m y^m \]

\[ \Omega = u_1 y^{m-1} - (m-1)u_2 y^{m-2} \cdot x \pm &amp;c. + (-) a_m^{m-1} x^{m-1}, \]

where \( u_1, u_2, \ldots, u_m \) are to be treated as constants.

Make

\[ E_{2i+1} f = \frac{1 \cdot 2 \cdots (2i+1)}{m(m-1) \cdots (m-2i)} \left( \xi \frac{d}{dx} + \eta \frac{d}{dy} \right)^{2i+1} f \]

\[ E_{2i+1} \phi = \frac{1 \cdot 2 \cdots (2i+1)}{m(m-1) \cdots (m-2i)} \left( \xi \frac{d}{dx} + \eta \frac{d}{dy} \right)^{2i+1} \phi, \]
i being any integer such that \(2i+1\) does not exceed \(m\), and now consider \(E_{2i+1}, f, E_{2i+1}, \varphi\) as two functions of the degree \(2i+1\) in \(\xi, \eta\) (x and y being regarded as constants); and by virtue of the formula in the last article, form \(T_i\), the lineo-linear combinant of \(E_{2i+1}, f\) and \(E_{2i+1}, \varphi\); \(T_i\) will then be lineo-linear in respect to the coefficients in \(f\) and \(\varphi\), and of the degree \(2(m-(2i+1))\) in respect to \(x\) and \(y\).

Again, let

\[
E_i.\Omega = \frac{1.2...2i}{m(m-1)...(m-2i+1)} \cdot (\xi \frac{d}{dx} + \eta \frac{d}{dy})^{2i} \cdot \Omega.
\]

\(E_{2i}. \Omega\) treated as a function of \(\xi\) and \(\eta\) of the degree \(2i\) will furnish a quadrinvariant \(Q_i\) of the degree \(2(m-1-2i)\) in respect of \(x\) and \(y\), and quadratic in respect of the system \(u_1, u_2, ... u_m\). We have thus two forms, \(T_i\) and \(Q_i\), each of the same even degree \((2m-(2i+1))\) in respect of \(x, y\). Forming between these the lineo-linear invariant \(G_i\), \(G_i\) will be a function lineo-linear in respect of the coefficients of \(f\) and \(\varphi\), and quadratic in respect of the system \(u_1, u_2, ... u_m\). Moreover, \(G_i\) will (by the general principle of successive concomitance) be an invariant in respect to the system \(f, \varphi, \Omega\), and combinantive in respect to \(f\) and \(\varphi\). Thus then \(G_i\) for all admissible values of \(i\) will belong to the family of forms to which the Bezoutiant is to be referred.

It requires to be noticed, that when \(i\) is taken \((0)\), so that \(T_i\) and \(G_i\) are of the degree \(2(m-1)\), \(E_i\) for this case must be taken equal to \(\Omega^2\), which evidently fulfills the required conditions of being of the degree \(2(m-1)\) in \((x, y)\), and quadratic in respect of the coefficients of \(\Omega\). If, now, \(m\) be even, we may take for \(2i+1\) successively all the odd numbers from 1 to \((m-1)\) inclusively, and there will be \(\frac{m}{2}\) forms \(G_i\); when \(m\) is odd we may take for \(2i+1\) successively all the odd numbers from 1 to \(m\), and the number of forms of \(G_i\) will be \(\frac{m+1}{2}\). It should be observed, that when \(m\) is odd and \(2i+1=m\), \(T_i\) will become identical with the lineo-linear combinant to \(f\) and \(\varphi\) and \(Q_i\) with the quadrinvariant to \(\Omega\); and no power of \(x\) or \(y\) will enter into either, so that \(G_m\) will become simply \(T_m \times Q_m\). I am now able to enunciate the proposition, that \(G_0, G_1, ... G_{\frac{m-1}{2}}\); when \(m\) is even, and \(G_0, G_1, ... G_{\frac{m-1}{2}}\), when \(m\) is odd, form the constituent scale of forms, of which the Bezoutiant and all other lineo-linear quadratic functions of \(m\) variables, which are combinants of the system \(f, \varphi\), will be numerically-linear functions. I propose to term the members of this scale Co-bezoutiants.

As regards the present memoir, I shall content myself with exhibiting a partial verification of this law as regards the connection of the Bezoutiant with the \(G\) scale of Co-bezoutiants, and a complete determination of the numerical multipliers which express this connection for the cases comprised between \(m=2\) and \(m=6\) taken inclusively. It is impossible to predict for what ulterior purposes in the development of the Calculus of Invariants these numbers may or may not be required, and it seems
to me desirable that a commencement of a table containing them should be made and placed on record. The remaining pages of this memoir will accordingly be devoted to the ascertainment of them.

The theory of the Bezoutoid being included within that of the Bezoutiant, need not hereafter call for any special attention; I may merely notice that the Bezoutoid to a function of the degree \( m \) will be a numerico-linear function of \( \frac{m-3}{2} \) of the G&#x27;s if \( m \) be odd, and \( \frac{m-4}{2} \) of the G&#x27;s if \( m \) be even.

It will be more convenient hereafter to denote the G&#x27;s as \( G_1, G_3, G_5 \) respectively, in lieu of \( G_0, G_1, G_2, \ldots \), and to continue at the same time to give to the T&#x27;s and Q&#x27;s the same subscripts as the corresponding G&#x27;s.

Art. (69.). 1st. Suppose \( m=2 \),

\[
f=ax^2+2bxy+cy^2 \\
\varphi=ax^2+2\beta xy+\gamma y^2 \\
\Omega=u_1.y-u_2.x.
\]

Then

\[
E_1.f=(ax+by)\xi+(bx+cy)\eta \\
E_1.\varphi=(ax+\beta y)\xi+(\beta x+\gamma y)\eta \\
T_1=(ax+by)(\beta x+\gamma y)-(bx+cy)(ax+\beta y) \\
=(a\beta-b\alpha)x^2+(a\gamma-c\alpha)xy+(b\gamma-c\beta)y^2 \\
Q_1=\Omega^2=u_1^2y^2-2u_1.u_2xy+u_2^2.x^2
\]

and

\[
G_1=(a\beta-b\alpha)u_1^2+(a\gamma-c\alpha)u_1u_2+(b\gamma-c\beta)u_2^2.
\]

Let us now form in the usual manner the Bezoutiant to \( f, \varphi \); this is the quadratic function which corresponds to the matrix

\[
(2a\beta-2b\alpha); \quad (a\gamma-c\alpha) \\
(a\gamma-c\alpha); \quad (2b\gamma-c\beta)
\]

i.e. \( \frac{1}{2}B=(a\beta-b\alpha)u_1^2+(a\gamma-c\alpha)u_1u_2+(b\gamma-c\beta)u_2^2=G_1 \) or \( B=2G_1 \).

2nd. Suppose \( m=3 \).

\[
f=ax^3+3bxy^2+3cxy^2+dy^3 \\
\varphi=ax^3+3\beta xy^2+3\gamma xy^2+dy^3 \\
\Omega=u_1y^3-2u_2yx+u_3x^3.
\]

We have then

\[
E_1.(f)=(ax^2+2bxy+cy^2)\xi+(bx^2+2cxy+dy^2)\eta \\
E_1.(\varphi)=(ax^2+2bxy+\gamma y^2)\xi+(\beta x^2+2\gamma xy+\delta y^2)\eta \\
T_1=(ax^2+2bxy+cy^2)(\beta x^2+2\gamma xy+\delta y^2)-(bx^2+2cxy+dy^2)(ax^2+2\beta xy+\gamma y^2) \\
=(a\beta-b\alpha)x^4+2(a\gamma-c\alpha)x^3y+(3(\beta\gamma-c\beta)+(a\delta-d\alpha))x^2y^2+2(b\delta-d\beta)x^2y^2+(c\delta-d\gamma)y^4 \\
Q_1=\Omega^2=u_1^2y^4-4u_1.u_2y^3u+(4u_2^2+2u_1.u_3)y^2x^2-4u_2.u_3yx^3+u_3^2.x^4.
\]
Supplying for facility of computation the reciprocals of the binomial coefficients to the index 4, viz.—

\[1; \quad -\frac{1}{4}; \quad \frac{1}{6}; \quad -\frac{1}{4}; \quad 1,\]

we obtain

\[G_1 = (a\beta - b\alpha)u_1^2 + 2(a\gamma - c\alpha)u_1.u_2 + (2(b\gamma - c\beta) + \frac{2}{3}(a\delta - d\alpha))u_2^2\]

\[+ ((b\gamma - c\beta) + \frac{1}{3}(a\delta - d\alpha))u_1.u_3 + 2(b\delta - d\beta)u_2.u_3 + (c\delta - d\gamma)u_3^2.\]

It will here and henceforth be more useful to employ \([r, s]\) to denote, not the difference of the cross products of the \((r+1)\)th and \((s+1)\)th entire coefficients in \(f\) and \(\varphi\), but the difference of the cross products of these coefficients divided each by its appropriate binomial coefficient. We may then write

\[G_1 = [0, 1]u_1^2 + 2[0, 2]u_1.u_2 + ([1, 2] + \frac{1}{3}[0, 3])u_1.u_3 + (2[1, 2] + \frac{2}{3}[0, 3]).u_2^2\]

\[+ 2[1, 3]u_2.u_3 + [2, 3]u_3^2.\]

Again,

\[G_3 = ((a\delta - d\alpha) - 3(b\gamma - c\beta)) + (u_1.u_3 - u_2^2) = ([0, 3] - 3[1, 2])(u_1.u_3) - ([0, 3] - 3[1, 2])u_2^2.\]

Hence

\[G_1 - \frac{1}{3}G_3 = [0, 1]u_1^2 + 2[0, 2]u_1.u_2 + 2[1, 2]u_1.u_3 + ([0, 3] + [1, 2])u_2^2 + 2[1, 3]u_2.u_3 + [2, 3]u_3^2.\]

But, again, the Bezoutiant of \(f, \varphi\) corresponds to the matrix

\[
\begin{array}{ccc}
3[0, 1]; &amp; 3[0, 2]; &amp; [0, 3] \\
3[0, 2]; &amp; [0, 3] + 9[1, 2]; &amp; 3[1, 3] \\
[0, 3]; &amp; 3[1, 3]; &amp; [3, 4].
\end{array}
\]

Hence summing the sinister bands to form the coefficients, we have

\[B = 3[0, 1]u_1^2 + 6[0, 2]u_1.u_2 + (3[0, 3] + 9[1, 2])u_2^2 + 6[1, 3]u_2.u_3 + [2, 3]u_3^2 = 3G_1 - G_3.\]

3rd. Suppose \(m = 4\),

\[f = ax^4 + 4bx^3y + 6cx^2y^2 + 4dxy^3 + ey^4\]

\[\varphi = ax^4 + 4\beta x^3y + 6\gamma x^2y^2 + 4\delta xy^3 + \varepsilon y^4\]

\[\Omega = u_1y^3 - 3u_2y^2x + 3u_3yx^2 - u_4x^3.\]

Then

\[E_3.f = (ax + by)x^3 + 3(bx + cy)x^2y + 3(cx + dy)y^3 + (dx + ey)y^4,\]

\[\therefore T_3.f = \left\{\begin{array}{l}
(ax + by)(\delta x + \varepsilon y) \\
-(ax + \beta y)(dx + ey)
\end{array}\right\} - 3\left\{\begin{array}{l}
(bx + cy)(\gamma x + \delta y) \\
-(\beta x + \gamma y)(cx + dy)
\end{array}\right\}\]

\[= ([0, 3] - 3[1, 2])x^2 + ([0, 4] - 2[1, 3])xy + ([1, 4] - 3[2, 3])y^2\]

and

\[Q_3 = (u_1.y - u_2x)(u_3y - u_4x) - (u_2y - u_3x)^2\]

\[= (u_1.u_3 - u_2^2)y^2(u_1.u_4 - u_2u_3)xy + (u_2.u_4 - u_3^2)x^2.\]
Hence supplying the binomial reciprocals

\[1; -\frac{1}{2}; 1,\]

we have

\[G_3 = ([0, 3] - 3[1, 2])(u_1.u_3 - u_2^2) + \frac{1}{2}([0, 4] - 2[1, 3])(u_1.u_4 - u_2.u_3)\]
\[+ ([1, 4] - 3[2, 3])(u_2.u_4 - u_3^2).\]

Again,

\[T_3 = (ax^3 + 3bx^2y + 3cxy^2 + dy^3)(\beta x^3 + 3\gamma x^2y + 3\delta xy^2 + ey^3)\]
\[- (\alpha x^3 + 3\beta x^2y + 3\gamma xy^2 + \delta y^3)(bx^3 + 3cx^2y + 3dx^2y + ey^3)\]
\[= [0, 1]x^6 + 3[0, 2]x^5y + (3[0, 3] + 6[1, 2])x^4y^2 + ([0, 4] + 8[1, 3])x^3y^3\]
\[+ (3[1, 4] + 6[2, 3])x^2y^4 + [3, 4]y^6,\]

and

\[Q_1 = \Omega^2\]
\[= u_1^2.y^6 - 6u_1.u_2.x^5y + (9u_3^2 + 6u_1.u_3)y^4x^2 - (2u_1.u_4 + 18u_2.u_3)x^3y^3\]
\[+ (9u_3^2 + 6u_2.u_3)y^3x^4 - 6u_3.u_4.yx^5 + u_4^2.x^6.\]

Hence, supplying the reciprocal binomial coefficients,

\[1; -\frac{1}{6}; +\frac{1}{15}; -\frac{1}{20}; \frac{1}{15}; -\frac{1}{6}; 1,\]

we find

\[G_i = [0, 1]u_1^2 + 3[0, 2]u_1.u_2 + \left(\frac{1}{5}[0, 3] + \frac{2}{5}[1, 2]\right)(9u_3^2 + 6u_1.u_3)\]
\[+ \left(\frac{1}{10}[0, 4] + \frac{8}{10}[1, 3]\right)(u_1.u_4 + 9u_2.u_3) + \left(\frac{1}{5}[1, 4] + \frac{2}{5}[2, 3]\right)(9u_3^2 + 6u_2.u_4)\]
\[+ 3[2, 4]u_3.u_4 + [3, 4]u_4^2.\]

Now the Bezoutian square, taking account of the binomial factors in \(f\) and \(\varphi\), may be written under the form

\[
\begin{array}{cccc}
4[0, 1]; &amp; 6[0, 2]; &amp; 4[0, 3]; &amp; [0, 4] \\
6[0, 2]; &amp; 4[0, 3]; &amp; [0, 4]; &amp; 4[1, 4] \\
4[0, 3]; &amp; [0, 4]; &amp; [1, 4]; &amp; 6[2, 4] \\
[0, 4]; &amp; 4[1, 4]; &amp; 6[2, 4]; &amp; [3, 4].
\end{array}
\]

Hence the Bezoutian \(B\) becomes

\[4[0, 1]u_1^2 + 12[0, 2]u_1.u_2 + (4[0, 3] + 24[1, 2])u_2^2 + 2[0, 4]u_1.u_4\]
\[+ (2[0, 4] + 32[1, 3])u_2.u_3 + 8[1, 4]u_2.u_4 + ([1, 4] + 24[2, 3])u_3^2\]
\[+ 12[2, 4]u_3.u_4 + [3, 4]u_4^2.\]
And we ought to have $B = cG_1 + eG_3$, to satisfy which equation we must manifestly have $c = 4$; to find $(e)$, compare the coefficients of $u_2^2$, this gives

$$4[0, 3] + 24[1, 2] = \frac{36}{5}[0, 3] + \frac{72}{5}[1, 2] + e(3[1, 2] - [0, 3]);$$

accordingly we ought to be able to satisfy the two equations

$$\frac{36}{5} - e = 4 \quad \frac{72}{5} + 3e = 24,$$

each of which accordingly we find is satisfied by the equality $e = \frac{16}{5}$.

Substituting in the equation for $B$ above written, we thus obtain

$$B = 4G_1 + \frac{16}{5}G_3,$$

which will be found to be identically true.

Art (70.). We may now see our way to a more concise mode of obtaining the numerical coefficients [by which they may in fact be computed and verified with comparatively little labour], connecting the Bezoutiant with the co-bezoutiant forms of the constituent scale. It will not fail to have been remarked, that throughout the preceding determinations I have presumed the truth of the formulæ which admits of an immediate verification, that for all values of $m$ and $\omega$ we have the identical equation

$$\left(\frac{dz}{dx} + \eta \frac{d}{dy}\right)^\omega \left\{c_0x^m + mc_1x^{m-1}y + m \frac{m-1}{2}c_2x^{m-2}y^2 + \ldots + mc_{m-1}y^{m-1} + c_mx^m\right\}$$

$$= \frac{(m, m-1) \ldots (m-\omega+1)}{1.2 \ldots \omega} \left\{L_0x^\omega + c_0L_1x^{\omega-1}y + \omega \frac{\omega-1}{2}L_2x^{\omega-2}y^2 + \ldots + L_\omega y^\omega\right\},$$

where

$$L_0 = c_0x^{m-\omega} + (m-\omega)c_1x^{m-\omega-1}y + (m-\omega)\frac{m-\omega-1}{2}c_2x^{m-\omega-2}y^2 + \ldots + c_{m-\omega}y^m$$

$$L_1 = c_1x^{m-\omega} + (m-\omega)c_2x^{m-\omega-1}y + (m-\omega)\frac{m-\omega-1}{2}c_2x^{m-\omega-2}y^2 + \ldots + c_{m-\omega+1}y^m$$

$$\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots$$

$$L_\omega = c_\omega x^{m-\omega} + (m-\omega)c_{\omega+1}x^{m-\omega-1}y + (m-\omega)\frac{m-\omega-1}{2}c_2x^{m-\omega-2}y^2 + \ldots + c_{m}y^m.$$

Let us now proceed to determine by an abridged method the linear relations corresponding to the cases of $m = 5, m = 6,$ and first for $m = 5$.

Let

$$f = ax^5 + bx^4y + 10cx^3y^2 + 16dx^2y^3 + 5exy^4 + hy^5$$

$$\varphi = ax^5 + 5bx^4y + 10cyx^3y^2 + 10dx^2y^3 + 5exy^4 + ey^5$$

$$\Omega = u_1y^4 - 4u_2yx^3 + 6u_3yx^3 - 4u_4yx^3 + u_5y^4.$$ 

In forming $G_5, G_3, G_1$, let us confine our attention to the terms $u_1^2; u_1u_3; u_1u_4$.
A comparison of the coefficients of these with those in the Bezoutiant (B) will be sufficient for assigning the three numerical quantities which connect B with $G_1$, $G_3$, $G_5$. I omit $u_1.u_2$, because $G_1$ is the only one of the G&#x27;s for any value of $(m)$ which contains $u_1^2$ or $u_1.u_2$, and in $G_1$ the terms containing $u_1^2$ and $u_1.u_2$ are

$$[0, 1]u_1^2 + (m-1)[0, 2].u_1.u_2,$$

and the corresponding part of the Bezoutiant is

$$m[0, 1]u_1^2 + m.(m-1)[0, 2]u_1.u_2;$$

so that if we write

$$B = c_1.G_1 + c_3.G_3 + c_5.G_5 + &amp;c.,$$

the two terms $u_1^2$ and $u_1.u_2$ will only enable us to form one equation with the $c$&#x27;s, viz. $c_1=m$. Again, instead of considering the entire coefficients of $u_1.u_3$ and $u_1.u_4$, it will be sufficient to take a single argument of either of these coefficients (in the forms to be compared), as for instance $[0, 3]$ and $[1, 3]$. Then $c_1$ being known, $c_3$, $c_5$ will be determined; but for the purposes of verification I shall furthermore compute the whole of the coefficient of $u_1.u_5$.

Accordingly [calculating the G system in reverse order] we have

$$G_5 = \{[0, 5] - 5[1, 4] + 10[2, 3]\} \{u_1.u_5 - 4u_2.u_4 + .3u_3\}$$

$$= \{[0, 5] - 5[1, 4] + 10[2, 3]\} u_1.u_5 + ...$$

$$E_3.f = (ax^2 + 2bxy + cy^2)\xi^2 + 3(bx^2 + 2cxy + dy^2)\xi^2y + 3(cx^2 + 2dxy + ey^2)\xi^2y + (dx^2 + 2exy + fy^2)\xi^2;$$

$$E_3.\phi = &amp;c. &amp;c.;$$

$$\therefore T_s = \{(ax^2 + 2bxy + cy^2)(\delta x^2 + 2\epsilon xy + \eta y^2) - (ax^2 + 2\beta xy + \gamma y^2)(dx^2 + 2exy + hy^2)\}$$

$$- \{3(bx^2 + 2cxy + dy^2)(\gamma x^2 + 2\delta xy + \epsilon y^2) - (\beta x^2 + 2\gamma xy + \delta y^2)(cx^2 + 2dxy + ey^2)\}$$

$$= [0, 3]x^4 + (2[0, 4] + ...)x^3y + \{[0, 5] + [1, 4] - 8[2, 3]\}x^2y^2 + &amp;c.$$

[The number $-8$ results from the calculation $1 - 3(4 - 1) = -8$.]

Again,

$$E_2.\Omega = (u_1.y^2 - 2u_2yx + u_3.x^2)\xi^2 - 2(u_2.y^2 - 2u_3.yx + u_4.x^2)\xi^2y + (u_3.y^2 - 2u_4.yx + u_5.x^2)\xi^2y,$$

$$\therefore Q_s = (u_1.y^2 - 2u_2yx + u_3.x^2)(u_3.y^2 - 2u_4.yx + u_5.x^2) - (u_2.y^2 - 2u_3.yx + u_4.x^2)^2$$

$$= u_1.u_3.y^4 - 2u_1.u_4.y^3x + u_1.u_5.y^2x^2 + &amp;c.,$$

all the terms and parts of terms unexpressed being free of $u_1$, and therefore not necessary for our purpose. Hence supplying the reciprocal factors

$$1; \quad -\frac{1}{4}; \quad \frac{1}{6}; \quad ...,$$

we have

$$G_3 = [0, 3]u_1.u_3 + ([0, 4] + )u_1.u_4 + \frac{1}{6}\{[0, 5] + [1, 4] + [2, 3]\}u_1.u_5 + &amp;c.$$

Again, expressing $E_1.f$ and $E_1.\phi$ in the usual way, we obtain
\[
T_1 = (ax^4 + 4bx^3y + 6cx^2y^2 + 4dxy^3 + ey^4)(3x^4 + 4\gamma x^3y + 6\delta x^2y^2 + 4\epsilon xy^3 + \eta y^4) \\
- (ax^4 + 4\beta x^3y + 6\gamma x^2y^2 + 4\delta xy^3 + ey^4)(bx^4 + 4cx^3y + 6dx^2y^2 + 4exy^3 + hy^4)
\]

\[= [0, 1]x^8 + 4[0, 2]x^7y + (6[0, 3] + )x^6y^2 + (4[0, 4] + )x^5y^3 + ([0, 5] \\
+ 15[1, 4] + 20[2, 3])x^4y^4 + &amp;c.\]

(where it may be observed that the numbers 15 and 20 in the coefficient of \(x^4.y^4\) arise from the quantities \(4^2 - 1; 6^2 - 4^2\)).

Again, \(Q_i = \Omega^2 = u_1^2.x^8 + 8u_1.u_2x^7y + 12u_1.u_3x^6y^2 - 8u_1.u_4x^5y^3 + 2u_1.u_5.x^4y^4 + &amp;c.\)

Hence supplying the multipliers

\[1; \frac{-1}{8}; \frac{1}{28}; \frac{-1}{56}; \frac{1}{70}; &amp;c.\]

we have

\[G_i = [0, 1]u_1^2 + 4[0, 2]u_1.u_2 + \frac{18}{7}[0, 3]u_1.u_3 + \frac{4}{7}[0, 4]u_1.u_4 \\
+ \frac{1}{35}([0, 5] + 15[1, 4] + 20[2, 3])u_1.u_5.\]

Again, the Bezoutiant

\[B = 5[0, 1]u_1^2 + 2.10[0, 2]u_1.u_2 + 2.10[0, 3]u_1.u_3 + 2.5[0, 4]u_1.u_4 + 2.[0, 5]u_1.u_5 + &amp;c.\]

Accordingly, if we write \(B = c_1.G_1 + c_2.G_2 + c_3.G_3 + c_4.G_4 + c_5.G_5\), we have, as above remarked, \(c_1 = 5\); and to determine \(c_3, c_5\), we have, by comparing the coefficients of \(u_1.u_3, u_1.u_4\) in \(B, G_1, G_3, G_5\),

\[20 = \frac{90}{7} + c_3\]
\[10 = \frac{20}{7} + c_3.\]

These two equations, then, as it turns out, are not independent, but are satisfied simultaneously by

\[c_3 = \frac{50}{7}.\]

Finally, equating the coefficients of the several arguments in \(u_1.u_5\), we have

\[0 = 5 \times \frac{1}{35} + \frac{50}{7} \times \frac{1}{6} + c_5 \text{ from the argument } [0, 5]\]
\[0 = 5 \times \frac{15}{35} + \frac{50}{7} \times \frac{1}{6} + 5c_5 \text{ from the argument } [1, 4]\]
\[0 = 5 \times \frac{20}{35} + \frac{50}{7} \times \frac{8}{6} + 10c_5 \text{ from the argument } [2, 3].\]

The 1st of which equations gives

\[c_5 = 2 - \frac{1}{7} - \frac{25}{21} = \frac{14}{21} = \frac{2}{3};\]

the 2nd gives

\[c_5 = \frac{3}{7} + \frac{5}{21} = \frac{2}{3},\]
and the 3rd gives

\[ c_5 = \frac{20}{21} + \frac{2}{7} = \frac{2}{3}. \]

We have thus abundantly verified the accuracy of the calculation, and there results the relation

\[ B = 5G_1 + \frac{50}{7}G_3 + \frac{2}{3}G_5. \]

Lastly, let \( m = 6 \),

\[
\begin{align*}
f &amp;= ax^6 + 6bx^5y + 15cx^4y^2 + 20dx^3y^3 + 15ex^2y^4 + 6hxy^5 + ly^6 \\
\varphi &amp;= ax^6 + 6\beta x^5y + 15\gamma x^4y^2 + 20\delta x^3y^3 + 15\varepsilon x^2y^4 + 6\eta xy + \lambda y^6 \\
\Omega &amp;= u_1.y^5 - 5u_2.y^4x + 10u_3.y^3x^2 - 10u_4.y^2x^3 + 50yx^4 - u_6.x^6.
\end{align*}
\]

I shall here confine myself to the determination of a single argument in each of the terms \( u_1; u_1.u_2; u_1.u_3; u_1.u_4; u_1.u_5; u_1.u_6 \); this will be ample for the purpose of verification, as the equation to be assigned is of the form

\[ B = c_5.G_1 + c_3.G_3 + c_5.G_5. \]

The arguments which I select as the most simple, will be those expressed by the symbols \((0, 1); (0, 2); (0, 3); (0, 4); (0, 5); (0, 6)\) respectively, then we have

\[
\begin{align*}
T_5 &amp;= (ax + by)(\alpha x + \lambda y) + &amp;c. - (hx + ly)(\alpha x + \beta y) \\
&amp;= ([0, 5] + ...)x^5 + ([0, 6] + ...)xy + (...)y^2 \\
Q_5 &amp;= (u_1.y - u_2x)(u_3.y - u_6x) + &amp;c. \\
&amp;= (u_1.u_5 + ...)y^5 - (u_1.u_6 + ...)yx + (...)x^2.
\end{align*}
\]

Hence supplying the binomial reciprocals

\[ G_5 = ([0, 5] + ...)u_1.u_5 + \frac{1}{2}([0, 6] + ...)u_1.u_6 + &amp;c. \]

Again,

\[
\begin{align*}
T_3 &amp;= (ax^3 + ...)(\delta x^3 + 3\epsilon x^2y + 3\eta xy^2 + \lambda y^3) + &amp;c. - (dx^3 + 3ex^2y + 3hxy^2 + ly^3)(\alpha x^3 + ...) \\
&amp;= ([0, 3] + ...)x^6 + (3[0, 4] + ...)x^5y + (3[0, 5] + ...)x^4y^2 + ([0, 6] + ...)x^3y^3 + &amp;c. \\
Q_3 &amp;= (u_1.y^3 + &amp;c.)(u_3.y^3 + 3u_4y^2 + 3u_7x^2 - u_6x^3) - &amp;c. \\
&amp;= (u_1.u_3 + ...)y^6 - (3u_1.u_4 + ...)y^5x + (3u_1.u_5 + ...)y^4x^2 - (u_1.u_6 + ...)y^3x^3 + &amp;c.,
\end{align*}
\]

and the reciprocal binomial multipliers will be

\[ 1; \quad -\frac{1}{6}; \quad \frac{+1}{15}; \quad -\frac{1}{20}; \quad &amp;c. \]

Hence

\[ G_3 = [0, 3]u_1.u_3 + \frac{3}{2}[0, 4]u_1.u_4 + \frac{3}{5}[0, 5]u_1.u_5 + \frac{1}{20}[0, 6]u_1.u_6 &amp;c. &amp;c. \]
Finally,

\[ T_1 = (ax^5 + \&amp;c.) (\beta x^5 + 5\gamma x^4 y + 10\delta x^3 y^2 + 10\varepsilon x^2 y^3 + 5\eta xy^4 + \lambda y^5) - \&amp;c. \]

\[ = ([0, 1] + \&amp;c.) x^{10} + 5([0, 2] + \&amp;c.) x^9 y + (10[0, 3] + \&amp;c.) x^8 y^2 + (10[0, 4] + \&amp;c.) x^7 y^3 \]

\[ + (5[0, 5] + \&amp;c.) x^6 y^4 + ([0, 6] + \&amp;c.) x^5 y^5 + \&amp;c. \]

\[ Q_1 = \Omega^2 = u_1^2 y^{10} + (10u_1 u_2 + \&amp;c.) y^9 x + (20u_1 u_3 + \&amp;c.) y^8 x^2 + (20u_1 u_4 + \&amp;c.) y^7 x^3 \]

\[ + (10u_1 u_5 + \&amp;c.) y^6 x^4 + (2u_1 u_6 + \&amp;c.) y^5 x^5 + \&amp;c.; \]

and supplying the numerical series

\[ 1; \quad -\frac{1}{10}; \quad \frac{1}{45}; \quad -\frac{1}{120}; \quad \frac{1}{210}; \quad -\frac{1}{252}; \quad \&amp;c., \]

we have

\[ G_1 = [0, 1] u_1^2 + 5[0, 2] u_1 u_2 + \frac{40}{9}[0, 3] u_1 u_3 + \frac{5}{3}[0, 4] u_1 u_4 \]

\[ + \frac{5}{21}[0, 5] u_1 u_5 + \frac{1}{126}[0, 6] u_1 u_6 + \&amp;c. \]

Again, the Bezoutiant

\[ = 6[0, 1] u_1^2 + 30[0, 2] u_1 u_2 + 40[0, 3] u_1 u_3 + 30[0, 4] u_1 u_4 \]

\[ + 12[0, 5] u_1 u_5 + 2[0, 6] u_1 u_6 + \&amp;c. = B. \]

Hence making

\[ B = c_1 G_1 + c_3 G_3 + c_5 G_5, \]

from \( u_1^2 \) and \( u_1 u_2 \) we obtain respectively

\[ c_1 = 6 \]

\[ 5c_1 = 30; \]

hence from \( u_1 u_3 \) and \( u_1 u_4 \) we obtain respectively

\[ \frac{240}{9} + c_3 = 40 \]

\[ \frac{30}{3} + \frac{3}{2} c_3 = 30 \]

or \( c_3 = \frac{40}{3}; \)

hence from \( u_1 u_5 \) and \( u_1 u_6 \) we obtain respectively

\[ 6 \times \frac{5}{21} + \frac{40}{3} \cdot \frac{3}{5} + c_5 = 12, \text{i.e. } c_5 = 12 - 8 - \frac{10}{7} = \frac{18}{7} \]

\[ 6 \times \frac{1}{126} + \frac{40}{3} \cdot \frac{1}{20} + \frac{1}{2} c_5 = 2, \text{i.e. } \frac{1}{2} c_5 = 2 - \frac{2}{3} - \frac{1}{21} = \frac{9}{7}; \]

hence

\[ c_5 = \frac{18}{27}, \]

and the equation sought for is

\[ B = 6G_1 + \frac{40}{3} G_3 + \frac{18}{7} G_5. \]

Art. (71.). The following table exhibits the relations between the Bezoutiant and
the correspondent system of Co-bezoutiants for all values of $m$ between 1 and 6 under a synoptical form.

\[
\begin{align*}
m=1 &amp; \quad B=G_1 \\
m=2 &amp; \quad B=2G_1 \\
m=3 &amp; \quad B=3G_1-4G_3 \\
m=4 &amp; \quad B=4G_1+\frac{16}{5}G_3 \\
m=5 &amp; \quad B=5G_1+\frac{50}{7}G_3+\frac{2}{3}G_5 \\
m=6 &amp; \quad B=6G_1+\frac{40}{3}G_3+\frac{18}{7}G_5.
\end{align*}
\]

These series could if wanted be easily extended, and the calculation of the coefficients reduced to a mere mechanical procedure.

If we suppose $m$ to be $2i$ or $2i-1$, we have the equation

\[B=c_1G_1+c_3G_3+\ldots+c_{2i-1}G_{2i-1};\]

and it appears from the foregoing instances that the comparison of the coefficients, either of $u_1^2$, or of $u_1,u_2$ on the two sides of the equation, will serve to give $c_1$ and $c_i$ (which is always $m$ being known), $c_3$ may be found by a comparison of the coefficients either of $u_1,u_3$, or of $u_1,u_4$, and so on for $c_5,\ldots,c_{2i-1}$; all the coefficients in the equation for $B$ above given, thus admitting of being found separately and successively and in two modes, so that there is a check at each step upon the correctness of the computations: the only exception to this last remark is (when $m$ is odd) for the last coefficient of which the above condensed method affords only a single determination.

I need hardly add the remark, that in substituting $x^{m-1}, x^{m-2}.y; \ldots x.y^{m-2}\ldots y^{m-1}$ in place of $u_1, u_2, \ldots u_{m-1}, u_m$ respectively, all the $G$&#x27;s become (to a numerical factor près) identical with one another and with the Jacobian to the system $(f\phi)$.

Art. (72.). The foregoing theory took its origin (as will have been readily imagined) in meditations growing out of the celebrated theorem of M. Sturm. There appear to be several directions in which a development or extension of the subject matter of that theorem may be sought for. Thus a theory may be constructed relative to a single function of one or more variables, viewed in all cases as representing a geometrical locus. In the limiting case, when this locus becomes a system of points in a right line, we have the theorem of Sturm; generally the theory will be that of contours. Or, again, a theory may be formed in which the number of functions is always kept equal to that of the variables. We have then a theory of discreet points corresponding to roots, the number of real ones of which comprised within given limits it is the object of such theory to determine. M. Hermite, in a memoir recently presented to the French Institute, appears to have made a valuable addition to the Sturmian theory extended in this direction, to which the beautiful researches of M. Cauchy and the joint labours of MM. Liouville and Sturm, with reference to
the disposition of the imaginary roots of equations appear to have led the way. Finally, the number of variables may be supposed to be arbitrarily increased, but made always inferior by a unit to the number of the functions in which they are contained, or which comes to the same thing, we may construct the theory of a system of homogeneous functions equal in number to the variables in them, which in its simplest case becomes the theory of Intercalations which has been here partially considered, and which (as has been shown) embraces (not as a particular case, but as an implied consequence and easily extricated result) the theorem of M. Sturm.

London, June 25, 1853.

General and Concluding Supplement.

Art. (N.). The expressions given in art. (n.) for the partial quotients of the continued fraction represented by \( \frac{f(x)}{g(x)} \), are restricted to the supposition of all these partial quotients (except the first) being linear in \( x \); when the first partial quotient is linear the formula (B.) of that article continues applicable on replacing \((D, h)\) by 1. I was forcibly struck by the peculiarity of these formulæ not ceasing to be true in consequence of the first partial quotient being supposed non-linear; and reflecting upon this, I was soon led to perceive that all the partial quotients might be supposed to be arbitrary integral functions of \( x \), and the formulæ would still continue to apply to any such of them as might happen to be linear, although, as it were, imbedded among a group of other non-linear partial quotients. From this it was but an easy step to perceive that the formulæ A and B must admit of extension to the representation of partial quotients of any form, and that the dimorphism of the representation of the linear partial quotients could only be a consequence of the equation in integers \( u + v = 1 \) having two solutions \( u = 0, v = 1 \) and \( u = 1, v = 0 \). I now proceed to enunciate the very remarkable general theorem (or as it may perhaps not inappropriately be termed Algebraical Porism), by virtue of which any partial quotient of a given degree in \( x \) belonging to an infinite continued fraction, all of whose partial quotients are algebraical functions of \( x \), may be expressed to a constant factor près, by means of the numerator and denominator (or if we please either one of these) of the convergent immediately antecedent to and of the numerator and denominator of any convergent not antecedent to the partial quotient which is to be determined.

Art. (2.). Theorem. Let \( Q_1, Q_2, \ldots, Q_i, Q_{i+1}, \ldots, Q_n, \&amp;c. \), each of an arbitrary degree in \( x \), be the \( n \) first partial quotients of an algebraical continued fraction; let \( Q_{i+1} \) be the partial quotient to be determined and of the given degree \( \omega_i \); let

\[
\frac{1}{Q_1} - \frac{1}{Q_2} - \frac{1}{Q_3} - \cdots - \frac{1}{Q_i} = \frac{\varphi_i(x)}{f_i(x)}
\]

and

\[
\frac{1}{Q_1} - \frac{1}{Q_2} - \frac{1}{Q_3} - \cdots - \frac{1}{Q_{i+1}} - \cdots - \frac{1}{Q_n} = \frac{\Phi(x)}{F(x)};
\]

let \( u \) and \( v \) be any couple of integers of the \( \omega_{i+1} + 1 \) couples which satisfy the equation \( u + v = \omega_{i+1} \); then, as usual, denoting the product of the differences of each of one set
of terms from each of another set, by writing the former under the latter, and calling \( \eta_1, \eta_2, \ldots, \eta_\mu \) the \( \mu \) roots of \( \Phi(x) \), and \( h_1, h_2, \ldots, h_m \) the \( m \) roots of \( F(x) \), (\( \Phi \) and \( F \) being supposed respectively of \( \mu \) and \( m \) dimensions in \( x \)), and forming the disjunctive equations

\[
\begin{align*}
\theta_1, \theta_2, \theta_3, \ldots, \theta_\mu &amp;= 1, 2, 3, \ldots, \mu \\
t_1, t_2, t_3, \ldots, t_m &amp;= 1, 2, 3, \ldots, m,
\end{align*}
\]

we have the following equation,

\[
Q_{i+1} = K_{u,v} \times \sum \left\{ (\varphi_{\theta_1}, \varphi_{\theta_2}, \ldots, \varphi_{\theta_\mu})^2 \times (fh_{t_1}, fh_{t_2}, \ldots, fh_{t_u})^2 \right\}
\]

and moreover the different values of \( K_{u,v} \) depending upon the different modes of breaking up \( \omega_i \) into two parts \( u \) and \( v \) are all (to a numerical factor près) equal to one another. Thus then the theorem pointed at in art. (p.) is discovered, and the way laid open (by an unexpected channel) for a complete discussion of the theory of the singular cases which may occur in the expansion of any rational algebraical fraction under the form of a continued fraction.

Art. (2.). In the above expression, if we suppose \( \omega_i = 1 \), we have \( u = 1 \) and \( v = 0 \), or \( u = 0 \) and \( v = 1 \), and remembering that

\[
\begin{bmatrix}
h \\
\eta_1, \eta_2, \ldots, \eta_\mu
\end{bmatrix} = \Phi h \quad \text{and} \quad \begin{bmatrix}
\eta \\
h_1, h_2, \ldots, h_m
\end{bmatrix} = F h
\]

\[
\begin{bmatrix}
h_{t_1} \\
h_{t_2}, h_{t_3}, \ldots, h_{t_m}
\end{bmatrix} = F&#x27; h, \quad \text{and} \quad \begin{bmatrix}
\eta_{\theta_1} \\
\eta_{\theta_2}, \eta_{\theta_3}, \ldots, \eta_{\theta_\mu}
\end{bmatrix} = \Phi&#x27; h,
\]

\( Q_{i+1} \) becomes by virtue of the general formula representable under either of the equivalent forms

\[
K_{0,1} \sum_{\mu} \left\{ (\varphi_{\theta_1}, \varphi_{\theta_2}, \ldots, \varphi_{\theta_\mu})^2 \frac{F_{\eta_{\theta}}}{\Phi_{\eta_{\theta}}} (x - \eta_{\theta}) \right\} \quad \text{and} \quad K_{1,0} \sum_{m} \left\{ (fh_{t_1})^2 \frac{\Phi_{h_t}}{F_{h_t}} (x - h_t) \right\},
\]

\( K_{0,1} \) and \( K_{1,0} \) being either equal, or differing only in the sign agreeably to the formulæ A and B.

Art. (7.). It may be worth while to notice, that, although (of course) these formulæ and the general formulæ of (art. 2.), when supposed converted into functions of \( x \) and of the coefficients of \( F \) and of \( \Phi \) by the reduction, integration and summation of the symmetrical functions of the roots which enter into them remain universally valid, and subject to no cases of exception, yet antecedently to these processes being performed the formulæ as they stand may become illusory when any relations of equality exist between the roots of \( \Phi \) inter se, or between the roots of \( F \) inter se. Thus in the case before us, if \( \Phi \) have equal roots the formulæ commencing with \( K_{0,1} \) is illusory, and if \( F \) have equal roots the other of the two formulæ becomes illusory.

Let us take the second of these and suppose that \( F(x) \) has

\( k_1 \) roots \( c_1, k_2 \) roots \( c_2, \ldots, k_p \) roots \( c_p \),
we may pass to the actual case from any case where the roots are infinitesimally near to the actual roots of $F(k)$, and all infinitesimally different from one another. Moreover the choice of the infinitesimal variations being arbitrary, let the $k_1$ roots $c_i$ be replaced by a group of roots

$$c_i + \delta; c_i + \delta_{\xi_1}; c_i + \delta_{\xi_2}; \ldots; c_i + \delta_{\xi_{k_1-1}},$$

where $\xi_i$ is a prime root of the equation $\varepsilon^{k_1} = 0$, and $\delta$ is an infinitesimal quantity, and suppose each of the other groups to be varied in an analogous manner. Then it may easily be shown from this that the one of the formulæ in question will become

$$K_1 \sum_{p} k_i \left( \frac{d}{dc_i} \right)^{k-1} \left\{ (f_{c_i})^3 (\Phi_{c_i})(x - c_i) \right\}$$

and similarly, the twin formula becomes

$$K_1 \sum_{q} \left( \frac{d}{dy_q} \right)^{n-1} \left\{ (\Phi y_q)^3 (F y_q)(x - y_q) \right\}.$$  

Corresponding modifications will admit of being made by aid of a like method in the general formulæ of art. (2.) upon a similar supposition as to equalities springing up between the roots of $fx$ per se and of $\varphi(x)$ per se, or between the roots of $fx$ and $\varphi x$ inter se.

Art. (7.). If in (art. 2.) we take $i = 0$, the formula for $Q_{i+1}$ will become

$$Q_1 = K_{u,v} \begin{bmatrix} \eta_{\theta_1} &amp; \eta_{\theta_2} &amp; \ldots &amp; \eta_{\theta_u} \\ h_{t_1} &amp; h_{t_2} &amp; \ldots &amp; h_{t_u} \\ \eta_{\theta_{u+1}} &amp; \eta_{\theta_{u+2}} &amp; \ldots &amp; \eta_{\theta_{u+v}} \\ h_{t_{u+1}} &amp; h_{t_{u+2}} &amp; \ldots &amp; h_{t_{u+v}} \end{bmatrix} \times \begin{bmatrix} \eta_{\theta_{u+v+1}} &amp; \eta_{\theta_{u+v+2}} &amp; \ldots &amp; \eta_{\theta_{u+v+\mu}} \\ h_{t_{u+v+1}} &amp; h_{t_{u+v+2}} &amp; \ldots &amp; h_{t_{u+v+\mu}} \end{bmatrix},$$

$u$ and $v$ being any two integers whose sum is $\omega_1$, which is identical (as it ought to be) with the expression virtually contained in the formulæ of Section II. for the syzygetic multiplier of $\Phi(x)$ in the syzygetic equation connecting $Fx$ and $\Phi x$ with their first residue when $\Phi x$ is supposed to be $\omega_1$ dimensions in $x$ lower than $Fx$ identical, *videlicet*, in other words, with the integer part of the algebraical fraction $\frac{F(x)}{\Phi(x)}$.

* For in general if $\rho$ is a prime root of the equation $\rho^\omega = 1$, and if $fx$ have $\omega$ roots all equal to $c$ and $\psi x$ is any other function of $x$ and if $\delta$ is an infinitesimal quantity, then rejecting all powers of $\delta$ higher than the $(\omega-1)$th degree,

$$\frac{\psi(c + \delta) + \psi(c + \rho \delta) + \psi(c + \rho^2 \delta) + \ldots + \psi(c + \rho^{\omega-1} \delta)}{f&#x27;(c + \delta) + f&#x27;(c + \rho \delta) + f&#x27;(c + \rho^2 \delta) + \ldots + f&#x27;(c + \rho^{\omega-1} \delta)}$$

$$= \frac{1}{\left( \frac{d}{dc} \right)^\omega f c \delta^{\omega-1}} \left\{ \psi(c + \delta) + \rho \psi(c + \rho \delta) + \rho^2 \psi(c + \rho^2 \delta) + \ldots + \rho^{\omega-1} \psi(c + \rho^{\omega-1} \delta) \right\}$$

$$= \frac{\left( \frac{d}{dc} \right)^\omega f c \delta^{\omega-1}}{\left( \frac{d}{dc} \right)^\omega f c} = \omega \left( \frac{d}{dc} \right)^\omega \psi c.$$
Art. (1.). When $\Phi(x) = F&#x27;(x)$,

$$\begin{bmatrix}
\Phi(h_1) &amp; \Phi(h_2) &amp; \ldots &amp; \Phi(h_{\omega_i+1}) \\
h_1 &amp; h_2 &amp; \ldots &amp; h_{\omega_i+1} \\
h_1 + \omega_i + 1 &amp; h_2 + \omega_i + 2 &amp; \ldots &amp; h_m
\end{bmatrix}$$

becomes identical with $(-)^{\frac{1}{2}(\omega_i+1-1)\omega_i+1}\zeta(h_1, h_2, \ldots, h_{\omega_i+1})$,

and we may consequently (using an extreme term in the forms in the polymorphic scale of forms representing $Q_{i+1}$), write

$$Q_{i+1} = (-)^{\frac{1}{2}(\omega_i+1-1)\omega_i+1}K_{0, \omega_i+1}\Sigma\zeta(h_1, h_2, \ldots, h_{\omega_i+1})(f_1 h_1)^2(f_2 h_2)^2 \ldots (f_{\omega_i+1} h_{\omega_i+1})^2(x-h_1)(x-h_2) \ldots (x-h_{\omega_i+1}).$$

Art. (2.). The following observations will serve to complete the theory of the singular cases in the expansion of an algebraical continued fraction.

Preserving the notation of art. (2.), let

$$\sigma_i = m - (\omega_1 + \omega_2 + \ldots + \omega_{i-1} + 1),$$

Then (calling the roots of $Fx$, $h_1, h_2, \ldots, h_m$) the $(i)$th simplified residue to $\frac{\Phi x}{F(x)}$, in accordance with the general formulæ for the residues in the second section (for greater simplicity selecting an extreme term of the polymorphic scale), will be represented by

$$\Sigma \begin{bmatrix}
\Phi h_1 &amp; \Phi h_2 &amp; \Phi h_3 &amp; \ldots &amp; \Phi(h_{\sigma_i}) \\
h_1 &amp; h_2 &amp; h_3 &amp; \ldots &amp; h_{\sigma_i} \\
h_1 + \sigma_i &amp; h_2 + \sigma_i &amp; h_3 + \sigma_i &amp; \ldots &amp; h_m
\end{bmatrix}(x-h_1)(x-h_2)(x-h_3) \ldots (x-h_{\sigma_i}),$$

which will be of the form $L_{\sigma_i}x^{\sigma_i-\omega_i+1} + \&amp;c.$, all the terms containing powers of $x$ superior to $\sigma_i$ vanishing by the coefficients becoming zero. If in the above expression we should use $\sigma_i$ in lieu of $\sigma_i$, where $\sigma_i$ is $\sigma_i$ diminished by any integer inferior to $\omega_i$, we should get other forms of the same residue, but these will all be of higher dimensions in the roots or coefficients than the one just given, and in fact the forms thus obtained corresponding to the values $\sigma_i, \sigma_i-1, \sigma_i-2, \ldots, \sigma_i-\omega_i+1$ substituted for $\sigma_i$ in succession, would by aid of the relations of condition between the coefficients of $\Phi x$ and $Fx$ implied in the value of $\omega_i$ admit of being exhibited as a scale in which each form would be an exact algebraical product of the form which precedes it, multiplied by a function of the coefficients, and did space permit thereof it would be perfectly easy to give the forms of these multiplicators. But I pass on to the representation of what is more material, viz. the form of the complete residue in the case supposed, merely observing (as an obiter dictum) that the existence of each singular partial quotient (meaning thereby a quotient non-linear in $x$) only affects the form of the single simplified residue in immediate connexion with itself, and not at all the form of the other residues antecedent or subsequent to that one.

Art. (3.). Let the $i$th simplified residue be called $R_i$ and the corresponding complete residue $[R_i]$, then applying a method similar to the method given in Section I., we shall find that

$$(-)^{\frac{1}{2}}[R_i] = \frac{L_{\omega_i-1+1}, L_{\omega_i-4+1}, \&amp;c.}{L_{\omega_i-3+1}, L_{\omega_i-3+1}, \&amp;c.} R_i,$$
$L_i$ representing the leading coefficient in the (ith) simplified residue, and the sign of interrogation (?) denoting some function of $\omega_1 \omega_2 \ldots \omega_i$ (possibly a constant) remaining to be determined. And reverting to art. (2.), the quantity that would be called $K_{0,\omega_i}$ according to the notation employed in the formulæ expressing $Q_{i+1}$ in that article, will (abstraction being made of the algebraical sign and using for greater brevity $(i)$, $(i-1)$, &amp;c. to express $1+\omega_i$, $1+\omega_{i-1}$, &amp;c.) come to be represented by

$$\frac{L_{i-1}^{(i-1)}}{L_i^{(i)}}, \frac{L_{i-3}^{(i-3)}}{L_i^{(i-2)}}, \frac{L_{i-5}^{(i-5)}}{L_i^{(i-4)}} \text{ &amp;c.}$$

a similar convention being supposed to be made respecting the numerator and denominator of each convergent as was made respecting them in the particular case treated of in art. (f), page 473.

Art. (2.). I will merely add a very few words in generalization of the method of limiting the roots of $f(x)$ given in the Supplement to the fourth Section. As an inferior limit to $f(x)$ is identical with a superior limit to $f(-x)$, we may confine our attention to superior limits alone. Suppose then that

$$\frac{\varphi x}{f(x)} = \frac{1}{Q_1 - Q_2} \cdot \frac{1}{Q_3 - Q_4} \cdot \frac{1}{Q_5 - Q_6} \cdots \frac{1}{Q_i - Q_{i+1}} \cdots \frac{1}{(Q)_1 - (Q)_2} \cdots \frac{1}{(Q)_i},$$

where the partial quotients $Q$ are each of any arbitrary degree in $x$, and have all one algebraical sign in the coefficients of the highest powers of $x$ from $Q_1$ to $Q_5$, and all the same sign (contrary to the former), in the coefficients of the highest powers of $x$ from $Q&#x27;_i$ to $Q&#x27;_i$, and so on alternately, then $1^o$, a superior limit to the superior limits of the cumulants $[Q_1 Q_2 \ldots Q_i]$, $[Q&#x27;_1 Q&#x27;_2 \ldots Q&#x27;_i]$, ... $[(Q)_1 (Q)_2 \ldots (Q)_i]$ will be a superior limit to $f(x)$, so that it remains only to give a rule for finding a superior limit to a cumulant $[Q_1 Q_2 Q_3 \ldots Q_i]$, which, $2^o$, is to be found by making

$$Q_1 - M_1 = 0, \quad Q_2 - M_2 = 0, \quad Q_3 - M_3 = 0 \ldots Q_i - M_i = 0,$$

where

$$M_1 = \mu_1, \quad M_2 = \mu_2 + \frac{1}{\mu_1}, \quad M_3 = \mu_3 + \frac{1}{\mu_2} \ldots M_i = \frac{1}{\mu_{i-1}},$$

$\mu_1, \mu_2, \ldots \mu_{i-1}$ being any quantities entirely independent and arbitrary except in regard to their being all of the same sign as the leading coefficient in the element $Q_1, Q_2 \ldots Q_i$.

We may then find $L_1, L_2, \ldots L_i$ any superior limits to the roots of $x$ in these $i$ equations respectively; $L$, the greatest of these, will be a superior limit to the proposed cumulant $[Q_1 Q_2 \ldots Q_i]$; and it may be observed that $M_1 M_2 \ldots M_i$ are the general values which satisfy the equation

$$M_1 - \frac{1}{M_2} - \frac{1}{M_3} \cdots \frac{1}{M_i} = 0,$$

subject to the condition that for all values of $e$

$$\frac{1}{M_e} - \frac{1}{M_{e-1}} - \frac{1}{M_{e-2}} \cdots \frac{1}{M_1}$$

shall have a given invariable sign. The first part of the process, as just shown, consists in separating the type of the total cumulant which represents $f(x)$ into partial
types, the point for each fracture of the total type being marked by a change of sign in the elements of the type for the value \( x = +\infty \); it is easily seen therefore from this, that if \( \frac{\Phi_x}{F_x} \) is the generatrix of the cumulant in question, the number of such fractures (i.e. the number one less than the number of partial cumulants) will be the number of changes of algebraical sign in the signaletic series, consisting of the leading coefficients in \( F_x \) and in each of the odd-placed complete residues respectively, together with the number of changes of sign in the signaletic series, consisting of the leading coefficients in \( \Phi_x \) and in each of the even-placed complete residues respectively.

The syzygetic theory of two algebraical functions, and the allied theory of algebraical continued fractions with their principal applications, may, I think, now be said to be completely made out, as well for the singular cases as for the general hypothesis.

Art. (&#x27;). I will conclude with observing that the theory within developed gives the means of transforming (explicitly and without the aid of symmetrical functions) into an algebraical continued fraction, any given sum of algebraical fractions of the form

\[
\frac{c_1}{x-h_1} + \frac{c_2}{x-h_2} + \frac{c_3}{x-h_3} + \cdots + \frac{c_n}{x-h_n},
\]

where each \( c \) and \( h \) are supposed known. For let the above sum be called \( \frac{\Phi_x}{F(x)} \), then if \( h_g, c_g \) be used to denote any pair of corresponding terms of the \( h \) series and the \( c \) series, we have \( \frac{\Phi_h}{F_h} = c_g \), as is well known and easily proved. Again, if \( D_ix \) represent the simplified denominator of the \( i \)th convergent to the continued fraction equal to \( \frac{\Phi_x}{F(x)} \) which is to be found, say

\[
\frac{1}{(A_1x+B_1)} - \frac{1}{(A_2x+B_2)} - \cdots - \frac{1}{A_nx+B_n},
\]

we have \( D_ix = \sum_{h_i} \frac{\Phi_{h_1} \Phi_{h_2} \cdots \Phi_{h_i}}{f_{h_1} f_{h_2} \cdots f_{h_i}} (x-h_1)(x-h_2) \cdots (x-h_i) \),

\[
= \sum (-)^{\frac{i-1}{2}} \frac{\zeta(h_1, h_2, \ldots, h_i) \Phi_{h_1} \Phi_{h_2} \cdots \Phi_{h_i}}{f_{h_1} f_{h_2} \cdots f_{h_i}} (x-h_1)(x-h_2) \cdots (x-h_i).
\]

Therefore \( (D_i h_i)^2 = \left\{ \sum (c_2 c_3 \cdots c_{i+1}) \zeta(h_2 h_3 \cdots h_{i+1})(h_1-h_2)(h_1-h_3) \cdots (h_1-h_{i+1}) \right\}^2 \),

and the simplified \((i+1)\)th quotient, i.e. the value of \( A_{i+1}x+B_{i+1} \), when divested of the allotrious factor, has been proved to be equal to

\[
\sum (D_i h_i) \frac{\Phi_{h_i}}{F_{h_i}} (x-h_i);
\]
it is therefore now known as a rational and integral function of \( x \); \( h_1h_2\ldots h_n; c_1c_2\ldots c_n \). The allotrious factor itself is made up of the product of squares of quantities all of the same form as the leading coefficient in \( D_x \), which, from what has been shown above, is seen to be equal to

\[
(-)^{\frac{i-1}{2}} \sum_{i=1}^{n} (c_1c_2\ldots c_i) \zeta(h_1h_2\ldots h_i).
\]

Hence each term in the continued fraction

\[
\frac{1}{(A_1x+B_1)} - \frac{1}{(A_2x+B_2)} - \cdots - \frac{1}{(A_nx+B_n)},
\]

which is to be made equal to

\[
\frac{c_1}{(x-h_1)} + \frac{c_2}{(x-h_2)} + \cdots + \frac{c_n}{(x-h_n)},
\]

is completely assigned in terms of \( x \) and the given quantities \( c \) and \( h \).

Art. (2.). The number of effective intercalations between the roots of \( \Phi x \), \( Fx \) is easily seen to be equal to the excess of the number of positive real numerators over the number of negative real numerators in the partial fractions of which \( \frac{\Phi x}{Fx} \) is the sum, and hence we see \( a \) priori, as an obvious consequence of a simple extension of the reasoning in art. (47.), that the inertia of the quadratic function

\[
\Sigma \left\{ c_\theta(u_1+h_\theta u_2+h_\theta^2 u_3+\ldots+h_\theta^{n-1}.u_n)\right\} \frac{1}{x-h_\theta},
\]

where \( c_\theta = \frac{\Phi h_\theta}{F h_\theta} \) will represent the value of the index in question. So too we may see that the formulæ given for the residues to \( f x, f&#x27;x \) in art. (46.) continue to apply to the residues \( Fx, \Phi x \). That is to say, these residues when divided out by \( Fx \) will be respectively represented by the successive principal coaxal determinants to the matrix

\[
S_0 S_1 S_2 \ldots S_{m-1}
S_1 S_2 S_3 \ldots S_m
S_2 S_3 S_4 \ldots S_{m+1}
\ldots \ldots \ldots \ldots \ldots
S_{m-1} S_m S_{m+1} \ldots S_{2m-2},
\]

where in general

\[
S_r = \frac{c_1}{x-h_1} h_1^r + \frac{c_2}{x-h_2} h_2^r + \cdots + \frac{c_n}{x-h_n} h_n^r;
\]

and using the same matrix as above written with \( S&#x27; \) substituted for \( S \), where in general

\[
S&#x27;_r = c_1(x-h_1)^r + c_2(x-h_2)^r + \cdots + c_n(x-h_n)^r,
\]

the successive principal coaxal determinants of the new matrix represent the successive denominators to the convergents of the continued fraction which expresses \( \frac{\Phi x}{Fx} \).

The expression for the numerators to the convergents may also, there is no doubt, be obtained by some simple modification (dependent on introducing the quantities \( c_1c_2\ldots c_n \)) of the formula in art. (41.), p. 465.

I annex, more with the hope of suggesting than (in all instances) of conveying a
full conception of the force of the definitions, a Glossary, or rather a Repertory of
the principal terms of art employed in the preceding pages, which might otherwise
be apt to occasion some difficulty to persons unfamiliar with the subject.

ERRATA AND ADDENDA.

Page 408, 410, 412, 414, in running head to page, for Conjugate read Syzygetic.
— 408, line 16 from foot, for above read about.
— 409, line 4 from top, for continual read continued.
— 429, line 12 from foot, for the same r new, read the same number r of new.
— 430, line 3 from foot, after simplicity insert a comma.
— 432, line 2 above (15.), for $\frac{1}{q_{n-1}}$ read $\frac{1}{q_{n-1}}$.
— 432, line 3 under (15.), after fraction dele —
— 434, at end of the equation nearest the foot, for $(x - \eta_{q_i})$ read $x - \eta_{q_i}$.
— 436, in equation (21.), for $(x - \eta_{k_n})$ read $(x - \eta_{k_n})$.
— 436, line 2 under (21.), for $k_m$ read $k_n$.
— 438, line 10 from foot, for $(\lambda_0) (\lambda_1) (\lambda_{n-1})$ read $\lambda_0 \lambda_1 \lambda_{n-1}$.
— 439, line 3 from top, after the words &quot;solution of&quot; insert &quot;the equation.&quot;
— 439, line 10 from top, for and therefore read then.
— 444, line 2 from top, for or read i.e.
— 448, Art. 28, line 3, for $\varepsilon - x^m$ read $\varepsilon x^m$.
— 452, line 1, for but read for.
— 454, lines 5 and 14, for fm read fn.
— 458, line 4 in Art. 37, for fx read f&#x27;x.
— 459, line 7 in Art. 38, for $-\delta$ read $+\delta$.
— 464, line 15 from foot, for $k_1 = k_2 = k_3$ read $k_1 = k_2 = k_3$.
— 467, line 6 from foot, for Latin and Greek read Latin, Greek and Hebrew.
— 479, Art. p, line 2, for $\Sigma&#x27;_m$ and $\Sigma&#x27;_n$ read $\Sigma&#x27;_m$ and $\Sigma&#x27;_n$.
— 479, last line, for subscrolet read subscript.
— 481, in the value of $y_3$ near foot of page, for the sign — read +
— 482, middle of the page, for $\frac{d^2f}{dx^2}$ read $\frac{d^2f}{dx^2}$.
— 485, line 10, for $\rho$ read $x$.
— 497, Art. $\beta$, for Now read Also.
— 504, line 12, dele &#x27;m&#x27;.
— 514, Art. (61.), lines 7 and 8, for am$x^m$ and bm$x^m$ read am$y^m$, bm$y^m$.
— 515, line 4, for $u_1$, $u_2$...$u_m$ read $u&#x27;_1$, $u&#x27;_2$...$u&#x27;_m$.
— 518, near middle of page, for $\frac{1}{1,2,3...(m-1)^2}$ read $\frac{1}{(1,2,3...(m-1)^2)}$.
— 524, near middle of page, for $\alpha_0$, $\frac{d}{da_1}$ read $\alpha_0$, $\frac{d}{da_1}$.
Glossary of new or unusual Terms, or of Terms used in a new or unusual sense in the preceding Memoir.

Allotrious.—The allotrious factor to a residue or quotient in the process of common measure applied to two algebraical functions is the constant factor of which such residue or quotient must be divested in order to become an integral and irreducible function.

Apocopated.—Applied to a type in the Theory of Cumulants, denotes a type the final or initial element of which has been taken away. If both are taken away, the type is said to be doubly apocopated.

Bezoutic.—For definition of Primary and Secondary Bezoutics see first Section. Bezoutiant to two functions, each of degree \( n \), is a homogeneous quadratic invariantive function of \( n \) variables, the form of which serves to assign the index of the scale of the effective intercalations of the real roots of the two given functions.

Bezoutoid.—The Bezoutiant to two homogeneous functions obtained by differentiation from one homogeneous function of two variables. The Bezoutoid to a given function of \( m \) dimensions in the variables is accordingly a quadratic function of \((m-1)\) variables, the form of which is sufficient for determining the number of real roots in the given function.

Characteristic.—The employment of this word has been avoided in the preceding memoir; but as it contains an idea of capital importance in analysis, and especially in all inquiries of the kind here treated of, I subjoin the definition of its meaning. The characteristic of a simple condition of any kind is the rational integral function (in its lowest terms) whose evanescence necessarily and universally implies and is implied by the satisfaction of such condition. A simple condition has always a single characteristic, abstraction being made of the algebraical sign, which remains indeterminate. In like manner, a multiple condition, or a system of conditions, will have for its characteristic a plexus of rational integral functions, whose evanescence necessarily and universally implies and is implied by the satisfaction of such multiple condition or system of conditions. The number of functions in the characteristic plexus will however in general greatly exceed the index of the multiplicity of the conditions, and need not always be a unique system. There are however exceptions to this: thus the duplex condition, that a biquadratic function of \( x \) shall contain a cubic factor, or that a curve of the third degree shall have a cusp, will each be definitely characterized by a plexus of two functions, and no more.

The spirit of the higher analysis resides, and is to be sought for, in the logic of characteristics.

Co-bezoutiant.—Any homogeneous quadratic function similar in form and in its property of invariance to the Bezoutiant.

Cogredient and Contragredient.—A system of variables is cogredient to another system when it is subject to undergo simultaneously therewith linear substitutions of a like kind, and contragredient when it is subject to undergo linear substitutions simultaneously therewith but of a contrary kind.

Combinant.—A function of the quantities appearing in a given set of functions which remains unaltered as well for linear substitutions impressed upon the variables as for linear combinations of the functions themselves.

Concomitant.—Nomen generalissimum for a form invariantively connected with a given form or system of forms.

Conjunctive.—A syzygetic function of a given set of functions. Any function which universally,
and subject to no cases of exception, vanishes when a certain number of other functions all vanish together must be a conjunctive (i.e. a syzygetic function), or a root of a conjunctive of such functions. But if its vanishing is subject to cases of exception, then all that can be predicated of it is that it is syzygetically related to such functions, but it may, and usually does happen, that it will be syzygetically related to them in more than one way.

Contravariant.—A function which stands in the same relation to the primitive function from which it is derived as any of its linear transforms to an inversely derived transform of its primitive.

Covariant.—A function which stands in the same relation to the primitive function from which it is derived as any of its linear transforms to a similarly derived transform of its primitive.

Cumulant.—The denominator of the simple algebraical fraction which expresses the value of an improper continued fraction. See Type, infra.

Determinant.—This word is used throughout in the single sense, after which it denotes the alternate or hemihedral function the vanishing of which is the condition of the possibility of the coexistence of a system of a certain number of homogeneous linear equations of as many variables.

Dialytic.—If there be a system of functions containing in each term different combinations of the powers of the variables in number equal to the number of the functions, a resultant may be formed from these functions by, as it were, dissolving the relations which connect together the different combinations of the powers of the variables, and treating them as simple independent quantities linearly involved in the functions. The resultant so formed is called the Dialytic Resultant of the functions supposed; and any method by which the elimination between two or more equations can be made to depend on the formation of such a resultant is called a dialytic method of elimination. In such method accordingly the process of elimination between equations of a higher degree than the first is always reduced to a question of elimination between equations which are of the first degree only.

Discriminant.—The resultant of the $n$ differential coefficients of a homogeneous function of $n$ variables. See Resultant, infra.

Disjunctive.—A disjunctive equation is a relation between two sets of quantities such that each one of either set is equal according to some unspecified order of connexion with some one of the other set.

Effective scale of intercalations is the series of the real roots of two functions of $x$ written in order of magnitude after repeated processes of removing pairs of roots belonging to either the same function (when not separated by roots of the other function): the roots of the two functions follow each other alternately.

Effluent.—From every homogeneous function of any number of variables $i$ of the degree $mm&#x27;$, where $mm&#x27;$ are any two integers, may be formed (as shown in the Calculus of Forms, Section I.) a covariantive function of the degree $m$ and of $\mu$ variables [where $\mu$ is the number of permutations that can be obtained by dividing $m&#x27;$ into $i$ parts (zeros admissible)], in which all the coefficients are numerical multiples of the given coefficients; covariants so formed may be termed effluents of their primitive. An example of this occurs in the foot note to Section V, p. 522, where the quantity there called $Q$ is a quadratic effluent of the Jacobian.

Element.—A simple component of the type to a cumulant. See Cumulant, supra.
Emanant.—The result of operating any number of times (suppose \( i \) times) upon a given homogeneous function of any number of variables \( x, y, z \ldots t \) with the operative symbol

\[
\left( ax&#x27; \frac{d}{dx} + by&#x27; \frac{d}{dy} + cz&#x27; \frac{d}{dz} + \ldots + tx&#x27; \frac{d}{dt} \right),
\]

is called the \( i \)th emanant of the function operated upon. Every emanant is a covariant to its primitive, the new variables \( x&#x27;, y&#x27;, z&#x27;, \ldots t&#x27; \) being cogradient with the variables \( x, y, z \ldots t \) with which they are respectively associated. \( E_{2i+1}f, E_{2i+1}\varphi \), page 522, are emanants of \( f \) and \( \varphi \). The process of emanation is one of incessant occurrence in the theory of invariants. When the order of the emanation is the same as the degree of the function (supposed to be rational and integral) from which the emanation proceeds, the form of the original function is reproduced in the final emanant, the names only of the variables being changed.

Endoscopic, Exoscopic.—When the coefficients of the functions concerned in any investigation are regarded as integral indecomposable monads, the method is called exoscopic, and endoscopic when the coefficients are treated with reference to their internal constitution as composed of roots or other elements.

In addition to the examples in the foot note to Section I, these words have a marked and most important application in the theory of Invariants, especially of two variables.

Form.—Any function may be regarded as an opus operatum; the matter operated upon being the variables, and the substance of the operations being the form, which resides in the function as the soul in the body. A form is always common to an infinity of functions, but for greater brevity may be and frequently is called by the name of some specified function in which it is contained.

Fundamental.—The fundamental scale of a system of Invariants or Concomitants is a set of the same, whereof every other is a Rational Integral Function.

Hessian or Hessean, named after Dr. Otto Hesse, of Konigsberg (the worthy pupil of his illustrious master, Jacobi, but who, to the scandal of the mathematical world, remains still without a Chair in the University which he adorns with his presence and his name), is the Jacobian to the differential coefficients of a homogeneous function of any number of variables. It is to a Jacobian what a Bezoutoid is to a Bezoutiant, or a Discriminant to a Resultant.

Hyperdeterminants.—See Memoir of Mr. Cayley, Cambridge and Dublin Mathematical Journal, May 1845, and Crelle&#x27;s Journal of about the same date.

Improper, continued fraction is a continued fraction differing only from an ordinary one in the circumstance of negative signs being substituted for positive signs to connect the terms.

Inertia.—The unchangeable number of integers in the excess of positive over negative signs which adheres to a quadratic form expressed as the sum of positive and negative squares, notwithstanding any real linear transformations impressed upon such form.

Intercalations.—The theory of intercalations is the theory of the relative distribution of the real roots, or point-roots, of two or more equations, but in this theory the number of roots mutually interposed is to be taken only with reference to the number 2 as a modulus.

Invariance.—The property (under prescribed or implied conditions) of remaining invariable.

Invariant.—A function of the coefficients of one or more forms which remains unaltered when these undergo suitable linear transformations.
Inverse.—The inverse to a given square matrix is formed by selecting in its turn each component of the given matrix, substituting unity in its place, making all the other components in the same line and column therewith zero, and finally writing the value of the determinant corresponding to the matrix thus modified in lieu of the selected component. If the determinant to the matrix be equal to unity, its second inverse, i.e. the inverse to its inverse, will be identical, term for term, with the original matrix.

Jacobian.—The Jacobian to $n$ homogeneous functions of $n$ variables is the determinant represented by the symmetrical collocation in a square of the $n$ differential coefficients of each of the $n$ functions.

Kenotheme.—A finite system of discrete points defined by one or more homogeneous equations in number one less than the number of variables contained therein.

Limiting Series.—One set of quantities whose extreme values are exterior to the extreme values of a second set is set to limit the latter.

Matrix.—A square or rectangular arrangement of terms in lines and columns.

Minor Determinant.—Any determinant retained represented by a square group of terms arbitrarily chosen out of a matrix is a minor determinant thereto. The simple terms of the matrix are the last minors, and of course if the matrix is a square, it will itself in its totality represent a single complete determinant.

Monotheme.—A line, or finite system of lines, defined by one or more homogeneous equations two less in number than the numbers of the variables contained therein.

Order.—The orders of a homogeneous function are the linear functions of the variables the least in number by aid of which the function admits of being expressed.

Persymmetrical.—A symmetrical matrix, in which all the terms in the diagonal bands transverse to the axis of symmetry are identical, is said to be persymmetrical. Ex. An addition table.

Quadrinvariant.—An invariant of which the terms are quadratic functions of the coefficients of the primitive.

Relation (simple and compound). Vide Substitution, infra.

Resultant.—The resultant of $n$ homogeneous general functions of $n$ variables is that function of their coefficients which, equalled to zero, expresses in the simplest terms the condition of the possibility of their coexistence.

Rhizoristic.—A rhizoristic series is a series of disconnected functions which serve to fix the number of real roots of a given function lying between any assigned limits.

Signaletic.—A signaletic or Semaphoretic series is a sequence of disjunctive terms, considered solely with reference to the algebraical signs of plus and minus which they respectively carry.

Singular.—A proper algebraical function of a given degree, $n$, in one variable in its most general form, will, in respect to that variable, be of the $n$th degree in the denominator and the $(n-1)$th degree in the numerator, and will admit of being represented by a continued algebraical fraction of $n$ terms, all of them linear.

But for particular values of, or relations among, the coefficients entering into the given fraction this mode of representation fails, and the continued fraction, instead of consisting of linear terms
$n$ in number, will consist of terms, some of them at least, non-linear, and fewer than $n$ in number. These then are the singular cases (or cases of singularity) in the theory of the development of an algebraical fraction under the continued fraction form; and it will be seen that according to this definition the case of the development of any proper algebraical fraction in which the degree of the numerator is more than one unit below that of the denominator, belongs (strictly speaking) to the class of singular cases; and this view of the case supposed is perfectly correct and conformable to the analogies of the subject.

Substitution (linear, similar or contrary).—A linear substitution is said to be impressed upon a system of variables when each variable is replaced by a linear conjunctive of all the variables. The matrix formed by the coefficients of substitution arranged in regular order is called the Matrix of Substitution, and is of course a square. When two substitutions (impressed in two systems of variables) have the same matrix, they are said to be similar and contrary when their matrices are contrary, i.e. mutually inverse to each other. When two systems of variables are supposed to be subject to the condition that their substitutions are always similar or always contrary, they are said to be related or in simple relation, the relation being of cogredience in the one case and of contragredience in the other.

When a linear substitution is impressed upon a system of independent variables, a corresponding linear substitution is necessarily impressed at the same time upon every complete system of homogeneous combinations (i.e. products and powers and products of powers) of these variables, the matrix to which latter substitution will consist of terms which will be functions (depending upon the degree of the homogeneous combinations) of the terms of the matrix to the primitive substitution. This matrix may be termed a compound matrix, having the primitive matrix for its base.

If, now, two systems of independent variables are subject to be synchronously impressed with substitutions, the matrices to which (not being both of them simple matrices) have for their bases matrices which are either similar or contrary, these two systems will be said to be in compound relation of cogredience in the one case, and of contragredience in the other.

Syrrhizoristic.—A syrrhizoristic series is a series of disconnected functions which serve to determine the effective intercalations of the real roots of two functions lying between any assigned limits.

Syzygetic.—A syzygetic function or conjunctive of a number of given rational integral functions is the sum of these affected respectively with arbitrary functional multipliers, which are termed the syzygetic multipliers. When a syzygetic function of a given set of functions can be made to vanish, they are said to be syzygetically related.

Transform.—Equivalent to the French noun substantive &quot;transformée.&quot;

Type.—The type of a cumulant is the series of the simple elements (or quotients), arranged in a fixed order, of which the cumulant is composed.

Umbral.—The umbral notation is a notation according to which simple quantities are denoted by syllables, instead of by single letters (the composition of these syllables being governed by the mode in which the quantities which they express are obtained); and the single letters of such syllables are termed umbral quantities or umbrae.

Weight.—In this memoir (throughout the earlier sections) the weight of any quantity composed of the product of the coefficients of any given function or functions of $x$ is used to denote the number of roots of $x$ appertaining to the given function or functions which must be employed to express such quantity. More generally, when dealing with a system of homogeneous functions,
the weight of a quantity may be defined with respect to any selected variable therein as the sum of the weights in respect to such variable of the several coefficients of which the quantity is composed (the weight of each several coefficient meaning the index of the power of the selected variable in that term of the given function or functions which is affected with such coefficient). These two definitions of weight may be perfectly well reconciled with each other by understanding the weight of a quantity formed from the coefficients of a function or system of functions of \( x \) to mean the weight, in respect to unity, of such quantity when the given functions are treated as homogeneous functions of \( x \) and 1.

Zeta.—The symbol \( \zeta \) (preceding a row of bracketed terms) is used to denote the product of the squared differences of the terms which it affects.

\[ [ ] \]. A bracket of this form, when inclosing a superior and an inferior row of terms \( m \) and \( n \) in number respectively, indicates the \( mn \) products of the differences obtained by subtracting each term in the second row from each term in the first row; when enclosing an arrangement of terms in a single line, it is used to denote the cumulant of which such an arrangement is the type.

---

CONTENTS.

Introduction .................................................................................................................. 407

Section I.—On the complete and simplified residues generated in the process of developing under the form of a continued fraction, an ordinary rational algebraical fraction ........................................... 415

Section II.—On the general solution in terms of the roots of any two given algebraical functions of \( x \) of the syzygetic equation, which connects them with a third function, whose degree in \( (x) \) is given, but whose form is to be determined .............................................................................. 433

Section III.—On the application of the Theorems in the preceding Section to the expression in terms of the roots of any primitive function of Sturm&#x27;s auxiliary functions, and the other functions which connect these with the primitive function and its first differential derivative ......................... 456

Supplement to Section III.—On the Quotients resulting from the process of continued division ordinarily applied to two Algebraical Functions in order to determine their greatest Common Measure... 467

Section IV.—On some further Formulae connected with M. Sturm&#x27;s theorem, and on the Theory of Intercalations whereof that theorem may be treated as a corollary ........................................ 480

Supplement to Section IV.—Development of the method of assigning a superior and inferior limit to the roots of any algebraical equation ........................................................................ 496

Section V.—On the Theory of Intercalations as applicable to two functions of the same degree, and on the formal properties of the Bezoutian with reference to the method of Invariants ....................... 510

General and Concluding Supplement.—General Theorem connecting the Partial Quotients with the Convergents to an Unlimited Arbitrary Rational Integral Algebraical Continued Fraction, and on the Conversion of a Series of Partial Fractions into a Continued Fraction ........................................ 535

Errata ............................................................................................................................. 542

Glossary of new or unusual Terms, or of Terms used in a new or unusual sense in the preceding Memoir 543</div>
</article>
